@inproceedings{10.1145/1988051.1988065,
author = {M\"{u}lders, Peter and Gruner, Stefan and Thang, Nguyen Xuan},
title = {Model-Driven Design plus Artificial Intelligence for Wireless Sensor Networks Software Development},
year = {2011},
isbn = {9781450305839},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1988051.1988065},
doi = {10.1145/1988051.1988065},
abstract = {To date, software development for wireless sensor network nodes is still characterized by low-level ad-hoc programming to a large extent. This short-paper argues for a methodologically more systematic approach on the basis of Model-Driven Engineering with CASE-Tool support, in combination with AI-based design choice optimizations during the MDE-steps of model-refinement and information-enrichment. Our work in this project is ongoing.},
booktitle = {Proceedings of the 2nd Workshop on Software Engineering for Sensor Network Applications},
pages = {63–64},
numpages = {2},
keywords = {wireless sensor networks, genetic algorithms, model-driven engineering, case-tool support, development methodology},
location = {Waikiki, Honolulu, HI, USA},
series = {SESENA '11}
}

@inproceedings{10.1109/MODELS-C.2019.00028,
author = {Burgue\~{n}o, Loli and Burdusel, Alexandru and G\'{e}rard, S\'{e}bastien and Wimmer, Manuel},
title = {MDE Intelligence 2019: 1st Workshop on Artificial Intelligence and Model-Driven Engineering},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00028},
doi = {10.1109/MODELS-C.2019.00028},
abstract = {Model-driven engineering (MDE) and Artificial Intelligence (AI) are two separate fields in computer science, which can clearly benefit from cross-fertilization and collaboration. There are at least two ways in which such integrations---which we call MDE Intelligence---can manifest: (1) MDE can benefit from integrating AI concepts and ideas to increasing the power and flexibility of model-driven techniques by means of the application of AI algorithms. (2) Conversely, AI can benefit from integrating concepts and ideas from MDE---for example, using domain-specific languages and model transformations allows domain experts to directly express and manipulate their problems while providing an auditable computation pipeline.To discuss and further stimulate such integrations, the 1st edition of the Workshop on Artificial Intelligence and Model-driven Engineering (MDE Intelligence) was held on September 16, 2019 in Munich, Germany, as part of the satellite events of the IEEE/ACM 22th International Conference on Model-Driven Engineering Languages and Systems (MODELS 2019).},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {168–169},
numpages = {2},
keywords = {artificial intelligence, MDE, MDE intelligence},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1145/3550356.3561609,
author = {Bergelin, Johan and Strandberg, Per Erik},
title = {Industrial Requirements for Supporting AI-Enhanced Model-Driven Engineering},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561609},
doi = {10.1145/3550356.3561609},
abstract = {There is an increasing interest in research on the combination of AI techniques and methods with MDE. However, there is a gap between AI and MDE practices, as well as between researchers and practitioners. This paper tackles this gap by reporting on industrial requirements in this field. In the AIDOaRt research project, practitioners and researchers collaborate on AI-augmented automation supporting modeling, coding, testing, monitoring, and continuous development in cyber-physical systems. The project specifically lies at the intersection of industry and academia collaboration with several industrial use cases. Through a process of elicitation and refinement, 78 high-level requirements were defined, and generalized into 30 generic requirements by the AIDOaRt partners. The main contribution of this paper is the set of generic requirements from the project for enhancing the development of cyber-physical systems with artificial intelligence, DevOps, and model-driven engineering, identifying the hot spots of industry needs in the interactions of MDE and AI. Future work will refine, implement and evaluate solutions toward these requirements in industry contexts.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {375–379},
numpages = {5},
keywords = {requirements, artificial intelligence, model-driven engineering, cyber-physical systems},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.5555/2008503.2008556,
author = {Lortal, Ga\"{e}lle and Dhouib, Saadia and G\'{e}rard, S\'{e}bastien},
title = {Integrating Ontological Domain Knowledge into a Robotic DSL},
year = {2010},
isbn = {9783642212093},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Coming from the Artificial Intelligence (AI) and Semantic Web (SW) circles, ontologies are used mainly to represent domains. The Model Driven Engineering (MDE) field gave birth to Domain Specific Languages to represent a particular technical domain. Abstracting from their uses, we consider as many others researchers that ontologies and models are closer than their original fields could get to think. Furthermore, their building or development are facing the same problems. They are costly and need experts' interviews in order to grasp specific knowledge and structure it. Likewise, ontologies and DSL can benefit from each other domains in reusing construction methodologies and even reusing knowledge modelled in another format. In this paper we first present the ontologies and DSL definition we use and some methodologies of development enabling the reuse of knowledge (as alignment, fusion). We then present how we propose to reuse the knowledge of a robotic ontology to develop robotic DSLs within the PROTEUS project in order to inject readymade domain information to the DSL.},
booktitle = {Proceedings of the 2010 International Conference on Models in Software Engineering},
pages = {401–414},
numpages = {14},
location = {Oslo, Norway},
series = {MODELS'10}
}

@inproceedings{10.5555/2662593.2662595,
author = {Hastjarjanto, Tom and Jeuring, Johan and Leather, Sean},
title = {A DSL for Describing the Artificial Intelligence in Real-Time Video Games},
year = {2013},
isbn = {9781467362634},
publisher = {IEEE Press},
abstract = {Many games have computer-controlled agents that play against a player. The behavior of these computer-controlled agents is described by means of the artificial intelligence (AI) in the game. The AI is an important component of the game, and needs to be developed carefully, and adapted regularly. This paper introduces a novel language for describing the decision making process of the AI in real-time video games. We develop a declarative, domain-specific language (DSL) embedded in the functional programming language Haskell for real-time video games. We use the DSL to describe the AI of a prototype real-time video game.},
booktitle = {Proceedings of the 3rd International Workshop on Games and Software Engineering: Engineering Computer Games to Enable Positive, Progressive Change},
pages = {8–14},
numpages = {7},
location = {San Francisco, California},
series = {GAS '13}
}

@inproceedings{10.1145/1774088.1774614,
author = {Hurnaus, Dominik and Pr\"{a}hofer, Herbert},
title = {Programming Assistance Based on Contracts and Modular Verification in the Automation Domain},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774614},
doi = {10.1145/1774088.1774614},
abstract = {In industrial automation, control software often has to get changed and adapted by domain experts and end users who have no or only limited software development expertise. This results in high demands on programming environments with respect to supporting, guiding, and supervising the programming tasks. In this paper we present an approach based on model checking and artificial intelligence techniques to guide domain experts in building control software which is guaranteed to obey specified contracts and constraints. The work is based on Monaco which is a domain-specific language for programming automation solutions. As Monaco employs a hierarchical component approach, the verification is done hierarchically where an upper component is verified against the contracts of its subcomponents. The verification approach is leveraged in different programming support systems which give immediate feedback about valid and invalid programs in an integrated development environment.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {2544–2551},
numpages = {8},
keywords = {domain-specific language, end-user programming, automation software, component-based systems},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@inproceedings{10.1145/3053600.3053619,
author = {Mangels, Tatiana and Murarasu, Alin and Oden, Forest and Fishkin, Alexey and Becker, Daniel},
title = {Efficient Analysis at Edge},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053619},
doi = {10.1145/3053600.3053619},
abstract = {Digitalization changes traditional business models by using digital technologies to improve existing offerings and to create new offerings. Current technological trends such as artificial intelligence, autonomous systems, and predictive maintenance are ideal candidate technologies to enable digitalization use cases. Often, these technologies rely on the availability of large amounts of data and the capability to process these data efficiently. In contrast to consumer markets, industrial products must fulfill higher non-functional requirements such as fast response times, 24/7 availability and stability, real-time processing, safety, or security requirements. As a consequence, processing capabilities -- ranging from multicore and manycores to even high end parallel clusters -- have to be exploited to achieve necessary performance and stability needs. In this paper, we introduce a Distributed Multicore Monitoring Framework (MoMo) which is a reference monitoring solution developed at Siemens Corporate Technology. It can be used to easily build efficient and stable diagnostic solutions which can help to understand the correctness, availability, reliability, and performance of large-scale distributed systems based on live data. Due to its small footprint MoMo can be used to analyze data directly at the data source which, for instance, can significantly reduce the network load. While MoMo's efficiency comes from the usage of multicore processors (CPUs) for running analysis in parallel, its usability is guaranteed by its capability to easily integrate with other monitoring frameworks and its usage of SPL - a domain-specific language which allows user to easily define diagnostic algorithms.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {85–90},
numpages = {6},
keywords = {monitoring, parallel computing, data analysis},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}

@inproceedings{10.1145/224401.224834,
author = {Frantz, Frederick K.},
title = {A Taxonomy of Model Abstraction Techniques},
year = {1995},
isbn = {0780330188},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1145/224401.224834},
doi = {10.1145/224401.224834},
abstract = {Model abstraction is a method for reducing the complexity of a simulation model while maintaining the validity of the simulation results with respect to the question that the simulation is being used to address. Model developers have traditionally used a number of abstraction techniques, and simulation researchers have conducted formal research to build a theoretical foundation for model manipulation. More recently, researchers in the artificial intelligence (AI) subfield of qualitative simulation have also been developing techniques for simplifying models, determining whether models results are valid, and developing tools for automatic model selection and manipulation. Metamodeling can also be considered as an abstraction technique. The purpose of the paper is to provide a taxonomy of abstraction techniques drawn from these fields. This taxonomy provides a framework for comparing and contrasting various abstraction techniques.},
booktitle = {Proceedings of the 27th Conference on Winter Simulation},
pages = {1413–1420},
numpages = {8},
location = {Arlington, Virginia, USA},
series = {WSC '95}
}@inproceedings{10.1145/3417990.3419486,
author = {Saini, Rijul},
title = {Artificial Intelligence Empowered Domain Modelling Bot},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3419486},
doi = {10.1145/3417990.3419486},
abstract = {With the increasing adoption of Model-Based Software Engineering (MBSE) to handle the complexity of modern software systems in industry and inclusion of modelling topics in academic curricula, it is no longer a question of whether to use MBSE but how to use it. Acquiring modelling skills to properly build and use models with the help of modelling formalisms are non-trivial learning objectives, which novice modellers struggle to achieve for several reasons. For example, it is difficult for novice modellers to learn to use their abstraction abilities. Also, due to high student-teacher ratios in a typical classroom setting, novice modellers may not receive personalized and timely feedback on their modelling decisions. These issues hinder the novice modellers in improving their modelling skills. Furthermore, a lack of modelling skills among modellers inhibits the adoption and practice of modelling in industry. Therefore, an automated and intelligent solution is required to help modellers and other practitioners in improving their modelling skills. This doctoral research builds an automated and intelligent solution for one modelling formalism - domain models, in an avatar of a domain modelling bot. The bot automatically extracts domain models from problem descriptions written in natural language and generates intelligent recommendations, particularly for teaching modelling literacy to novice modellers. For this domain modelling bot, we leverage the capabilities of various Artificial Intelligence techniques such as Natural Language Processing and Machine Learning.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {26},
numpages = {6},
keywords = {machine learning (ML), bot, domain model, natural language (NL), artificial intelligence (AI), natural language processing (NLP)},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.5555/1123196.1123314,
author = {Malyankar, R. M. and Baddam, A.},
title = {XML Schemas from Computational Ontologies},
year = {2003},
publisher = {Digital Government Society of North America},
abstract = {Academic researchers in artificial intelligence tend to use computational ontologies for knowledge modeling whereas commercial developers tend to use XML schemas, even though there is considerable overlap between the two representations considered as models of knowledge domains. Each representation has its own advantages and disadvantages compared to the other. There are active initiatives on the representation of knowledge for Web technologies, e.g., RDF (Resource Description Framework), and OWL (Web Ontology Language). These efforts often include ontology and schema editors that try to make schemas adhere to well-defined domain modeling principles, usually drawn from AI research in knowledge representation. This work is generally part of semantic web research. However, application developer communities have long accepted XML markup technology for data structuring, even though XML lacks (or rather, does not require) well-defined, rigorous domain models; the fact that such rigor is not required means that XML vocabularies are proliferating, and variant and ill-constructed models of domains and XML markup vocabularies are becoming set in stone by the effort that has gone into developing XML-based applications around them. One way to avoid this, and pave the way for future semantic web applications, is to devise a way to create and maintain a well-defined and unambiguous link between XML schemas and XML vocabularies and computational ontologies.Our XML schema generator is intended for ontologies represented in Protege. The schema generator maps ontology classes to named complex types in the format of the XML Schema specification; slots in the ontology are (at the user's option) either attributes for the complex types corresponding to the classes, or sub-elements in those same complex types. Range restrictions on the values of slots in the ontology are preserved and enumerated ranges are transformed into schema enumerations. Class inheritance relationships are converted into XML schema extension relationships. Metadata for classes and attributes is placed into schema annotation elements. Schema metadata can also be entered by the user. The schema generator optionally compels adherence to the naming standards in the Department of the Navy draft guidelines for XML schema development. The validity of the XML type libraries generated by this tool has been verified using schema validation tools available on XML Schema-related web sites.The difference between the expressive power of XML schemas and ontologies means certain features cannot be transformed. However, we find that for limited purposes, namely, turning ontologies into XML schema type libraries, the tool is useful even in its current form - it certainly speeds up the process of XML schema creation, because the taxonomical content of XML schemas, i.e., defining inheritance relationships, attributes, slot value ranges, etc., is easier with an ontology editor; so far, adding the unrepresented information to the sype libraries after the fact has not been too laborious a task - though it is certainly error-prone and repetitive, and we are investigating means of automating it or representing all the details necessary for XML schemas in ontologies.The XML schema generator described here is being used in WIN (Waterway Information Network), a proposed distributed content management architecture for marine transportation information, described in a companion paper in this conference (Malyankar et al 2003). The rationale underlying the use of such a schema generator is outlined above and in the companion paper: facilitating linkage between AI concepts of ontologies and programming structures for XML, thereby providing a formal and logically sound basis for XML application development. We hope this is one route from current Web technology to the Semantic Web; i.e., it is transitional technology that should ease progression to the semantic web.},
booktitle = {Proceedings of the 2003 Annual National Conference on Digital Government Research},
pages = {1},
numpages = {1},
location = {Boston, MA, USA},
series = {dg.o '03}
}

@inproceedings{10.1145/3550356.3559096,
author = {L\'{o}pez, Jos\'{e} Antonio Hern\'{a}ndez and Izquierdo, Javier Luis C\'{a}novas and Cuadrado, Jes\'{u}s S\'{a}nchez},
title = {Using the ModelSet Dataset to Support Machine Learning in Model-Driven Engineering},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3559096},
doi = {10.1145/3550356.3559096},
abstract = {The availability of curated collections of models is essential for the application of techniques like Machine Learning (ML) and Data Analytics to MDE as well as to boost research activities. However, many applications of ML to address MDE tasks are currently limited to small datasets. In this demo paper, we will present ModelSet, a dataset composed of 5,466 Ecore models and 5,120 UML models which have been manually labelled to support ML tasks (http://modelset.github.io). ModelSet is built upon the models collected by the MAR search engine (http://mar-search.org), which provides more than 500,000 models of different types. We will describe the structure of the dataset and we will explain how to use the associated library to develop ML applications in Python. Finally, we will describe some applications which can be addressed using ModelSet.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {66–70},
numpages = {5},
keywords = {model classification, machine learning, model-driven engineering},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3550356.3561576,
author = {Kirchhof, J\"{o}rg Christian and Kusmenko, Evgeny and Ritz, Jonas and Rumpe, Bernhard and Moin, Armin and Badii, Atta and G\"{u}nnemann, Stephan and Challenger, Moharram},
title = {MDE for Machine Learning-Enabled Software Systems: A Case Study and Comparison of MontiAnna &amp; ML-Quadrat},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561576},
doi = {10.1145/3550356.3561576},
abstract = {In this paper, we propose to adopt the MDE paradigm for the development of Machine Learning (ML)-enabled software systems with a focus on the Internet of Things (IoT) domain. We illustrate how two state-of-the-art open-source modeling tools, namely MontiAnna and ML-Quadrat can be used for this purpose as demonstrated through a case study. The case study illustrates using ML, in particular deep Artificial Neural Networks (ANNs), for automated image recognition of handwritten digits using the MNIST reference dataset, and integrating the machine learning components into an IoT-system. Subsequently, we conduct a functional comparison of the two frameworks, setting out an analysis base to include a broad range of design considerations, such as the problem domain, methods for the ML integration into larger systems, and supported ML methods, as well as topics of recent intense interest to the ML community, such as AutoML and MLOps. Accordingly, this paper is focused on elucidating the potential of the MDE approach in the ML domain. This supports the ML-engineer in developing the (ML/software) model rather than implementing the code, and additionally enforces reusability and modularity of the design through enabling the out-of-the-box integration of ML functionality as a component of the IoT or cyber-physical systems.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {380–387},
numpages = {8},
keywords = {tools, artificial intelligence, machine learning, domain specific modeling, model-driven engineering},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.5555/2486788.2487038,
author = {Ciccozzi, Federico},
title = {From Models to Code and Back: Correct-by-Construction Code from UML and ALF},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = {Ever increasing complexity of modern software systems demands new powerful development mechanisms. Model-driven engineering (MDE) can ease the development process through problem abstraction and automated code generation from models. In order for MDE solutions to be trusted, such generation should preserve the system's properties defined at modelling level, both functional and extra-functional, all the way down to the target code. The outcome of our research is an approach that aids the preservation of system's properties in MDE of embedded systems. More specifically, we provide generation of full source code from design models defined using the CHESS-ML, monitoring of selected extra-functional properties at code level, and back-propagation of observed values to design models. The approach is validated against industrial case-studies in the telecommunications applicative domain.},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {1459–1461},
numpages = {3},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.5555/2486788.2487038,
author = {Ciccozzi, Federico},
title = {From Models to Code and Back: Correct-by-Construction Code from UML and ALF},
year = {2013},
isbn = {9781467330763},
publisher = {IEEE Press},
abstract = {Ever increasing complexity of modern software systems demands new powerful development mechanisms. Model-driven engineering (MDE) can ease the development process through problem abstraction and automated code generation from models. In order for MDE solutions to be trusted, such generation should preserve the system's properties defined at modelling level, both functional and extra-functional, all the way down to the target code. The outcome of our research is an approach that aids the preservation of system's properties in MDE of embedded systems. More specifically, we provide generation of full source code from design models defined using the CHESS-ML, monitoring of selected extra-functional properties at code level, and back-propagation of observed values to design models. The approach is validated against industrial case-studies in the telecommunications applicative domain.},
booktitle = {Proceedings of the 2013 International Conference on Software Engineering},
pages = {1459–1461},
numpages = {3},
location = {San Francisco, CA, USA},
series = {ICSE '13}
}

@inproceedings{10.1145/3510454.3517067,
author = {d'Aloisio, Giordano},
title = {Quality-Driven Machine Learning-Based Data Science Pipeline Realization: A Software Engineering Approach},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3517067},
doi = {10.1145/3510454.3517067},
abstract = {The recently wide adoption of data science approaches to decision making in several application domains (such as health, business and even education) open new challenges in engineering and implementation of this systems. Considering the big picture of data science, Machine learning is the wider used technique and due to its characteristics, we believe that a better engineering methodology and tools are needed to realize innovative data-driven systems able to satisfy the emerging quality attributes (such as, debias and fariness, explainability, privacy and ethics, sustainability). This research project will explore the following three pillars: i) identify key quality attributes, formalize them in the context of data science pipelines and study their relationships; ii) define a new software engineering approach for data-science systems development that assures compliance with quality requirements; iii) implement tools that guide IT professionals and researchers in the realization of ML-based data science pipelines since the requirement engineering. Moreover, in this paper we also presents some details of the project showing how the feature models and model-driven engineering can be leveraged to realize our project.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {291–293},
numpages = {3},
keywords = {software quality, pipelines, machine learning, product-line architecture, model-driven},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3468044.3468052,
author = {Podobas, Artur and Svedin, Martin and Chien, Steven W. D. and Peng, Ivy B. and Ravichandran, Naresh Balaji and Herman, Pawel and Lansner, Anders and Markidis, Stefano},
title = {StreamBrain: An HPC Framework for Brain-like Neural Networks on CPUs, GPUs and FPGAs},
year = {2021},
isbn = {9781450385497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468044.3468052},
doi = {10.1145/3468044.3468052},
abstract = {The modern deep learning method based on backpropagation has surged in popularity and has been used in multiple domains and application areas. At the same time, there are other - less-known - machine learning algorithms with a mature and solid theoretical foundation whose performance remains unexplored. One such example is the brain-like Bayesian Confidence Propagation Neural Network (BCPNN). In this paper, we introduce StreamBrain--a framework that allows neural networks based on BCPNN to be practically deployed in High-Performance Computing systems. StreamBrain is a domain-specific language (DSL), similar in concept to existing machine learning (ML) frameworks, and supports backends for CPUs, GPUs, and even FPGAs. We empirically demonstrate that StreamBrain can train the well-known ML benchmark dataset MNIST within seconds, and we are the first to demonstrate BCPNN on STL-10 size networks. We also show how StreamBrain can be used to train with custom floating-point formats and illustrate the impact of using different bfloat variations on BCPNN using FPGAs.},
booktitle = {Proceedings of the 11th International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
articleno = {8},
numpages = {6},
keywords = {Emerging Machine Learning, Unsupervised learning, AI, Neural networks, Representation learning, GPU, HPC, FPGA, BCPNN},
location = {Online, Germany},
series = {HEART '21}
}

@inproceedings{10.1145/3123939.3123979,
author = {Park, Jongse and Sharma, Hardik and Mahajan, Divya and Kim, Joon Kyung and Olds, Preston and Esmaeilzadeh, Hadi},
title = {Scale-out Acceleration for Machine Learning},
year = {2017},
isbn = {9781450349529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123939.3123979},
doi = {10.1145/3123939.3123979},
abstract = {The growing scale and complexity of Machine Learning (ML) algorithms has resulted in prevalent use of distributed general-purpose systems. In a rather disjoint effort, the community is focusing mostly on high performance single-node accelerators for learning. This work bridges these two paradigms and offers CoSMIC, a full computing stack constituting language, compiler, system software, template architecture, and circuit generators, that enable programmable acceleration of learning at scale. CoSMIC enables programmers to exploit scale-out acceleration using FPGAs and Programmable ASICs (P-ASICs) from a high-level and mathematical Domain-Specific Language (DSL). Nonetheless, CoSMIC does not require programmers to delve into the onerous task of system software development or hardware design. CoSMIC achieves three conflicting objectives of efficiency, automation, and programmability, by integrating a novel multi-threaded template accelerator architecture and a cohesive stack that generates the hardware and software code from its high-level DSL. CoSMIC can accelerate a wide range of learning algorithms that are most commonly trained using parallel variants of gradient descent. The key is to distribute partial gradient calculations of the learning algorithms across the accelerator-augmented nodes of the scale-out system. Additionally, CoSMIC leverages the parallelizability of the algorithms to offer multi-threaded acceleration within each node. Multi-threading allows CoSMIC to efficiently exploit the numerous resources that are becoming available on modern FPGAs/P-ASICs by striking a balance between multi-threaded parallelism and single-threaded performance. CoSMIC takes advantage of algorithmic properties of ML to offer a specialized system software that optimizes task allocation, role-assignment, thread management, and internode communication. We evaluate the versatility and efficiency of CoSMIC for 10 different machine learning applications from various domains. On average, a 16-node CoSMIC with UltraScale+ FPGAs offers 18.8\texttimes{} speedup over a 16-node Spark system with Xeon processors while the programmer only writes 22--55 lines of code. CoSMIC offers higher scalability compared to the state-of-the-art Spark; scaling from 4 to 16 nodes with CoSMIC yields 2.7\texttimes{} improvements whereas Spark offers 1.8\texttimes{}. These results confirm that the full-stack approach of CoSMIC takes an effective and vital step towards enabling scale-out acceleration for machine learning.},
booktitle = {Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {367–381},
numpages = {15},
keywords = {scale-out, accelerator, machine learning, distributed, cloud},
location = {Cambridge, Massachusetts},
series = {MICRO-50 '17}
}

@inbook{10.1145/3447404.3447405,
title = {Preface},
year = {2021},
isbn = {9781450390293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
url = {https://doi.org/10.1145/3447404.3447405},
abstract = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice provides a comprehensive resource on what has become the dominant paradigm for novel interaction design methods involving gesture, speech, text, and touch embedded in novel and emerging interfaces. These interfaces support smartphones, wearables, in-vehicle devices, virtual reality, robotic, the Internet of Things (IoT), brain–computer interaction, and many other applications that are now highly competitive commercially.This edited collection is written by international experts and pioneers in the field of digital signal processing (DSP) and machine learning (ML) for interactive systems. It provides a textbook for students, and a reference and technology roadmap for developers and professionals working in interaction design on emerging platforms. This introductory textbook presents theory chapters on statistical grounding, signal processing, and ML foundations for guiding the development of novel interactive systems. Additional chapters discuss case studies on smart cities, brain–computer interfaces (BCI), probabilistic text entry, secure gestures, personal context from mobile phones, building adaptive touch interfaces, and automotive user interfaces (UIs). The chapters on case studies also highlight an in-depth look at domain-specific language (DSL) and ML methods used, for example, in touch, gesture, electroencephalography (EEG), electrocardiography (ECG), and galvanic skin response (GSR) signals, or embedded sensor inputs. A common theme throughout is the ubiquitous support for humans as they go about their daily professional or personal activities.This introductory book provides walk-through examples of different DSP and ML techniques and their use in interactive systems. Common terms are defined, and information on practical resources is provided (e.g., software tools, data resources) for hands-on project work to develop and evaluate multimodal–multisensor systems. After each chapter an expert on the legal and ethical issues explores the wider ethical issues on how DSP and ML should be adopted and used in socially appropriate ways, to most effectively advance human performance during interaction with novel platforms.Parisa Eslambolchilar, Andreas Komninos, and Mark D. Dunlop, March 2020AcknowledgmentsWe would like to thank our external reviewers for their valuable feedback throughout the writing process.},
booktitle = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice},
pages = {xv–xvi}
}

@article{10.14778/3236187.3236188,
author = {Mahajan, Divya and Kim, Joon Kyung and Sacks, Jacob and Ardalan, Adel and Kumar, Arun and Esmaeilzadeh, Hadi},
title = {In-RDBMS Hardware Acceleration of Advanced Analytics},
year = {2018},
issue_date = {July 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3236187.3236188},
doi = {10.14778/3236187.3236188},
abstract = {The data revolution is fueled by advances in machine learning, databases, and hardware design. Programmable accelerators are making their way into each of these areas independently. As such, there is a void of solutions that enables hardware acceleration at the intersection of these disjoint fields. This paper sets out to be the initial step towards a unifying solution for in-Database Acceleration of Advanced Analytics (DAnA). Deploying specialized hardware, such as FPGAs, for in-database analytics currently requires hand-designing the hardware and manually routing the data. Instead, DAnA automatically maps a high-level specification of advanced analytics queries to an FPGA accelerator. The accelerator implementation is generated for a User Defined Function (UDF), expressed as a part of an SQL query using a Python-embedded Domain-Specific Language (DSL). To realize an efficient in-database integration, DAnA accelerators contain a novel hardware structure, Striders, that directly interface with the buffer pool of the database. Striders extract, cleanse, and process the training data tuples that are consumed by a multi-threaded FPGA engine that executes the analytics algorithm. We integrate DAnA with PostgreSQL to generate hardware accelerators for a range of real-world and synthetic datasets running diverse ML algorithms. Results show that DAnA-enhanced PostgreSQL provides, on average, 8.3\texttimes{} end-to-end speedup for real datasets, with a maximum of 28.2\texttimes{}. Moreover, DAnA-enhanced PostgreSQL is, on average, 4.0\texttimes{} faster than the multi-threaded Apache MADLib running on Greenplum. DAnA provides these benefits while hiding the complexity of hardware design from data scientists and allowing them to express the algorithm in ≈30-60 lines of Python.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {1317–1331},
numpages = {15}
}

@inproceedings{10.1145/3461648.3463842,
author = {Poroor, Jayaraj and Lal, Akash and Ghanta, Sandesh},
title = {Robust I/O-Compute Concurrency for Machine Learning Pipelines in Constrained Cyber-Physical Devices},
year = {2021},
isbn = {9781450384728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461648.3463842},
doi = {10.1145/3461648.3463842},
abstract = {Cyberphysical systems have numerous industrial and commercial applications. Such systems are often built using low-resource devices that gather and process data, using machine-learning (ML) models, to make intelligent decisions and provide value to users. Programming such low-resource devices with an impoverished system runtime is often challenging. This paper presents a new domain-specific language called PiCon for programming ML pipelines in low-resource devices. PiCon allows safe I/O-compute concurrency, ruling out a large class of errors, while providing a simple and sequential coding abstraction to the programmer. PiCon compiles to C code and easily interfaces with existing C/C++ code. Furthermore, the generated code does not rely on multi-threading support or dynamic memory allocation, dramatically reducing its footprint on the device. We present experience porting two real-world ML applications that demonstrate simplification in programmability, in addition to several safe-by-construction guarantees.},
booktitle = {Proceedings of the 22nd ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems},
pages = {1–11},
numpages = {11},
keywords = {Cyberphysical systems, Constrained devices, Embedded systems, IoT, Machine Learning},
location = {Virtual, Canada},
series = {LCTES 2021}
}

@article{10.14778/3007263.3007279,
author = {Boehm, Matthias and Dusenberry, Michael W. and Eriksson, Deron and Evfimievski, Alexandre V. and Manshadi, Faraz Makari and Pansare, Niketan and Reinwald, Berthold and Reiss, Frederick R. and Sen, Prithviraj and Surve, Arvind C. and Tatikonda, Shirish},
title = {SystemML: Declarative Machine Learning on Spark},
year = {2016},
issue_date = {September 2016},
publisher = {VLDB Endowment},
volume = {9},
number = {13},
issn = {2150-8097},
url = {https://doi.org/10.14778/3007263.3007279},
doi = {10.14778/3007263.3007279},
abstract = {The rising need for custom machine learning (ML) algorithms and the growing data sizes that require the exploitation of distributed, data-parallel frameworks such as MapReduce or Spark, pose significant productivity challenges to data scientists. Apache SystemML addresses these challenges through declarative ML by (1) increasing the productivity of data scientists as they are able to express custom algorithms in a familiar domain-specific language covering linear algebra primitives and statistical functions, and (2) transparently running these ML algorithms on distributed, data-parallel frameworks by applying cost-based compilation techniques to generate efficient, low-level execution plans with in-memory single-node and large-scale distributed operations. This paper describes SystemML on Apache Spark, end to end, including insights into various optimizer and runtime techniques as well as performance characteristics. We also share lessons learned from porting SystemML to Spark and declarative ML in general. Finally, SystemML is open-source, which allows the database community to leverage it as a testbed for further research.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {1425–1436},
numpages = {12}
}

@inproceedings{10.1145/3468044.3468052,
author = {Podobas, Artur and Svedin, Martin and Chien, Steven W. D. and Peng, Ivy B. and Ravichandran, Naresh Balaji and Herman, Pawel and Lansner, Anders and Markidis, Stefano},
title = {StreamBrain: An HPC Framework for Brain-like Neural Networks on CPUs, GPUs and FPGAs},
year = {2021},
isbn = {9781450385497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468044.3468052},
doi = {10.1145/3468044.3468052},
abstract = {The modern deep learning method based on backpropagation has surged in popularity and has been used in multiple domains and application areas. At the same time, there are other - less-known - machine learning algorithms with a mature and solid theoretical foundation whose performance remains unexplored. One such example is the brain-like Bayesian Confidence Propagation Neural Network (BCPNN). In this paper, we introduce StreamBrain--a framework that allows neural networks based on BCPNN to be practically deployed in High-Performance Computing systems. StreamBrain is a domain-specific language (DSL), similar in concept to existing machine learning (ML) frameworks, and supports backends for CPUs, GPUs, and even FPGAs. We empirically demonstrate that StreamBrain can train the well-known ML benchmark dataset MNIST within seconds, and we are the first to demonstrate BCPNN on STL-10 size networks. We also show how StreamBrain can be used to train with custom floating-point formats and illustrate the impact of using different bfloat variations on BCPNN using FPGAs.},
booktitle = {Proceedings of the 11th International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
articleno = {8},
numpages = {6},
keywords = {Unsupervised learning, HPC, GPU, Neural networks, Emerging Machine Learning, AI, FPGA, BCPNN, Representation learning},
location = {Online, Germany},
series = {HEART '21}
}

@inproceedings{10.1145/3510458.3513012,
author = {Alves, Lucas and Pereira, Jos\'{e} Davi and Arag\~{a}o, Nat\'{a}lia and Chagas, Matheus and Maia, Paulo Henrique},
title = {DRESS-ML: A Domain-Specific Language for Modelling Exceptional Scenarios and Self-Adaptive Behaviours for Drone-Based Applications},
year = {2022},
isbn = {9781450392273},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510458.3513012},
doi = {10.1145/3510458.3513012},
abstract = {Drones are gaining attention due to its possibility to support wide different types of applications. Since they can operate in different environments, it is possible to encounter uncertainties and exceptional situations, not initially predicted, during the use of drone-based applications. In this realm, self-adaptive strategies have been successfully used to guarantee resilience and continuous execution of such applications despite environment changes. Although some modelling approaches emerged to represent drone concepts, they are limited to model only expected flight plans or include few environmental conditions and drone resources, which restrict considerably their use. To mitigate those problems, this work proposes a domain-specific language, called DRESS-ML, which allows modelling exceptional situations and self-adaptive behaviours for drone-based applications. It relies on the Given-When-Then template used in the Behaviour-driven development (BDD) technique and the some of the main Aspect-oriented Programming concepts. We validate the applicability of our language through a proof of concept regarding an example application that uses a drone to monitor a forest to search for fire spots.Drones are gaining attention due to their possibility of supporting diverse applications and environments, such as search-and-rescue, surveillance, and goods delivery. Due to this variety of applications, drones can face both uncertainties and exceptional situations that they did not initially foresee during flight plan. In this sense, providing the ability to monitor the system and its environment and to change the system to ensure resilience and continuous execution are benefits of self-adaptation strategies. Although some studies have proposed approaches to model drone concepts, they are limited to model only expected flight plans or include few environmental conditions and drone resources, which restrict considerably their use. This work proposes a domain-specific language, called DRESS-ML, which allows modelling exceptional scenarios and self-adaptive behaviors to mitigate those problems. The language is based on an well known structure used for specifying system behaviour and the main concepts of a programming paradigm that injects encapsulated behaviours in the system. A practical example that uses a drone to monitor a forest to search for fire spots is used to evaluate the proposed language, demonstrating its applicability to model various exceptional scenarios.},
booktitle = {Proceedings of the 2022 ACM/IEEE 44th International Conference on Software Engineering: Software Engineering in Society},
pages = {56–66},
numpages = {11},
keywords = {modelling language, exceptional scenarios, self-adaptive systems, drones},
location = {Pittsburgh, Pennsylvania},
series = {ICSE-SEIS '22}
}

@article{10.14778/3342263.3342633,
author = {Kunft, Andreas and Katsifodimos, Asterios and Schelter, Sebastian and Bre\ss{}, Sebastian and Rabl, Tilmann and Markl, Volker},
title = {An Intermediate Representation for Optimizing Machine Learning Pipelines},
year = {2019},
issue_date = {July 2019},
publisher = {VLDB Endowment},
volume = {12},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3342263.3342633},
doi = {10.14778/3342263.3342633},
abstract = {Machine learning (ML) pipelines for model training and validation typically include preprocessing, such as data cleaning and feature engineering, prior to training an ML model. Preprocessing combines relational algebra and user-defined functions (UDFs), while model training uses iterations and linear algebra. Current systems are tailored to either of the two. As a consequence, preprocessing and ML steps are optimized in isolation. To enable holistic optimization of ML training pipelines, we present Lara, a declarative domain-specific language for collections and matrices. Lara's inter-mediate representation (IR) reflects on the complete program, i.e., UDFs, control flow, and both data types. Two views on the IR enable diverse optimizations. Monads enable operator pushdown and fusion across type and loop boundaries. Combinators provide the semantics of domain-specific operators and optimize data access and cross-validation of ML algorithms. Our experiments on preprocessing pipelines and selected ML algorithms show the effects of our proposed optimizations on dense and sparse data, which achieve speedups of up to an order of magnitude.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {1553–1567},
numpages = {15}
}

@inproceedings{10.1145/3314221.3314597,
author = {Gopinath, Sridhar and Ghanathe, Nikhil and Seshadri, Vivek and Sharma, Rahul},
title = {Compiling KB-Sized Machine Learning Models to Tiny IoT Devices},
year = {2019},
isbn = {9781450367127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314221.3314597},
doi = {10.1145/3314221.3314597},
abstract = {Recent advances in machine learning (ML) have produced KiloByte-size models that can directly run on constrained IoT devices. This approach avoids expensive communication between IoT devices and the cloud, thereby enabling energy-efficient real-time analytics. However, ML models are expressed typically in floating-point, and IoT hardware typically does not support floating-point. Therefore, running these models on IoT devices requires simulating IEEE-754 floating-point using software, which is very inefficient. We present SeeDot, a domain-specific language to express ML inference algorithms and a compiler that compiles SeeDot programs to fixed-point code that can efficiently run on constrained IoT devices. We propose 1)&nbsp;a novel compilation strategy that reduces the search space for some key parameters used in the fixed-point code, and 2)&nbsp;new efficient implementations of expensive operations. SeeDot compiles state-of-the-art KB-sized models to various microcontrollers and low-end FPGAs. We show that SeeDot outperforms 1) software emulation of floating-point (Arduino), 2) high-bitwidth fixed-point (MATLAB), 3) post-training quantization (TensorFlow-Lite), and 4) floating- and fixed-point FPGA implementations generated using high-level synthesis tools.},
booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {79–95},
numpages = {17},
keywords = {Programming Language, Fixed-point, Compiler, FPGA, Microcontroller, Machine Learning, IoT device},
location = {Phoenix, AZ, USA},
series = {PLDI 2019}
}

@inproceedings{10.1145/1134285.1134311,
author = {Verbaere, Mathieu and Ettinger, Ran and de Moor, Oege},
title = {JunGL: A Scripting Language for Refactoring},
year = {2006},
isbn = {1595933751},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1134285.1134311},
doi = {10.1145/1134285.1134311},
abstract = {Refactorings are behaviour-preserving program transformations, typically for improving the structure of existing code. A few of these transformations have been mechanised in interactive development environments. Many more refactorings have been proposed, and it would be desirable for programmers to script their own refactorings. Implementing such source-to-source transformations, however, is quite complex: even the most sophisticated development environments contain significant bugs in their refactoring tools.We present a domain-specific language for refactoring, named JunGL. It manipulates a graph representation of the program: all information about the program, including ASTs for its compilation units, variable binding, control flow and so on is represented in a uniform graph format. The language is a hybrid of a functional language (in the style of ML) and a logic query language (akin to Datalog). JunGL furthermore has a notion of demand-driven evaluation for constructing computed information in the graph, such as control flow edges. Borrowing from earlier work on the specification of compiler optimisations, JunGL uses so-called `path queries' to express dataflow properties.We motivate the design of JunGL via a number of non-trivial refactorings, and describe its implementation on the.NET platform.},
booktitle = {Proceedings of the 28th International Conference on Software Engineering},
pages = {172–181},
numpages = {10},
keywords = {refactoring, source code transformation, language workbenches, scripting language},
location = {Shanghai, China},
series = {ICSE '06}
}

@article{10.14778/3236187.3236188,
author = {Mahajan, Divya and Kim, Joon Kyung and Sacks, Jacob and Ardalan, Adel and Kumar, Arun and Esmaeilzadeh, Hadi},
title = {In-RDBMS Hardware Acceleration of Advanced Analytics},
year = {2018},
issue_date = {July 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3236187.3236188},
doi = {10.14778/3236187.3236188},
abstract = {The data revolution is fueled by advances in machine learning, databases, and hardware design. Programmable accelerators are making their way into each of these areas independently. As such, there is a void of solutions that enables hardware acceleration at the intersection of these disjoint fields. This paper sets out to be the initial step towards a unifying solution for in-Database Acceleration of Advanced Analytics (DAnA). Deploying specialized hardware, such as FPGAs, for in-database analytics currently requires hand-designing the hardware and manually routing the data. Instead, DAnA automatically maps a high-level specification of advanced analytics queries to an FPGA accelerator. The accelerator implementation is generated for a User Defined Function (UDF), expressed as a part of an SQL query using a Python-embedded Domain-Specific Language (DSL). To realize an efficient in-database integration, DAnA accelerators contain a novel hardware structure, Striders, that directly interface with the buffer pool of the database. Striders extract, cleanse, and process the training data tuples that are consumed by a multi-threaded FPGA engine that executes the analytics algorithm. We integrate DAnA with PostgreSQL to generate hardware accelerators for a range of real-world and synthetic datasets running diverse ML algorithms. Results show that DAnA-enhanced PostgreSQL provides, on average, 8.3\texttimes{} end-to-end speedup for real datasets, with a maximum of 28.2\texttimes{}. Moreover, DAnA-enhanced PostgreSQL is, on average, 4.0\texttimes{} faster than the multi-threaded Apache MADLib running on Greenplum. DAnA provides these benefits while hiding the complexity of hardware design from data scientists and allowing them to express the algorithm in ≈30-60 lines of Python.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {1317–1331},
numpages = {15}
}

@inbook{10.1145/3447404.3447405,
title = {Preface},
year = {2021},
isbn = {9781450390293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
url = {https://doi.org/10.1145/3447404.3447405},
abstract = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice provides a comprehensive resource on what has become the dominant paradigm for novel interaction design methods involving gesture, speech, text, and touch embedded in novel and emerging interfaces. These interfaces support smartphones, wearables, in-vehicle devices, virtual reality, robotic, the Internet of Things (IoT), brain–computer interaction, and many other applications that are now highly competitive commercially.This edited collection is written by international experts and pioneers in the field of digital signal processing (DSP) and machine learning (ML) for interactive systems. It provides a textbook for students, and a reference and technology roadmap for developers and professionals working in interaction design on emerging platforms. This introductory textbook presents theory chapters on statistical grounding, signal processing, and ML foundations for guiding the development of novel interactive systems. Additional chapters discuss case studies on smart cities, brain–computer interfaces (BCI), probabilistic text entry, secure gestures, personal context from mobile phones, building adaptive touch interfaces, and automotive user interfaces (UIs). The chapters on case studies also highlight an in-depth look at domain-specific language (DSL) and ML methods used, for example, in touch, gesture, electroencephalography (EEG), electrocardiography (ECG), and galvanic skin response (GSR) signals, or embedded sensor inputs. A common theme throughout is the ubiquitous support for humans as they go about their daily professional or personal activities.This introductory book provides walk-through examples of different DSP and ML techniques and their use in interactive systems. Common terms are defined, and information on practical resources is provided (e.g., software tools, data resources) for hands-on project work to develop and evaluate multimodal–multisensor systems. After each chapter an expert on the legal and ethical issues explores the wider ethical issues on how DSP and ML should be adopted and used in socially appropriate ways, to most effectively advance human performance during interaction with novel platforms.Parisa Eslambolchilar, Andreas Komninos, and Mark D. Dunlop, March 2020AcknowledgmentsWe would like to thank our external reviewers for their valuable feedback throughout the writing process.},
booktitle = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice},
pages = {xv–xvi}
}

@inproceedings{10.1145/3123939.3123979,
author = {Park, Jongse and Sharma, Hardik and Mahajan, Divya and Kim, Joon Kyung and Olds, Preston and Esmaeilzadeh, Hadi},
title = {Scale-out Acceleration for Machine Learning},
year = {2017},
isbn = {9781450349529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123939.3123979},
doi = {10.1145/3123939.3123979},
abstract = {The growing scale and complexity of Machine Learning (ML) algorithms has resulted in prevalent use of distributed general-purpose systems. In a rather disjoint effort, the community is focusing mostly on high performance single-node accelerators for learning. This work bridges these two paradigms and offers CoSMIC, a full computing stack constituting language, compiler, system software, template architecture, and circuit generators, that enable programmable acceleration of learning at scale. CoSMIC enables programmers to exploit scale-out acceleration using FPGAs and Programmable ASICs (P-ASICs) from a high-level and mathematical Domain-Specific Language (DSL). Nonetheless, CoSMIC does not require programmers to delve into the onerous task of system software development or hardware design. CoSMIC achieves three conflicting objectives of efficiency, automation, and programmability, by integrating a novel multi-threaded template accelerator architecture and a cohesive stack that generates the hardware and software code from its high-level DSL. CoSMIC can accelerate a wide range of learning algorithms that are most commonly trained using parallel variants of gradient descent. The key is to distribute partial gradient calculations of the learning algorithms across the accelerator-augmented nodes of the scale-out system. Additionally, CoSMIC leverages the parallelizability of the algorithms to offer multi-threaded acceleration within each node. Multi-threading allows CoSMIC to efficiently exploit the numerous resources that are becoming available on modern FPGAs/P-ASICs by striking a balance between multi-threaded parallelism and single-threaded performance. CoSMIC takes advantage of algorithmic properties of ML to offer a specialized system software that optimizes task allocation, role-assignment, thread management, and internode communication. We evaluate the versatility and efficiency of CoSMIC for 10 different machine learning applications from various domains. On average, a 16-node CoSMIC with UltraScale+ FPGAs offers 18.8\texttimes{} speedup over a 16-node Spark system with Xeon processors while the programmer only writes 22--55 lines of code. CoSMIC offers higher scalability compared to the state-of-the-art Spark; scaling from 4 to 16 nodes with CoSMIC yields 2.7\texttimes{} improvements whereas Spark offers 1.8\texttimes{}. These results confirm that the full-stack approach of CoSMIC takes an effective and vital step towards enabling scale-out acceleration for machine learning.},
booktitle = {Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {367–381},
numpages = {15},
keywords = {cloud, machine learning, accelerator, distributed, scale-out},
location = {Cambridge, Massachusetts},
series = {MICRO-50 '17}
}

@article{10.1145/1255456.1255470,
author = {Mathaikutty, Deepak and Patel, Hiren and Shukla, Sandeep and Jantsch, Axel},
title = {EWD: A Metamodeling Driven Customizable Multi-MoC System Modeling Framework},
year = {2008},
issue_date = {August 2007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {12},
number = {3},
issn = {1084-4309},
url = {https://doi.org/10.1145/1255456.1255470},
doi = {10.1145/1255456.1255470},
abstract = {We present the EWD design environment and methodology, a modeling and simulation framework suited for complex and heterogeneous embedded systems with varying degrees of expressibility and modeling fidelity. This environment promotes the use of multiple models of computation (MoCs) to support heterogeneity and metamodeling for conformance tests of syntactic and static semantics during the process of modeling. Therefore, EWD is a multiple MoC modeling and simulation framework that ensures conformance of the MoC formalisms during model construction using a metamodeling approach. In addition, EWD provides a suite of translation tools that generate executable models for two simulation frameworks to demonstrate its language-independent modeling framework. The EWD methodology uses the Generic Modeling Environment for customization of the MoC-specific modeling syntax into a visual representation. To embed the execution semantics of the MoCs into the models, we have built parsing and translation tools that leverage an XML-based interoperability language. This interoperability language is then translated into executable Standard ML or Haskell models that can also be analyzed by existing simulation frameworks such as SML-Sys or ForSyDe. In summary, EWD is a metamodeling driven multitarget design environment with multi-MoC modeling capability.},
journal = {ACM Trans. Des. Autom. Electron. Syst.},
month = {may},
articleno = {33},
numpages = {43},
keywords = {SystemC, Metamodeling, ForSyDe, heterogeneous system design, functional language, metamodel, MoC, interoperable modeling language, denotational semantics, Ptolemy II}
}@inproceedings{10.1145/3550356.3561576,
author = {Kirchhof, J\"{o}rg Christian and Kusmenko, Evgeny and Ritz, Jonas and Rumpe, Bernhard and Moin, Armin and Badii, Atta and G\"{u}nnemann, Stephan and Challenger, Moharram},
title = {MDE for Machine Learning-Enabled Software Systems: A Case Study and Comparison of MontiAnna &amp; ML-Quadrat},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561576},
doi = {10.1145/3550356.3561576},
abstract = {In this paper, we propose to adopt the MDE paradigm for the development of Machine Learning (ML)-enabled software systems with a focus on the Internet of Things (IoT) domain. We illustrate how two state-of-the-art open-source modeling tools, namely MontiAnna and ML-Quadrat can be used for this purpose as demonstrated through a case study. The case study illustrates using ML, in particular deep Artificial Neural Networks (ANNs), for automated image recognition of handwritten digits using the MNIST reference dataset, and integrating the machine learning components into an IoT-system. Subsequently, we conduct a functional comparison of the two frameworks, setting out an analysis base to include a broad range of design considerations, such as the problem domain, methods for the ML integration into larger systems, and supported ML methods, as well as topics of recent intense interest to the ML community, such as AutoML and MLOps. Accordingly, this paper is focused on elucidating the potential of the MDE approach in the ML domain. This supports the ML-engineer in developing the (ML/software) model rather than implementing the code, and additionally enforces reusability and modularity of the design through enabling the out-of-the-box integration of ML functionality as a component of the IoT or cyber-physical systems.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {380–387},
numpages = {8},
keywords = {machine learning, domain specific modeling, tools, artificial intelligence, model-driven engineering},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3550356.3559096,
author = {L\'{o}pez, Jos\'{e} Antonio Hern\'{a}ndez and Izquierdo, Javier Luis C\'{a}novas and Cuadrado, Jes\'{u}s S\'{a}nchez},
title = {Using the ModelSet Dataset to Support Machine Learning in Model-Driven Engineering},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3559096},
doi = {10.1145/3550356.3559096},
abstract = {The availability of curated collections of models is essential for the application of techniques like Machine Learning (ML) and Data Analytics to MDE as well as to boost research activities. However, many applications of ML to address MDE tasks are currently limited to small datasets. In this demo paper, we will present ModelSet, a dataset composed of 5,466 Ecore models and 5,120 UML models which have been manually labelled to support ML tasks (http://modelset.github.io). ModelSet is built upon the models collected by the MAR search engine (http://mar-search.org), which provides more than 500,000 models of different types. We will describe the structure of the dataset and we will explain how to use the associated library to develop ML applications in Python. Finally, we will describe some applications which can be addressed using ModelSet.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {66–70},
numpages = {5},
keywords = {model-driven engineering, model classification, machine learning},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1109/ICSE-NIER.2019.00014,
author = {Stephan, Matthew},
title = {Towards a Cognizant Virtual Software Modeling Assistant Using Model Clones},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER.2019.00014},
doi = {10.1109/ICSE-NIER.2019.00014},
abstract = {We present our new ideas on taking the first steps towards cultivating synergy between model-driven engineering (MDE), machine learning, and software clones. Specifically, we describe our vision in realizing a cognizant virtual software modeling assistant that uses the latter two to improve software design and MDE. Software engineering has benefited greatly from knowledge-based cognizant source code completion and assistance, but MDE has few and limited analogous capabilities. We outline our research directions by describing our vision for a prototype assistant that provides suggestions to modelers performing model creation or extension in the form of 1) complete models for insertion or guidance, and 2) granular single-step operations. These suggestions are derived by detecting clones of the in-progress model and existing domain, organizational, and exemplar models. We overview our envisioned workflow between modeler and assistant, and, using Simulink as an example, illustrate different manifestations including multiple overlays with percentages and employing variant elements.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {21–24},
numpages = {4},
keywords = {model driven engineering, model clones, software modeling, model clone detection, machine learning},
location = {Montreal, Quebec, Canada},
series = {ICSE-NIER '19}
}

@inproceedings{10.1145/3510454.3528639,
author = {Lano, K.},
title = {Program Translation Using Model-Driven Engineering},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3528639},
doi = {10.1145/3510454.3528639},
abstract = {The porting or translation of software applications from one programming language to another is a common requirement of organisations that utilise software, and the increasing number and diversity of programming languages makes this capability as relevant today as in previous decades.Several approaches have been used to address this challenge, including machine learning and the manual definition of explicit translation rules. We define a novel approach using model-driven engineering (MDE) techniques: reverse-engineering source programs into specifications in the UML and OCL formalisms, and then forward-engineering the specifications to the required target language. This approach has the additional advantage of extracting specifications of software from code. We provide an evaluation based on a comprehensive dataset of examples, including industrial cases, and compare our results to those of other approaches and tools.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {362–363},
numpages = {2},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3531146.3533236,
author = {Grabowicz, Przemyslaw A. and Perello, Nicholas and Mishra, Aarshee},
title = {Marrying Fairness and Explainability in Supervised Learning},
year = {2022},
isbn = {9781450393522},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3531146.3533236},
doi = {10.1145/3531146.3533236},
abstract = {Machine learning algorithms that aid human decision-making may inadvertently discriminate against certain protected groups. Therefore, we formalize direct discrimination as a direct causal effect of the protected attributes on the decisions, while induced discrimination as a change in the causal influence of non-protected features associated with the protected attributes. The measurements of marginal direct effect (MDE) and SHapley Additive exPlanations (SHAP) reveal that state-of-the-art fair learning methods can induce discrimination via association or reverse discrimination in synthetic and real-world datasets. To inhibit discrimination in algorithmic systems, we propose to nullify the influence of the protected attribute on the output of the system, while preserving the influence of remaining features. We introduce and study post-processing methods achieving such objectives, finding that they yield relatively high model accuracy, prevent direct discrimination, and diminishes various disparity measures, e.g., demographic disparity.},
booktitle = {2022 ACM Conference on Fairness, Accountability, and Transparency},
pages = {1905–1916},
numpages = {12},
keywords = {discrimination, algorithmic fairness, machine learning, supervised learning, explainability},
location = {Seoul, Republic of Korea},
series = {FAccT '22}
}

@inproceedings{10.1145/3417990.3418742,
author = {Boubekeur, Younes and Mussbacher, Gunter},
title = {Towards a Better Understanding of Interactions with a Domain Modeling Assistant},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3418742},
doi = {10.1145/3417990.3418742},
abstract = {The enrolment of software engineering students has increased rapidly in the past few years following industry demand. At the same time, model-driven engineering (MDE) continues to become relevant to more domains like embedded systems and machine learning. It is therefore important to teach students MDE skills in an effective manner to prepare them for future careers in academia and industry. The use of interactive online tools can help instructors deliver course material to more students in a more efficient manner, allowing them to offload repetitive or tedious tasks to these systems and focus on other teaching activities that cannot be easily automated. Interactive online tools can provide students with a more engaging learning experience than static resources like books or written exercises. Domain modeling with class diagrams is a fundamental modeling activity in MDE. While there exist multiple modeling tools that allow students to build a domain model, none of them offer an interactive learning experience. In this paper, we explore the interactions between a student modeler and an interactive domain modeling assistant with the aim of better understanding the required interaction. We illustrate desired interactions with three examples and then formalize them in a metamodel. Based on the metamodel, we explain how to form a corpus of learning material that supports the assistant interactions.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {21},
numpages = {10},
keywords = {feedback, domain model, chatbot, class diagram, learning corpus},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@article{10.1145/3550289,
author = {Cho, Hyunsung and Mathur, Akhil and Kawsar, Fahim},
title = {FLAME: Federated Learning across Multi-Device Environments},
year = {2022},
issue_date = {September 2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {6},
number = {3},
url = {https://doi.org/10.1145/3550289},
doi = {10.1145/3550289},
abstract = {Federated Learning (FL) enables distributed training of machine learning models while keeping personal data on user devices private. While we witness increasing applications of FL in the area of mobile sensing, such as human activity recognition (HAR), FL has not been studied in the context of a multi-device environment (MDE), wherein each user owns multiple data-producing devices. With the proliferation of mobile and wearable devices, MDEs are increasingly becoming popular in ubicomp settings, therefore necessitating the study of FL in them. FL in MDEs is characterized by being not independent and identically distributed (non-IID) across clients, complicated by the presence of both user and device heterogeneities. Further, ensuring efficient utilization of system resources on FL clients in a MDE remains an important challenge. In this paper, we propose FLAME, a user-centered FL training approach to counter statistical and system heterogeneity in MDEs, and bring consistency in inference performance across devices. FLAME features (i) user-centered FL training utilizing the time alignment across devices from the same user; (ii) accuracy- and efficiency-aware device selection; and (iii) model personalization to devices. We also present an FL evaluation testbed with realistic energy drain and network bandwidth profiles, and a novel class-based data partitioning scheme to extend existing HAR datasets to a federated setup. Our experiment results on three multi-device HAR datasets show that FLAME outperforms various baselines by 4.3-25.8% higher F1 score, 1.02-2.86x greater energy efficiency, and up to 2.06x speedup in convergence to target accuracy through fair distribution of the FL workload.},
journal = {Proc. ACM Interact. Mob. Wearable Ubiquitous Technol.},
month = {sep},
articleno = {107},
numpages = {29},
keywords = {Federated Learning, Human Activity Recognition}
}

@inproceedings{10.1109/MODELS-C.2019.00028,
author = {Burgue\~{n}o, Loli and Burdusel, Alexandru and G\'{e}rard, S\'{e}bastien and Wimmer, Manuel},
title = {MDE Intelligence 2019: 1st Workshop on Artificial Intelligence and Model-Driven Engineering},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00028},
doi = {10.1109/MODELS-C.2019.00028},
abstract = {Model-driven engineering (MDE) and Artificial Intelligence (AI) are two separate fields in computer science, which can clearly benefit from cross-fertilization and collaboration. There are at least two ways in which such integrations---which we call MDE Intelligence---can manifest: (1) MDE can benefit from integrating AI concepts and ideas to increasing the power and flexibility of model-driven techniques by means of the application of AI algorithms. (2) Conversely, AI can benefit from integrating concepts and ideas from MDE---for example, using domain-specific languages and model transformations allows domain experts to directly express and manipulate their problems while providing an auditable computation pipeline.To discuss and further stimulate such integrations, the 1st edition of the Workshop on Artificial Intelligence and Model-driven Engineering (MDE Intelligence) was held on September 16, 2019 in Munich, Germany, as part of the satellite events of the IEEE/ACM 22th International Conference on Model-Driven Engineering Languages and Systems (MODELS 2019).},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {168–169},
numpages = {2},
keywords = {artificial intelligence, MDE intelligence, MDE},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1145/1988051.1988065,
author = {M\"{u}lders, Peter and Gruner, Stefan and Thang, Nguyen Xuan},
title = {Model-Driven Design plus Artificial Intelligence for Wireless Sensor Networks Software Development},
year = {2011},
isbn = {9781450305839},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1988051.1988065},
doi = {10.1145/1988051.1988065},
abstract = {To date, software development for wireless sensor network nodes is still characterized by low-level ad-hoc programming to a large extent. This short-paper argues for a methodologically more systematic approach on the basis of Model-Driven Engineering with CASE-Tool support, in combination with AI-based design choice optimizations during the MDE-steps of model-refinement and information-enrichment. Our work in this project is ongoing.},
booktitle = {Proceedings of the 2nd Workshop on Software Engineering for Sensor Network Applications},
pages = {63–64},
numpages = {2},
keywords = {development methodology, case-tool support, wireless sensor networks, genetic algorithms, model-driven engineering},
location = {Waikiki, Honolulu, HI, USA},
series = {SESENA '11}
}

@inproceedings{10.5555/3400397.3400521,
author = {Benaben, Frederick and Lauras, Matthieu and Fertier, Audrey and Salatg\'{e}, Nicolas},
title = {Integrating Model-Driven Engineering as the next Challenge for Artificial Intelligence: Application to Risk and Crisis Management},
year = {2020},
isbn = {9781728132839},
publisher = {IEEE Press},
abstract = {Artificial Intelligence (AI) is currently on top of the hype regarding simultaneously research publications and industrial development. However, the current status of AI makes it quite far and different from the current understanding of Human intelligence. One suggestion that is made in this article is that Model-Driven approaches could be considered as an interesting avenue to complement classical visions of AI and to provide some missing features. Specifically, the use of Model-Driven Engineering tools (such as metamodel and model transformation) could benefit to the domain of AI by introducing a way to extend the apprehension of unknown situations. To support that proposal, an illustrative example is provided regarding the domain of risk and crisis management.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {1549–1563},
numpages = {15},
location = {National Harbor, Maryland},
series = {WSC '19}
}

@inproceedings{10.1145/3550356.3561609,
author = {Bergelin, Johan and Strandberg, Per Erik},
title = {Industrial Requirements for Supporting AI-Enhanced Model-Driven Engineering},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561609},
doi = {10.1145/3550356.3561609},
abstract = {There is an increasing interest in research on the combination of AI techniques and methods with MDE. However, there is a gap between AI and MDE practices, as well as between researchers and practitioners. This paper tackles this gap by reporting on industrial requirements in this field. In the AIDOaRt research project, practitioners and researchers collaborate on AI-augmented automation supporting modeling, coding, testing, monitoring, and continuous development in cyber-physical systems. The project specifically lies at the intersection of industry and academia collaboration with several industrial use cases. Through a process of elicitation and refinement, 78 high-level requirements were defined, and generalized into 30 generic requirements by the AIDOaRt partners. The main contribution of this paper is the set of generic requirements from the project for enhancing the development of cyber-physical systems with artificial intelligence, DevOps, and model-driven engineering, identifying the hot spots of industry needs in the interactions of MDE and AI. Future work will refine, implement and evaluate solutions toward these requirements in industry contexts.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {375–379},
numpages = {5},
keywords = {cyber-physical systems, requirements, model-driven engineering, artificial intelligence},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.5555/2008503.2008556,
author = {Lortal, Ga\"{e}lle and Dhouib, Saadia and G\'{e}rard, S\'{e}bastien},
title = {Integrating Ontological Domain Knowledge into a Robotic DSL},
year = {2010},
isbn = {9783642212093},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Coming from the Artificial Intelligence (AI) and Semantic Web (SW) circles, ontologies are used mainly to represent domains. The Model Driven Engineering (MDE) field gave birth to Domain Specific Languages to represent a particular technical domain. Abstracting from their uses, we consider as many others researchers that ontologies and models are closer than their original fields could get to think. Furthermore, their building or development are facing the same problems. They are costly and need experts' interviews in order to grasp specific knowledge and structure it. Likewise, ontologies and DSL can benefit from each other domains in reusing construction methodologies and even reusing knowledge modelled in another format. In this paper we first present the ontologies and DSL definition we use and some methodologies of development enabling the reuse of knowledge (as alignment, fusion). We then present how we propose to reuse the knowledge of a robotic ontology to develop robotic DSLs within the PROTEUS project in order to inject readymade domain information to the DSL.},
booktitle = {Proceedings of the 2010 International Conference on Models in Software Engineering},
pages = {401–414},
numpages = {14},
location = {Oslo, Norway},
series = {MODELS'10}
}

@inproceedings{10.1145/2970276.2975938,
author = {Babur, \"{O}nder},
title = {Statistical Analysis of Large Sets of Models},
year = {2016},
isbn = {9781450338455},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2970276.2975938},
doi = {10.1145/2970276.2975938},
abstract = {Many applications in Model-Driven Engineering involve processing multiple models, e.g. for comparing and merging of model variants into a common domain model. Despite many sophisticated techniques for model comparison, little attention has been given to the initial data analysis and filtering activities. These are hard to ignore especially in the case of a large dataset, possibly with outliers and sub-groupings. We would like to develop a generic approach for model comparison and analysis for large datasets; using techniques from information retrieval, natural language processing and machine learning. We are implementing our approach as an open framework and have so far evaluated it on public datasets involving domain analysis, repository management and model searching scenarios.},
booktitle = {Proceedings of the 31st IEEE/ACM International Conference on Automated Software Engineering},
pages = {888–891},
numpages = {4},
keywords = {clustering, model comparison, vector space model, Model-driven engineering},
location = {Singapore, Singapore},
series = {ASE 2016}
}

@inproceedings{10.1145/3417990.3418741,
author = {Boubekeur, Younes and Mussbacher, Gunter and McIntosh, Shane},
title = {Automatic Assessment of Students' Software Models Using a Simple Heuristic and Machine Learning},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3418741},
doi = {10.1145/3417990.3418741},
abstract = {Software models are increasingly popular. To educate the next generation of software engineers, it is important that they learn how to model software systems well, so that they can design them effectively in industry. It is also important that instructors have the tools that can help them assess students' models more effectively. In this paper, we investigate how a tool that combines a simple heuristic with machine learning techniques can be used to help assess student submissions in model-driven engineering courses. We apply our proposed technique to first identify submissions of high quality and second to predict approximate letter grades. The results are comparable to human grading and a complex rule-based technique for the former and surprisingly accurate for the latter.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {20},
numpages = {10},
keywords = {domain modeling, heuristics, assessment, grading, Umple},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3510454.3528639,
author = {Lano, K.},
title = {Program Translation Using Model-Driven Engineering},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3528639},
doi = {10.1145/3510454.3528639},
abstract = {The porting or translation of software applications from one programming language to another is a common requirement of organisations that utilise software, and the increasing number and diversity of programming languages makes this capability as relevant today as in previous decades.Several approaches have been used to address this challenge, including machine learning and the manual definition of explicit translation rules. We define a novel approach using model-driven engineering (MDE) techniques: reverse-engineering source programs into specifications in the UML and OCL formalisms, and then forward-engineering the specifications to the required target language. This approach has the additional advantage of extracting specifications of software from code. We provide an evaluation based on a comprehensive dataset of examples, including industrial cases, and compare our results to those of other approaches and tools.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {362–363},
numpages = {2},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1109/ICSE-NIER.2019.00014,
author = {Stephan, Matthew},
title = {Towards a Cognizant Virtual Software Modeling Assistant Using Model Clones},
year = {2019},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ICSE-NIER.2019.00014},
doi = {10.1109/ICSE-NIER.2019.00014},
abstract = {We present our new ideas on taking the first steps towards cultivating synergy between model-driven engineering (MDE), machine learning, and software clones. Specifically, we describe our vision in realizing a cognizant virtual software modeling assistant that uses the latter two to improve software design and MDE. Software engineering has benefited greatly from knowledge-based cognizant source code completion and assistance, but MDE has few and limited analogous capabilities. We outline our research directions by describing our vision for a prototype assistant that provides suggestions to modelers performing model creation or extension in the form of 1) complete models for insertion or guidance, and 2) granular single-step operations. These suggestions are derived by detecting clones of the in-progress model and existing domain, organizational, and exemplar models. We overview our envisioned workflow between modeler and assistant, and, using Simulink as an example, illustrate different manifestations including multiple overlays with percentages and employing variant elements.},
booktitle = {Proceedings of the 41st International Conference on Software Engineering: New Ideas and Emerging Results},
pages = {21–24},
numpages = {4},
keywords = {model driven engineering, model clones, software modeling, model clone detection, machine learning},
location = {Montreal, Quebec, Canada},
series = {ICSE-NIER '19}
}

@inproceedings{10.1145/3510454.3517067,
author = {d'Aloisio, Giordano},
title = {Quality-Driven Machine Learning-Based Data Science Pipeline Realization: A Software Engineering Approach},
year = {2022},
isbn = {9781450392235},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3510454.3517067},
doi = {10.1145/3510454.3517067},
abstract = {The recently wide adoption of data science approaches to decision making in several application domains (such as health, business and even education) open new challenges in engineering and implementation of this systems. Considering the big picture of data science, Machine learning is the wider used technique and due to its characteristics, we believe that a better engineering methodology and tools are needed to realize innovative data-driven systems able to satisfy the emerging quality attributes (such as, debias and fariness, explainability, privacy and ethics, sustainability). This research project will explore the following three pillars: i) identify key quality attributes, formalize them in the context of data science pipelines and study their relationships; ii) define a new software engineering approach for data-science systems development that assures compliance with quality requirements; iii) implement tools that guide IT professionals and researchers in the realization of ML-based data science pipelines since the requirement engineering. Moreover, in this paper we also presents some details of the project showing how the feature models and model-driven engineering can be leveraged to realize our project.},
booktitle = {Proceedings of the ACM/IEEE 44th International Conference on Software Engineering: Companion Proceedings},
pages = {291–293},
numpages = {3},
keywords = {machine learning, product-line architecture, pipelines, software quality, model-driven},
location = {Pittsburgh, Pennsylvania},
series = {ICSE '22}
}

@inproceedings{10.1145/3417990.3418742,
author = {Boubekeur, Younes and Mussbacher, Gunter},
title = {Towards a Better Understanding of Interactions with a Domain Modeling Assistant},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3418742},
doi = {10.1145/3417990.3418742},
abstract = {The enrolment of software engineering students has increased rapidly in the past few years following industry demand. At the same time, model-driven engineering (MDE) continues to become relevant to more domains like embedded systems and machine learning. It is therefore important to teach students MDE skills in an effective manner to prepare them for future careers in academia and industry. The use of interactive online tools can help instructors deliver course material to more students in a more efficient manner, allowing them to offload repetitive or tedious tasks to these systems and focus on other teaching activities that cannot be easily automated. Interactive online tools can provide students with a more engaging learning experience than static resources like books or written exercises. Domain modeling with class diagrams is a fundamental modeling activity in MDE. While there exist multiple modeling tools that allow students to build a domain model, none of them offer an interactive learning experience. In this paper, we explore the interactions between a student modeler and an interactive domain modeling assistant with the aim of better understanding the required interaction. We illustrate desired interactions with three examples and then formalize them in a metamodel. Based on the metamodel, we explain how to form a corpus of learning material that supports the assistant interactions.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {21},
numpages = {10},
keywords = {feedback, domain model, chatbot, class diagram, learning corpus},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1109/MODELS.2017.32,
author = {Hartmann, Thomas and Moawad, Assaad and Fouquet, Francois and Traon, Yves Le},
title = {The next Evolution of MDE: A Seamless Integration of Machine Learning into Domain Modeling},
year = {2017},
isbn = {9781538634929},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS.2017.32},
doi = {10.1109/MODELS.2017.32},
abstract = {Advances in software and sensors have led to a new generation of systems which can help to minimize human intervention in critical infrastructures, like the power grid. However, they have mainly been designed to face predictable situations, in order to react, for example, to a critical overload. This is called known domain knowledge. However, such systems have also to face events that are unpredictable at design time. For instance, the electric consumption of a house depends on the number of persons living there, their activities, weather conditions, used devices, and so forth. Despite such behaviour is unpredictable at design time, it is identifiable and a hypothesis about it can be already formulated and solved later by observing past situations, once data becomes available. Sutcliffe et al., [1] suggest to call this known unknown.Machine learning algorithms are designed to resolve these unknowns, using fine- or coarse-grained learning. Coarse-grained learning means extracting the average behaviour of a large dataset. Conversely, fine-grained learning means specializing learning algorithms only on specific elements. In cases where datasets are composed of independent and het-erogenous entities, which behave very differently, finding one coarse-grained common behaviour can be difficult or even inappropriate. For example, considering smart grids, the daily consumption of a factory follows a very different pattern than the consumption of an apartment. Thus, coarse-grained learning alone, which is based on the "law of large numbers", can be inaccurate for such systems. Additionally, any data changes requires the whole learning process to be recomputed. Instead, following a divide and conquer strategy, learning on finer granularities can be considerably more efficient [2], [3]. In accordance to the pedagogical concept [4], we refer to small fine-grained learning units as "micro learning".However, applying micro learning on systems, such as the electric grid, can potentially lead to many fine-grained learning units, that need to be combined and synchronised with domain data. Learning frameworks like TensorFlow focus solely on the learning flow without any relation to the domain model. Consequently, domain data and its structure is expressed in different models than learning tasks, using different languages and tools. This leads to a separation of domain data, knowledge, known unknowns, and associated learning methods. Therefore, an appropriate structure to model learning units and their relationships to domain knowledge is required. To tame such complexity, we propose to weave micro machine learning seamlessly into data modeling. Specifically, our approach aims at: (1) Structuring complex learning tasks with reusable, chainable, and independently computable micro learning units. (2) Seamlessly integrating behavioural models which are known at design time, behavioural models that need to be learned at runtime, and domain models using common modeling concepts. (3) Automating the mapping between the mathematical representation expected by a specific machine learning algorithm and the domain representation [5] and independently updating micro learning units to be fast enough for online learning.As a natural extension of model-driven engineering approaches, we take advantage of relationships between domain data and behavioural elements (learned or known at design time) to implicitly define a fine-grained mapping of learning units and domain data. We implemented and integrated our approach into the open-source modeling framework GreyCat, which is specifically designed for the requirements of CPSs and IoT. We evaluate our approach on a concrete smart grid case study and show that: (1) Micro machine learning for such scenarios can be more accurate than coarse-grained learning (2) Performance is fast enough to be used for real-time analytics. The full paper has been published in [6].},
booktitle = {Proceedings of the ACM/IEEE 20th International Conference on Model Driven Engineering Languages and Systems},
pages = {180},
numpages = {1},
keywords = {live learning, domain modeling, model-driven engineering, meta modeling, cyber-physical systems, smart grids},
location = {Austin, Texas},
series = {MODELS '17}
}

@inproceedings{10.1145/2371401.2371417,
author = {Bauer, Tim and Erwig, Martin and Fern, Alan and Pinto, Jervis},
title = {Faster Program Adaptation through Reward Attribution Inference},
year = {2012},
isbn = {9781450311298},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371401.2371417},
doi = {10.1145/2371401.2371417},
abstract = {In the adaptation-based programming (ABP) paradigm, programs may contain variable parts (function calls, parameter values, etc.) that can be take a number of different values. Programs also contain reward statements with which a programmer can provide feedback about how well a program is performing with respect to achieving its goals (for example, achieving a high score on some scale). By repeatedly running the program, a machine learning component will, guided by the rewards, gradually adjust the automatic choices made in the variable program parts so that they converge toward an optimal strategy.ABP is a method for semi-automatic program generation in which the choices and rewards offered by programmers allow standard machine-learning techniques to explore a design space defined by the programmer to find an optimal instance of a program template. ABP effectively provides a DSL that allows non-machine-learning experts to exploit machine learning to generate self-optimizing programs.Unfortunately, in many cases the placement and structuring of choices and rewards can have a detrimental effect on how an optimal solution to a program-generation problem can be found. To address this problem, we have developed a dataflow analysis that computes influence tracks of choices and rewards. This information can be exploited by an augmented machine-learning technique to ignore misleading rewards and to generally attribute rewards better to the choices that have actually influenced them. Moreover, this technique allows us to detect errors in the adaptive program that might arise out of program maintenance. Our evaluation shows that the dataflow analysis can lead to improvements in performance.},
booktitle = {Proceedings of the 11th International Conference on Generative Programming and Component Engineering},
pages = {103–111},
numpages = {9},
keywords = {reinforcement learning, partial programming, program adaptation},
location = {Dresden, Germany},
series = {GPCE '12}
}

@article{10.1145/2480361.2371417,
author = {Bauer, Tim and Erwig, Martin and Fern, Alan and Pinto, Jervis},
title = {Faster Program Adaptation through Reward Attribution Inference},
year = {2012},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0362-1340},
url = {https://doi.org/10.1145/2480361.2371417},
doi = {10.1145/2480361.2371417},
abstract = {In the adaptation-based programming (ABP) paradigm, programs may contain variable parts (function calls, parameter values, etc.) that can be take a number of different values. Programs also contain reward statements with which a programmer can provide feedback about how well a program is performing with respect to achieving its goals (for example, achieving a high score on some scale). By repeatedly running the program, a machine learning component will, guided by the rewards, gradually adjust the automatic choices made in the variable program parts so that they converge toward an optimal strategy.ABP is a method for semi-automatic program generation in which the choices and rewards offered by programmers allow standard machine-learning techniques to explore a design space defined by the programmer to find an optimal instance of a program template. ABP effectively provides a DSL that allows non-machine-learning experts to exploit machine learning to generate self-optimizing programs.Unfortunately, in many cases the placement and structuring of choices and rewards can have a detrimental effect on how an optimal solution to a program-generation problem can be found. To address this problem, we have developed a dataflow analysis that computes influence tracks of choices and rewards. This information can be exploited by an augmented machine-learning technique to ignore misleading rewards and to generally attribute rewards better to the choices that have actually influenced them. Moreover, this technique allows us to detect errors in the adaptive program that might arise out of program maintenance. Our evaluation shows that the dataflow analysis can lead to improvements in performance.},
journal = {SIGPLAN Not.},
month = {sep},
pages = {103–111},
numpages = {9},
keywords = {partial programming, reinforcement learning, program adaptation}
}

@inproceedings{10.1145/3417990.3420057,
author = {Moin, Armin and R\"{o}ssler, Stephan and Sayih, Marouane and G\"{u}nnemann, Stephan},
title = {From Things' Modeling Language (ThingML) to Things' Machine Learning (ThingML2)},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420057},
doi = {10.1145/3417990.3420057},
abstract = {In this paper, we illustrate how to enhance an existing state-of-the-art modeling language and tool for the Internet of Things (IoT), called ThingML, to support machine learning on the modeling level. To this aim, we extend the Domain-Specific Language (DSL) of ThingML, as well as its code generation framework. Our DSL allows one to define things, which are in charge of carrying out data analytics. Further, our code generators can automatically produce the complete implementation in Java and Python. The generated Python code is responsible for data analytics and employs APIs of machine learning libraries, such as Keras, Tensorflow and Scikit Learn. Our prototype is available as open source software on Github.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {19},
numpages = {2},
keywords = {internet of things, machine learning, domain-specific modeling},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@article{10.14778/3297753.3297763,
author = {Xin, Doris and Macke, Stephen and Ma, Litian and Liu, Jialin and Song, Shuchen and Parameswaran, Aditya},
title = {HELIX: Holistic Optimization for Accelerating Iterative Machine Learning},
year = {2018},
issue_date = {December 2018},
publisher = {VLDB Endowment},
volume = {12},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/3297753.3297763},
doi = {10.14778/3297753.3297763},
abstract = {Machine learning workflow development is a process of trial-and-error: developers iterate on workflows by testing out small modifications until the desired accuracy is achieved. Unfortunately, existing machine learning systems focus narrowly on model training---a small fraction of the overall development time---and neglect to address iterative development. We propose Helix, a machine learning system that optimizes the execution across iterations---intelligently caching and reusing, or recomputing intermediates as appropriate. Helix captures a wide variety of application needs within its Scala DSL, with succinct syntax defining unified processes for data preprocessing, model specification, and learning. We demonstrate that the reuse problem can be cast as a Max-Flow problem, while the caching problem is NP-Hard. We develop effective lightweight heuristics for the latter. Empirical evaluation shows that Helix is not only able to handle a wide variety of use cases in one unified workflow but also much faster, providing run time reductions of up to 19x over state-of-the-art systems, such as DeepDive or KeystoneML, on four real-world applications in natural language processing, computer vision, social and natural sciences.},
journal = {Proc. VLDB Endow.},
month = {dec},
pages = {446–460},
numpages = {15}
}

@inproceedings{10.1145/3468044.3468052,
author = {Podobas, Artur and Svedin, Martin and Chien, Steven W. D. and Peng, Ivy B. and Ravichandran, Naresh Balaji and Herman, Pawel and Lansner, Anders and Markidis, Stefano},
title = {StreamBrain: An HPC Framework for Brain-like Neural Networks on CPUs, GPUs and FPGAs},
year = {2021},
isbn = {9781450385497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468044.3468052},
doi = {10.1145/3468044.3468052},
abstract = {The modern deep learning method based on backpropagation has surged in popularity and has been used in multiple domains and application areas. At the same time, there are other - less-known - machine learning algorithms with a mature and solid theoretical foundation whose performance remains unexplored. One such example is the brain-like Bayesian Confidence Propagation Neural Network (BCPNN). In this paper, we introduce StreamBrain--a framework that allows neural networks based on BCPNN to be practically deployed in High-Performance Computing systems. StreamBrain is a domain-specific language (DSL), similar in concept to existing machine learning (ML) frameworks, and supports backends for CPUs, GPUs, and even FPGAs. We empirically demonstrate that StreamBrain can train the well-known ML benchmark dataset MNIST within seconds, and we are the first to demonstrate BCPNN on STL-10 size networks. We also show how StreamBrain can be used to train with custom floating-point formats and illustrate the impact of using different bfloat variations on BCPNN using FPGAs.},
booktitle = {Proceedings of the 11th International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
articleno = {8},
numpages = {6},
keywords = {Neural networks, GPU, Emerging Machine Learning, Unsupervised learning, HPC, AI, FPGA, BCPNN, Representation learning},
location = {Online, Germany},
series = {HEART '21}
}

@inproceedings{10.1145/3123939.3123979,
author = {Park, Jongse and Sharma, Hardik and Mahajan, Divya and Kim, Joon Kyung and Olds, Preston and Esmaeilzadeh, Hadi},
title = {Scale-out Acceleration for Machine Learning},
year = {2017},
isbn = {9781450349529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123939.3123979},
doi = {10.1145/3123939.3123979},
abstract = {The growing scale and complexity of Machine Learning (ML) algorithms has resulted in prevalent use of distributed general-purpose systems. In a rather disjoint effort, the community is focusing mostly on high performance single-node accelerators for learning. This work bridges these two paradigms and offers CoSMIC, a full computing stack constituting language, compiler, system software, template architecture, and circuit generators, that enable programmable acceleration of learning at scale. CoSMIC enables programmers to exploit scale-out acceleration using FPGAs and Programmable ASICs (P-ASICs) from a high-level and mathematical Domain-Specific Language (DSL). Nonetheless, CoSMIC does not require programmers to delve into the onerous task of system software development or hardware design. CoSMIC achieves three conflicting objectives of efficiency, automation, and programmability, by integrating a novel multi-threaded template accelerator architecture and a cohesive stack that generates the hardware and software code from its high-level DSL. CoSMIC can accelerate a wide range of learning algorithms that are most commonly trained using parallel variants of gradient descent. The key is to distribute partial gradient calculations of the learning algorithms across the accelerator-augmented nodes of the scale-out system. Additionally, CoSMIC leverages the parallelizability of the algorithms to offer multi-threaded acceleration within each node. Multi-threading allows CoSMIC to efficiently exploit the numerous resources that are becoming available on modern FPGAs/P-ASICs by striking a balance between multi-threaded parallelism and single-threaded performance. CoSMIC takes advantage of algorithmic properties of ML to offer a specialized system software that optimizes task allocation, role-assignment, thread management, and internode communication. We evaluate the versatility and efficiency of CoSMIC for 10 different machine learning applications from various domains. On average, a 16-node CoSMIC with UltraScale+ FPGAs offers 18.8\texttimes{} speedup over a 16-node Spark system with Xeon processors while the programmer only writes 22--55 lines of code. CoSMIC offers higher scalability compared to the state-of-the-art Spark; scaling from 4 to 16 nodes with CoSMIC yields 2.7\texttimes{} improvements whereas Spark offers 1.8\texttimes{}. These results confirm that the full-stack approach of CoSMIC takes an effective and vital step towards enabling scale-out acceleration for machine learning.},
booktitle = {Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {367–381},
numpages = {15},
keywords = {distributed, cloud, scale-out, accelerator, machine learning},
location = {Cambridge, Massachusetts},
series = {MICRO-50 '17}
}

@article{10.1145/3364999,
author = {Daruwalla, Kyle and Zhuo, Heng and Shukla, Rohit and Lipasti, Mikko},
title = {BitSAD v2: Compiler Optimization and Analysis for Bitstream Computing},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3364999},
doi = {10.1145/3364999},
abstract = {Computer vision and machine learning algorithms operating under a strict power budget require an alternate computing paradigm. While bitstream computing (BC) satisfies these constraints, creating BC systems is difficult. To address the design challenges, we propose compiler extensions to BitSAD, a DSL for BC. Our work enables bit-level software emulation and automated generation of hierarchical hardware, discusses potential optimizations, and proposes compiler phases to implement those optimizations in a hardware-aware manner. Finally, we introduce population coding, a parallelization scheme for stochastic computing that decreases latency without sacrificing accuracy, and provide theoretical and experimental guarantees on its effectiveness.},
journal = {ACM Trans. Archit. Code Optim.},
month = {nov},
articleno = {43},
numpages = {25},
keywords = {compiler, pulse density modulation, stochastic computing, Bitstream computing}
}

@inproceedings{10.1145/3097983.3098171,
author = {Cheng, Heng-Tze and Haque, Zakaria and Hong, Lichan and Ispir, Mustafa and Mewald, Clemens and Polosukhin, Illia and Roumpos, Georgios and Sculley, D. and Smith, Jamie and Soergel, David and Tang, Yuan and Tucker, Philipp and Wicke, Martin and Xia, Cassandra and Xie, Jianwei},
title = {TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level Machine Learning Frameworks},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098171},
doi = {10.1145/3097983.3098171},
abstract = {We present a framework for specifying, training, evaluating, and deploying machine learning models. Our focus is on simplifying cutting edge machine learning for practitioners in order to bring such technologies into production. Recognizing the fast evolution of the field of deep learning, we make no attempt to capture the design space of all possible model architectures in a domain-specific language (DSL) or similar configuration language. We allow users to write code to define their models, but provide abstractions that guide developers to write models in ways conducive to productionization. We also provide a unifying Estimator interface, making it possible to write downstream infrastructure (e.g. distributed training, hyperparameter tuning) independent of the model implementation.We balance the competing demands for flexibility and simplicity by offering APIs at different levels of abstraction, making common model architectures available out of the box, while providing a library of utilities designed to speed up experimentation with model architectures. To make out of the box models flexible and usable across a wide range of problems, these canned Estimators are parameterized not only over traditional hyperparameters, but also using feature columns, a declarative specification describing how to interpret input dataWe discuss our experience in using this framework in research and production environments, and show the impact on code health, maintainability, and development speed.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1763–1771},
numpages = {9},
keywords = {deep learning, high level api, machine learning framework},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/3276604.3276981,
author = {Merino, Mauricio Verano and Vinju, Jurgen and van der Storm, Tijs},
title = {Bacat\'{a}: A Language Parametric Notebook Generator (Tool Demo)},
year = {2018},
isbn = {9781450360296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3276604.3276981},
doi = {10.1145/3276604.3276981},
abstract = {Interactive notebooks allow people to communicate and collaborate through a single rich document that might include live code, multimedia, computed results, and documentation, which is persisted as a whole for reproducibility. Notebooks are currently being used extensively in domains such as data science, data journalism, and machine learning. However, constructing a notebook interface for a new language requires a lot of effort. In this tool paper, we present Bacat\'{a}, a language parametric notebook generator for domain-specific languages (DSL) based on the Jupyter framework. Bacat\'{a} is designed so that language engineers may reuse existing language components (such as parsers, code generators, interpreters, etc.) as much as possible. Moreover, we explain the design of Bacat\'{a} and how DSL notebooks can be generated with minimum effort in the context of the Rascal meta programming system and language workbench.},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {210–214},
numpages = {5},
keywords = {domain-specific languages, language workbenches, literate programming, Interactive computing},
location = {Boston, MA, USA},
series = {SLE 2018}
}

@inproceedings{10.1145/1941553.1941561,
author = {Chafi, Hassan and Sujeeth, Arvind K. and Brown, Kevin J. and Lee, HyoukJoong and Atreya, Anand R. and Olukotun, Kunle},
title = {A Domain-Specific Approach to Heterogeneous Parallelism},
year = {2011},
isbn = {9781450301190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1941553.1941561},
doi = {10.1145/1941553.1941561},
abstract = {Exploiting heterogeneous parallel hardware currently requires mapping application code to multiple disparate programming models. Unfortunately, general-purpose programming models available today can yield high performance but are too low-level to be accessible to the average programmer. We propose leveraging domain-specific languages (DSLs) to map high-level application code to heterogeneous devices. To demonstrate the potential of this approach we present OptiML, a DSL for machine learning. OptiML programs are implicitly parallel and can achieve high performance on heterogeneous hardware with no modification required to the source code. For such a DSL-based approach to be tractable at large scales, better tools are required for DSL authors to simplify language creation and parallelization. To address this concern, we introduce Delite, a system designed specifically for DSLs that is both a framework for creating an implicitly parallel DSL as well as a dynamic runtime providing automated targeting to heterogeneous parallel hardware. We show that OptiML running on Delite achieves single-threaded, parallel, and GPU performance superior to explicitly parallelized MATLAB code in nearly all cases.},
booktitle = {Proceedings of the 16th ACM Symposium on Principles and Practice of Parallel Programming},
pages = {35–46},
numpages = {12},
keywords = {dynamic optimizations, runtimes, parallel programming, domain-specific languages},
location = {San Antonio, TX, USA},
series = {PPoPP '11}
}

@article{10.1145/2038037.1941561,
author = {Chafi, Hassan and Sujeeth, Arvind K. and Brown, Kevin J. and Lee, HyoukJoong and Atreya, Anand R. and Olukotun, Kunle},
title = {A Domain-Specific Approach to Heterogeneous Parallelism},
year = {2011},
issue_date = {August 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/2038037.1941561},
doi = {10.1145/2038037.1941561},
abstract = {Exploiting heterogeneous parallel hardware currently requires mapping application code to multiple disparate programming models. Unfortunately, general-purpose programming models available today can yield high performance but are too low-level to be accessible to the average programmer. We propose leveraging domain-specific languages (DSLs) to map high-level application code to heterogeneous devices. To demonstrate the potential of this approach we present OptiML, a DSL for machine learning. OptiML programs are implicitly parallel and can achieve high performance on heterogeneous hardware with no modification required to the source code. For such a DSL-based approach to be tractable at large scales, better tools are required for DSL authors to simplify language creation and parallelization. To address this concern, we introduce Delite, a system designed specifically for DSLs that is both a framework for creating an implicitly parallel DSL as well as a dynamic runtime providing automated targeting to heterogeneous parallel hardware. We show that OptiML running on Delite achieves single-threaded, parallel, and GPU performance superior to explicitly parallelized MATLAB code in nearly all cases.},
journal = {SIGPLAN Not.},
month = {feb},
pages = {35–46},
numpages = {12},
keywords = {runtimes, dynamic optimizations, parallel programming, domain-specific languages}
}

@inproceedings{10.1145/2555243.2557966,
author = {Olukotun, Kunle},
title = {Beyond Parallel Programming with Domain Specific Languages},
year = {2014},
isbn = {9781450326568},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2555243.2557966},
doi = {10.1145/2555243.2557966},
abstract = {Today, almost all computer architectures are parallel and heterogeneous; a combination of multiple CPUs, GPUs and specialized processors. This creates a challenging problem for application developers who want to develop high performance programs without the effort required to use low-level, architecture specific parallel programming models (e.g. OpenMP for CMPs, CUDA for GPUs, MPI for clusters). Domain-specific languages (DSLs) are a promising solution to this problem because they can provide an avenue for high-level application-specific abstractions with implicit parallelism to be mapped directly to low level architecture-specific programming models; providing both high programmer productivity and high execution performance.In this talk I will describe an approach to building high performance DSLs, which is based on DSL embedding in a general purpose programming language, metaprogramming and a DSL infrastructure called Delite. I will describe how we transform DSL programs into efficient first-order low-level code using domain specific optimization, parallelism and locality optimization with parallel patterns, and architecture-specific code generation. All optimizations and transformations are implemented in Delite: an extensible DSL compiler infrastucture that significantly reduces the effort required to develop new DSLs. Delite DSLs for machine learning, data querying, graph analysis, and scientific computing all achieve performance competitive with manually parallelized C++ code.},
booktitle = {Proceedings of the 19th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {179–180},
numpages = {2},
keywords = {domain specific languages},
location = {Orlando, Florida, USA},
series = {PPoPP '14}
}

@article{10.1145/2692916.2557966,
author = {Olukotun, Kunle},
title = {Beyond Parallel Programming with Domain Specific Languages},
year = {2014},
issue_date = {August 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/2692916.2557966},
doi = {10.1145/2692916.2557966},
abstract = {Today, almost all computer architectures are parallel and heterogeneous; a combination of multiple CPUs, GPUs and specialized processors. This creates a challenging problem for application developers who want to develop high performance programs without the effort required to use low-level, architecture specific parallel programming models (e.g. OpenMP for CMPs, CUDA for GPUs, MPI for clusters). Domain-specific languages (DSLs) are a promising solution to this problem because they can provide an avenue for high-level application-specific abstractions with implicit parallelism to be mapped directly to low level architecture-specific programming models; providing both high programmer productivity and high execution performance.In this talk I will describe an approach to building high performance DSLs, which is based on DSL embedding in a general purpose programming language, metaprogramming and a DSL infrastructure called Delite. I will describe how we transform DSL programs into efficient first-order low-level code using domain specific optimization, parallelism and locality optimization with parallel patterns, and architecture-specific code generation. All optimizations and transformations are implemented in Delite: an extensible DSL compiler infrastucture that significantly reduces the effort required to develop new DSLs. Delite DSLs for machine learning, data querying, graph analysis, and scientific computing all achieve performance competitive with manually parallelized C++ code.},
journal = {SIGPLAN Not.},
month = {feb},
pages = {179–180},
numpages = {2},
keywords = {domain specific languages}
}

@inproceedings{10.1145/3039895.3039898,
author = {Dethlefs, Nina and Hawick, Ken},
title = {DEFIne: A Fluent Interface DSL for Deep Learning Applications},
year = {2017},
isbn = {9781450348454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3039895.3039898},
doi = {10.1145/3039895.3039898},
abstract = {Recent years have seen a surge of interest in deep learning models that outperform other machine learning algorithms on benchmarks across many disciplines. Most existing deep learning libraries facilitate the development of neural nets by providing a mathematical framework that helps users implement their models more efficiently. This still represents a substantial investment of time and effort, however, when the intention is to compare a range of competing models quickly for a specific task. We present DEFIne, a fluent interface DSL for the specification, optimisation and evaluation of deep learning models. The fluent interface is implemented through method chaining. DEFIne is embedded in Python and is build on top of its most popular deep learning libraries, Keras and Theano. It extends these with common operations for data pre-processing and representation as well as visualisation of datasets and results. We test our framework on three benchmark tasks from different domains: heart disease diagnosis, hand-written digit recognition and weather forecast generation. Results in terms of accuracy, runtime and lines of code show that our DSL achieves equivalent accuracy and runtime to state-of-the-art models, while requiring only about 10 lines of code per application.},
booktitle = {Proceedings of the 2nd International Workshop on Real World Domain Specific Languages},
articleno = {3},
numpages = {10},
keywords = {deep learning, Domain-specific languages},
location = {Austin, TX, USA},
series = {RWDSL17}
}

@inproceedings{10.1145/1921168.1921178,
author = {Jin, Yu and Duffield, Nick and Gerber, Alexandre and Haffner, Patrick and Sen, Subhabrata and Zhang, Zhi-Li},
title = {NEVERMIND, the Problem is Already Fixed: Proactively Detecting and Troubleshooting Customer DSL Problems},
year = {2010},
isbn = {9781450304481},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1921168.1921178},
doi = {10.1145/1921168.1921178},
abstract = {Traditional DSL troubleshooting solutions are reactive, relying mainly on customers to report problems, and tend to be labor-intensive, time consuming, prone to incorrect resolutions and overall can contribute to increased customer dissatisfaction. In this paper, we propose a proactive approach to facilitate troubleshooting customer edge problems and reducing customer tickets. Our system consists of: i) a ticket predictor which predicts future customer tickets; and ii) a trouble locator which helps technicians accelerate the troubleshooting process during field dispatches. Both components infer future tickets and trouble locations based on existing sparse line measurements, and the inference models are constructed automatically using supervised machine learning techniques. We propose several novel techniques to address the operational constraints in DSL networks and to enhance the accuracy of NEVERMIND. Extensive evaluations using an entire year worth of customer tickets and measurement data from a large network show that our method can predict thousands of future customer tickets per week with high accuracy and signifcantly reduce the time and effort for diagnosing these tickets. This is benefcial as it has the effect of both reducing the number of customer care calls and improving customer satisfaction.},
booktitle = {Proceedings of the 6th International COnference},
articleno = {7},
numpages = {12},
location = {Philadelphia, Pennsylvania},
series = {Co-NEXT '10}
}

@inbook{10.1145/3447404.3447405,
title = {Preface},
year = {2021},
isbn = {9781450390293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
url = {https://doi.org/10.1145/3447404.3447405},
abstract = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice provides a comprehensive resource on what has become the dominant paradigm for novel interaction design methods involving gesture, speech, text, and touch embedded in novel and emerging interfaces. These interfaces support smartphones, wearables, in-vehicle devices, virtual reality, robotic, the Internet of Things (IoT), brain–computer interaction, and many other applications that are now highly competitive commercially.This edited collection is written by international experts and pioneers in the field of digital signal processing (DSP) and machine learning (ML) for interactive systems. It provides a textbook for students, and a reference and technology roadmap for developers and professionals working in interaction design on emerging platforms. This introductory textbook presents theory chapters on statistical grounding, signal processing, and ML foundations for guiding the development of novel interactive systems. Additional chapters discuss case studies on smart cities, brain–computer interfaces (BCI), probabilistic text entry, secure gestures, personal context from mobile phones, building adaptive touch interfaces, and automotive user interfaces (UIs). The chapters on case studies also highlight an in-depth look at domain-specific language (DSL) and ML methods used, for example, in touch, gesture, electroencephalography (EEG), electrocardiography (ECG), and galvanic skin response (GSR) signals, or embedded sensor inputs. A common theme throughout is the ubiquitous support for humans as they go about their daily professional or personal activities.This introductory book provides walk-through examples of different DSP and ML techniques and their use in interactive systems. Common terms are defined, and information on practical resources is provided (e.g., software tools, data resources) for hands-on project work to develop and evaluate multimodal–multisensor systems. After each chapter an expert on the legal and ethical issues explores the wider ethical issues on how DSP and ML should be adopted and used in socially appropriate ways, to most effectively advance human performance during interaction with novel platforms.Parisa Eslambolchilar, Andreas Komninos, and Mark D. Dunlop, March 2020AcknowledgmentsWe would like to thank our external reviewers for their valuable feedback throughout the writing process.},
booktitle = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice},
pages = {xv–xvi}
}

@article{10.1145/3368858,
author = {Stoltzfus, Larisa and Hagedorn, Bastian and Steuwer, Michel and Gorlatch, Sergei and Dubach, Christophe},
title = {Tiling Optimizations for Stencil Computations Using Rewrite Rules in Lift},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3368858},
doi = {10.1145/3368858},
abstract = {Stencil computations are a widely used type of algorithm, found in applications from physical simulations to machine learning. Stencils are embarrassingly parallel, therefore fit on modern hardware such as Graphic Processing Units perfectly. Although stencil computations have been extensively studied, optimizing them for increasingly diverse hardware remains challenging. Domain-specific Languages (DSLs) have raised the programming abstraction and offer good performance; however, this method places the burden on DSL implementers to write almost full-fledged parallelizing compilers and optimizers.Lift has recently emerged as a promising approach to achieve performance portability by using a small set of reusable parallel primitives that DSL or library writers utilize. Lift’s key novelty is in its encoding of optimizations as a system of extensible rewrite rules which are used to explore the optimization space.This article demonstrates how complex multi-dimensional stencil code and optimizations are expressed using compositions of simple 1D Lift primitives and rewrite rules. We introduce two optimizations that provide high performance for stencils in particular: classical overlapped tiling for multi-dimensional stencils and 2.5D tiling specifically for 3D stencils. We provide an in-depth analysis on how the tiling optimizations affects stencils of different shapes and sizes across different applications. Our experimental results show that our approach outperforms existing compiler approaches and hand-tuned codes.},
journal = {ACM Trans. Archit. Code Optim.},
month = {dec},
articleno = {52},
numpages = {25},
keywords = {GPU computing, lift, performance portability, stencil, Code generation}
}

@inproceedings{10.1145/3168824,
author = {Hagedorn, Bastian and Stoltzfus, Larisa and Steuwer, Michel and Gorlatch, Sergei and Dubach, Christophe},
title = {High Performance Stencil Code Generation with Lift},
year = {2018},
isbn = {9781450356176},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168824},
doi = {10.1145/3168824},
abstract = {Stencil computations are widely used from physical simulations to machine-learning. They are embarrassingly parallel and perfectly fit modern hardware such as Graphic Processing Units. Although stencil computations have been extensively studied, optimizing them for increasingly diverse hardware remains challenging. Domain Specific Languages (DSLs) have raised the programming abstraction and offer good performance. However, this places the burden on DSL implementers who have to write almost full-fledged parallelizing compilers and optimizers. Lift has recently emerged as a promising approach to achieve performance portability and is based on a small set of reusable parallel primitives that DSL or library writers can build upon. Lift’s key novelty is in its encoding of optimizations as a system of extensible rewrite rules which are used to explore the optimization space. However, Lift has mostly focused on linear algebra operations and it remains to be seen whether this approach is applicable for other domains. This paper demonstrates how complex multidimensional stencil code and optimizations such as tiling are expressible using compositions of simple 1D Lift primitives. By leveraging existing Lift primitives and optimizations, we only require the addition of two primitives and one rewrite rule to do so. Our results show that this approach outperforms existing compiler approaches and hand-tuned codes.},
booktitle = {Proceedings of the 2018 International Symposium on Code Generation and Optimization},
pages = {100–112},
numpages = {13},
keywords = {GPU Computing, Stencil, Performance Portability, Code Generation, Lift},
location = {Vienna, Austria},
series = {CGO 2018}
}

@article{10.1145/2584665,
author = {Sujeeth, Arvind K. and Brown, Kevin J. and Lee, Hyoukjoong and Rompf, Tiark and Chafi, Hassan and Odersky, Martin and Olukotun, Kunle},
title = {Delite: A Compiler Architecture for Performance-Oriented Embedded Domain-Specific Languages},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4s},
issn = {1539-9087},
url = {https://doi.org/10.1145/2584665},
doi = {10.1145/2584665},
abstract = {Developing high-performance software is a difficult task that requires the use of low-level, architecture-specific programming models (e.g., OpenMP for CMPs, CUDA for GPUs, MPI for clusters). It is typically not possible to write a single application that can run efficiently in different environments, leading to multiple versions and increased complexity. Domain-Specific Languages (DSLs) are a promising avenue to enable programmers to use high-level abstractions and still achieve good performance on a variety of hardware. This is possible because DSLs have higher-level semantics and restrictions than general-purpose languages, so DSL compilers can perform higher-level optimization and translation. However, the cost of developing performance-oriented DSLs is a substantial roadblock to their development and adoption. In this article, we present an overview of the Delite compiler framework and the DSLs that have been developed with it. Delite simplifies the process of DSL development by providing common components, like parallel patterns, optimizations, and code generators, that can be reused in DSL implementations. Delite DSLs are embedded in Scala, a general-purpose programming language, but use metaprogramming to construct an Intermediate Representation (IR) of user programs and compile to multiple languages (including C++, CUDA, and OpenCL). DSL programs are automatically parallelized and different parts of the application can run simultaneously on CPUs and GPUs. We present Delite DSLs for machine learning, data querying, graph analysis, and scientific computing and show that they all achieve performance competitive to or exceeding C++ code.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {apr},
articleno = {134},
numpages = {25},
keywords = {Domain-specific languages, language virtualization, code generation, multistage programming}
}

@article{10.14778/3236187.3236188,
author = {Mahajan, Divya and Kim, Joon Kyung and Sacks, Jacob and Ardalan, Adel and Kumar, Arun and Esmaeilzadeh, Hadi},
title = {In-RDBMS Hardware Acceleration of Advanced Analytics},
year = {2018},
issue_date = {July 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3236187.3236188},
doi = {10.14778/3236187.3236188},
abstract = {The data revolution is fueled by advances in machine learning, databases, and hardware design. Programmable accelerators are making their way into each of these areas independently. As such, there is a void of solutions that enables hardware acceleration at the intersection of these disjoint fields. This paper sets out to be the initial step towards a unifying solution for in-Database Acceleration of Advanced Analytics (DAnA). Deploying specialized hardware, such as FPGAs, for in-database analytics currently requires hand-designing the hardware and manually routing the data. Instead, DAnA automatically maps a high-level specification of advanced analytics queries to an FPGA accelerator. The accelerator implementation is generated for a User Defined Function (UDF), expressed as a part of an SQL query using a Python-embedded Domain-Specific Language (DSL). To realize an efficient in-database integration, DAnA accelerators contain a novel hardware structure, Striders, that directly interface with the buffer pool of the database. Striders extract, cleanse, and process the training data tuples that are consumed by a multi-threaded FPGA engine that executes the analytics algorithm. We integrate DAnA with PostgreSQL to generate hardware accelerators for a range of real-world and synthetic datasets running diverse ML algorithms. Results show that DAnA-enhanced PostgreSQL provides, on average, 8.3\texttimes{} end-to-end speedup for real datasets, with a maximum of 28.2\texttimes{}. Moreover, DAnA-enhanced PostgreSQL is, on average, 4.0\texttimes{} faster than the multi-threaded Apache MADLib running on Greenplum. DAnA provides these benefits while hiding the complexity of hardware design from data scientists and allowing them to express the algorithm in ≈30-60 lines of Python.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {1317–1331},
numpages = {15}
}

@article{10.1145/3571284,
author = {Perez, Victor and Sommer, Lukas and Lom\"{u}ller, Victor and Narasimhan, Kumudha and Goli, Mehdi},
title = {User-Driven Online Kernel Fusion for SYCL},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1544-3566},
url = {https://doi.org/10.1145/3571284},
doi = {10.1145/3571284},
abstract = {Heterogeneous programming models are becoming increasingly popular to support the ever-evolving hardware architectures, especially for new and emerging specialized accelerators optimizing specific tasks. While such programs provide performance portability of the existing applications across various heterogeneous architectures to some extent, short-running device kernels can affect an application performance due to overheads of data transfer, synchronization and kernel launch. While in applications with one or two short-running kernels the overhead can be negligible, it can be noticeable when these short-running kernels dominate the overall number of kernels in an application, as it is the case in graph-based neural network models, where there are several small memory-bound nodes alongside few large compute-bound nodes. To reduce the overhead, combining several kernels into a single, more optimized kernel is an active area of research. However, this task can be time-consuming and error-prone given the huge set of potential combinations. This can push programmers to seek a trade-off between (a) task-specific kernels with low overhead but hard to maintain and (b) smaller modular kernels with higher overhead but easier to maintain. While there are DSL-based approaches, such as those provided for machine learning frameworks, which offer the possibility of such a fusion, they are limited to a particular domain and exploit specific knowledge of that domain and, as a consequence, are hard to port elsewhere. This study explores the feasibility of a user-driven kernel fusion through an extension to the SYCL API to address the automation of kernel fusion. The proposed solution requires programmers to define the subgraph regions that are potentially suitable for fusion without any modification to the kernel code or the function signature. We evaluate the performance benefit of our approach on common neural networks and study the performance improvement in detail.},
note = {Just Accepted},
journal = {ACM Trans. Archit. Code Optim.},
month = {nov},
keywords = {runtime environments, neural networks, just-in-time compilers}
}

@inproceedings{10.1145/3417990.3420057,
author = {Moin, Armin and R\"{o}ssler, Stephan and Sayih, Marouane and G\"{u}nnemann, Stephan},
title = {From Things' Modeling Language (ThingML) to Things' Machine Learning (ThingML2)},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420057},
doi = {10.1145/3417990.3420057},
abstract = {In this paper, we illustrate how to enhance an existing state-of-the-art modeling language and tool for the Internet of Things (IoT), called ThingML, to support machine learning on the modeling level. To this aim, we extend the Domain-Specific Language (DSL) of ThingML, as well as its code generation framework. Our DSL allows one to define things, which are in charge of carrying out data analytics. Further, our code generators can automatically produce the complete implementation in Java and Python. The generated Python code is responsible for data analytics and employs APIs of machine learning libraries, such as Keras, Tensorflow and Scikit Learn. Our prototype is available as open source software on Github.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {19},
numpages = {2},
keywords = {internet of things, machine learning, domain-specific modeling},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3503222.3507778,
author = {Jangda, Abhinav and Huang, Jun and Liu, Guodong and Sabet, Amir Hossein Nodehi and Maleki, Saeed and Miao, Youshan and Musuvathi, Madanlal and Mytkowicz, Todd and Saarikivi, Olli},
title = {Breaking the Computation and Communication Abstraction Barrier in Distributed Machine Learning Workloads},
year = {2022},
isbn = {9781450392051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3503222.3507778},
doi = {10.1145/3503222.3507778},
abstract = {Recent trends towards large machine learning models require both training and inference tasks to be distributed. Considering the huge cost of training these models, it is imperative to unlock optimizations in computation and communication to obtain best performance. However, the current logical separation between computation and communication kernels in machine learning frameworks misses optimization opportunities across this barrier. Breaking this abstraction can provide many optimizations to improve the performance of distributed workloads. However, manually applying these optimizations requires modifying the underlying computation and communication libraries for each scenario, which is both time consuming and error-prone. Therefore, we present CoCoNet, which contains (i) a domain specific language to express a distributed machine learning program in the form of computation and communication operations, (ii) a set of semantics preserving transformations to optimize the program, and (iii) a compiler to generate jointly optimized communication and computation GPU kernels. Providing both computation and communication as first class constructs allows users to work on a high-level abstraction and apply powerful optimizations, such as fusion or overlapping of communication and computation. CoCoNet enabled us to optimize data-, model- and pipeline-parallel workloads in large language models with only a few lines of code. Our experiments show that CoCoNet significantly outperforms state-of-the-art distributed machine learning implementations.},
booktitle = {Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems},
pages = {402–416},
numpages = {15},
keywords = {Code Generation, CUDA, Collective Communication, Compiler Optimizations, Distributed Machine Learning, MPI},
location = {Lausanne, Switzerland},
series = {ASPLOS '22}
}

@inproceedings{10.1145/3468044.3468052,
author = {Podobas, Artur and Svedin, Martin and Chien, Steven W. D. and Peng, Ivy B. and Ravichandran, Naresh Balaji and Herman, Pawel and Lansner, Anders and Markidis, Stefano},
title = {StreamBrain: An HPC Framework for Brain-like Neural Networks on CPUs, GPUs and FPGAs},
year = {2021},
isbn = {9781450385497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468044.3468052},
doi = {10.1145/3468044.3468052},
abstract = {The modern deep learning method based on backpropagation has surged in popularity and has been used in multiple domains and application areas. At the same time, there are other - less-known - machine learning algorithms with a mature and solid theoretical foundation whose performance remains unexplored. One such example is the brain-like Bayesian Confidence Propagation Neural Network (BCPNN). In this paper, we introduce StreamBrain--a framework that allows neural networks based on BCPNN to be practically deployed in High-Performance Computing systems. StreamBrain is a domain-specific language (DSL), similar in concept to existing machine learning (ML) frameworks, and supports backends for CPUs, GPUs, and even FPGAs. We empirically demonstrate that StreamBrain can train the well-known ML benchmark dataset MNIST within seconds, and we are the first to demonstrate BCPNN on STL-10 size networks. We also show how StreamBrain can be used to train with custom floating-point formats and illustrate the impact of using different bfloat variations on BCPNN using FPGAs.},
booktitle = {Proceedings of the 11th International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
articleno = {8},
numpages = {6},
keywords = {Neural networks, GPU, Emerging Machine Learning, Unsupervised learning, HPC, AI, FPGA, BCPNN, Representation learning},
location = {Online, Germany},
series = {HEART '21}
}

@inproceedings{10.1145/3368826.3377923,
author = {Shaikhha, Amir and Schleich, Maximilian and Ghita, Alexandru and Olteanu, Dan},
title = {Multi-Layer Optimizations for End-to-End Data Analytics},
year = {2020},
isbn = {9781450370479},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3368826.3377923},
doi = {10.1145/3368826.3377923},
abstract = {We consider the problem of training machine learning models over multi-relational data. The mainstream approach is to first construct the training dataset using a feature extraction query over input database and then use a statistical software package of choice to train the model. In this paper we introduce Iterative Functional Aggregate Queries (IFAQ), a framework that realizes an alternative approach. IFAQ treats the feature extraction query and the learning task as one program given in the IFAQ's domain-specific language, which captures a subset of Python commonly used in Jupyter notebooks for rapid prototyping of machine learning applications. The program is subject to several layers of IFAQ optimizations, such as algebraic transformations, loop transformations, schema specialization, data layout optimizations, and finally compilation into efficient low-level C++ code specialized for the given workload and data. We show that a Scala implementation of IFAQ can outperform mlpack, Scikit, and TensorFlow by several orders of magnitude for linear regression and regression tree models over several relational datasets.},
booktitle = {Proceedings of the 18th ACM/IEEE International Symposium on Code Generation and Optimization},
pages = {145–157},
numpages = {13},
keywords = {In-Database Machine Learning, Query Compilation, Multi-Query Optimization},
location = {San Diego, CA, USA},
series = {CGO 2020}
}

@inproceedings{10.1145/3470481.3472705,
author = {Chhokra, Ajay and Barreto, Carlos and Dubey, Abhishek and Karsai, Gabor and Koutsoukos, Xenofon},
title = {Power-Attack: A Comprehensive Tool-Chain for Modeling and Simulating Attacks in Power Systems},
year = {2021},
isbn = {9781450386081},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3470481.3472705},
doi = {10.1145/3470481.3472705},
abstract = {Due to the increased deployment of novel communication, control and protection functions, the grid has become vulnerable to a variety of attacks. Designing robust machine learning based attack detection and mitigation algorithms require large amounts of data that rely heavily on a representative environment, where different attacks can be simulated. This paper presents a comprehensive tool-chain for modeling and simulating attacks in power systems. The paper makes the following contributions, first, we present a probabilistic domain specific language to define multiple attack scenarios and simulation configuration parameters. Secondly, we extend the PyPower-dynamics simulator with protection system components to simulate cyber attacks in control and protection layers of power system. In the end, we demonstrate multiple attack scenarios with a case study based on IEEE 39 bus system.},
booktitle = {Proceedings of the 9th Workshop on Modeling and Simulation of Cyber-Physical Energy Systems},
articleno = {5},
numpages = {6},
keywords = {cyber attacks, protection system, cyber security, power system simulation},
location = {Virtual Event},
series = {MSCPES '21}
}

@inproceedings{10.1145/3018610.3018619,
author = {Jakub\r{u}v, Jan and Urban, Josef},
title = {BliStrTune: Hierarchical Invention of Theorem Proving Strategies},
year = {2017},
isbn = {9781450347051},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3018610.3018619},
doi = {10.1145/3018610.3018619},
abstract = {Inventing targeted proof search strategies for specific problem sets is a difficult task. State-of-the-art automated theorem provers (ATPs) such as E allow a large number of user-specified proof search strategies described in a rich domain specific language. Several machine learning methods that invent strategies automatically for ATPs were proposed previously. One of them is the Blind Strategymaker (BliStr), a system for automated invention of ATP strategies. In this paper we introduce BliStrTune -- a hierarchical extension of BliStr. BliStrTune allows exploring much larger space of E strategies by interleaving search for high-level parameters with their fine-tuning. We use BliStrTune to invent new strategies based also on new clause weight functions targeted at problems from large ITP libraries. We show that the new strategies significantly improve E's performance in solving problems from the Mizar Mathematical Library.},
booktitle = {Proceedings of the 6th ACM SIGPLAN Conference on Certified Programs and Proofs},
pages = {43–52},
numpages = {10},
keywords = {Clause Weight Functions, Machine Learning, Automated Theorem Proving, Proof Search Heuristics},
location = {Paris, France},
series = {CPP 2017}
}

@inproceedings{10.1145/3461648.3463842,
author = {Poroor, Jayaraj and Lal, Akash and Ghanta, Sandesh},
title = {Robust I/O-Compute Concurrency for Machine Learning Pipelines in Constrained Cyber-Physical Devices},
year = {2021},
isbn = {9781450384728},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3461648.3463842},
doi = {10.1145/3461648.3463842},
abstract = {Cyberphysical systems have numerous industrial and commercial applications. Such systems are often built using low-resource devices that gather and process data, using machine-learning (ML) models, to make intelligent decisions and provide value to users. Programming such low-resource devices with an impoverished system runtime is often challenging. This paper presents a new domain-specific language called PiCon for programming ML pipelines in low-resource devices. PiCon allows safe I/O-compute concurrency, ruling out a large class of errors, while providing a simple and sequential coding abstraction to the programmer. PiCon compiles to C code and easily interfaces with existing C/C++ code. Furthermore, the generated code does not rely on multi-threading support or dynamic memory allocation, dramatically reducing its footprint on the device. We present experience porting two real-world ML applications that demonstrate simplification in programmability, in addition to several safe-by-construction guarantees.},
booktitle = {Proceedings of the 22nd ACM SIGPLAN/SIGBED International Conference on Languages, Compilers, and Tools for Embedded Systems},
pages = {1–11},
numpages = {11},
keywords = {Cyberphysical systems, Embedded systems, IoT, Constrained devices, Machine Learning},
location = {Virtual, Canada},
series = {LCTES 2021}
}

@article{10.14778/3007263.3007279,
author = {Boehm, Matthias and Dusenberry, Michael W. and Eriksson, Deron and Evfimievski, Alexandre V. and Manshadi, Faraz Makari and Pansare, Niketan and Reinwald, Berthold and Reiss, Frederick R. and Sen, Prithviraj and Surve, Arvind C. and Tatikonda, Shirish},
title = {SystemML: Declarative Machine Learning on Spark},
year = {2016},
issue_date = {September 2016},
publisher = {VLDB Endowment},
volume = {9},
number = {13},
issn = {2150-8097},
url = {https://doi.org/10.14778/3007263.3007279},
doi = {10.14778/3007263.3007279},
abstract = {The rising need for custom machine learning (ML) algorithms and the growing data sizes that require the exploitation of distributed, data-parallel frameworks such as MapReduce or Spark, pose significant productivity challenges to data scientists. Apache SystemML addresses these challenges through declarative ML by (1) increasing the productivity of data scientists as they are able to express custom algorithms in a familiar domain-specific language covering linear algebra primitives and statistical functions, and (2) transparently running these ML algorithms on distributed, data-parallel frameworks by applying cost-based compilation techniques to generate efficient, low-level execution plans with in-memory single-node and large-scale distributed operations. This paper describes SystemML on Apache Spark, end to end, including insights into various optimizer and runtime techniques as well as performance characteristics. We also share lessons learned from porting SystemML to Spark and declarative ML in general. Finally, SystemML is open-source, which allows the database community to leverage it as a testbed for further research.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {1425–1436},
numpages = {12}
}

@inproceedings{10.1145/3183895.3183901,
author = {Svore, Krysta and Geller, Alan and Troyer, Matthias and Azariah, John and Granade, Christopher and Heim, Bettina and Kliuchnikov, Vadym and Mykhailova, Mariia and Paz, Andres and Roetteler, Martin},
title = {Q#: Enabling Scalable Quantum Computing and Development with a High-Level DSL},
year = {2018},
isbn = {9781450363556},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3183895.3183901},
doi = {10.1145/3183895.3183901},
abstract = {Quantum computing exploits quantum phenomena such as superposition and entanglement to realize a form of parallelism that is not available to traditional computing. It offers the potential of significant computational speed-ups in quantum chemistry, materials science, cryptography, and machine learning.The dominant approach to programming quantum computers is to provide an existing high-level language with libraries that allow for the expression of quantum programs. This approach can permit computations that are meaningless in a quantum context; prohibits succint expression of interaction between classical and quantum logic; and does not provide important constructs that are required for quantum programming.We present Q#, a quantum-focused domain-specific language explicitly designed to correctly, clearly and completely express quantum algorithms. Q# provides a type system; a tightly constrained environment to safely interleave classical and quantum computations; specialized syntax; symbolic code manipulation to automatically generate correct transformations of quantum operations; and powerful functional constructs which aid composition.},
booktitle = {Proceedings of the Real World Domain Specific Languages Workshop 2018},
articleno = {7},
numpages = {10},
keywords = {domain specific language, quantum computing, functional programming},
location = {Vienna, Austria},
series = {RWDSL2018}
}

@article{10.14778/3430915.3430919,
author = {Kiefer, Martin and Poulakis, Ilias and Bre\ss{}, Sebastian and Markl, Volker},
title = {Scotch: Generating FPGA-Accelerators for Sketching at Line Rate},
year = {2021},
issue_date = {November 2020},
publisher = {VLDB Endowment},
volume = {14},
number = {3},
issn = {2150-8097},
url = {https://doi.org/10.14778/3430915.3430919},
doi = {10.14778/3430915.3430919},
abstract = {Sketching algorithms are a powerful tool for single-pass data summarization. Their numerous applications include approximate query processing, machine learning, and large-scale network monitoring. In the presence of high-bandwidth interconnects or in-memory data, the throughput of summary maintenance over input data becomes the bottleneck. While FPGAs have shown admirable throughput and energy-efficiency for data processing tasks, developing FPGA accelerators requires a sophisticated hardware design and expensive manual tuning by an expert.We propose Scotch, a novel system for accelerating sketch maintenance using FPGAs. Scotch provides a domain-specific language for the user-friendly, high-level definition of a broad class of sketching algorithms. A code generator performs the heavy-lifting of hardware description, while an auto-tuning algorithm optimizes the summary size. Our evaluation shows that FPGA accelerators generated by Scotch outperform CPU- and GPU-based sketching by up to two orders of magnitude in terms of throughput and up to a factor of five in terms of energy efficiency.},
journal = {Proc. VLDB Endow.},
month = {dec},
pages = {281–293},
numpages = {13}
}

@inproceedings{10.1145/3097983.3098171,
author = {Cheng, Heng-Tze and Haque, Zakaria and Hong, Lichan and Ispir, Mustafa and Mewald, Clemens and Polosukhin, Illia and Roumpos, Georgios and Sculley, D. and Smith, Jamie and Soergel, David and Tang, Yuan and Tucker, Philipp and Wicke, Martin and Xia, Cassandra and Xie, Jianwei},
title = {TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level Machine Learning Frameworks},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098171},
doi = {10.1145/3097983.3098171},
abstract = {We present a framework for specifying, training, evaluating, and deploying machine learning models. Our focus is on simplifying cutting edge machine learning for practitioners in order to bring such technologies into production. Recognizing the fast evolution of the field of deep learning, we make no attempt to capture the design space of all possible model architectures in a domain-specific language (DSL) or similar configuration language. We allow users to write code to define their models, but provide abstractions that guide developers to write models in ways conducive to productionization. We also provide a unifying Estimator interface, making it possible to write downstream infrastructure (e.g. distributed training, hyperparameter tuning) independent of the model implementation.We balance the competing demands for flexibility and simplicity by offering APIs at different levels of abstraction, making common model architectures available out of the box, while providing a library of utilities designed to speed up experimentation with model architectures. To make out of the box models flexible and usable across a wide range of problems, these canned Estimators are parameterized not only over traditional hyperparameters, but also using feature columns, a declarative specification describing how to interpret input dataWe discuss our experience in using this framework in research and production environments, and show the impact on code health, maintainability, and development speed.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1763–1771},
numpages = {9},
keywords = {deep learning, high level api, machine learning framework},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/3192366.3192379,
author = {Koeplinger, David and Feldman, Matthew and Prabhakar, Raghu and Zhang, Yaqi and Hadjis, Stefan and Fiszel, Ruben and Zhao, Tian and Nardi, Luigi and Pedram, Ardavan and Kozyrakis, Christos and Olukotun, Kunle},
title = {Spatial: A Language and Compiler for Application Accelerators},
year = {2018},
isbn = {9781450356985},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3192366.3192379},
doi = {10.1145/3192366.3192379},
abstract = {Industry is increasingly turning to reconfigurable architectures like FPGAs and CGRAs for improved performance and energy efficiency. Unfortunately, adoption of these architectures has been limited by their programming models. HDLs lack abstractions for productivity and are difficult to target from higher level languages. HLS tools are more productive, but offer an ad-hoc mix of software and hardware abstractions which make performance optimizations difficult. In this work, we describe a new domain-specific language and compiler called Spatial for higher level descriptions of application accelerators. We describe Spatial's hardware-centric abstractions for both programmer productivity and design performance, and summarize the compiler passes required to support these abstractions, including pipeline scheduling, automatic memory banking, and automated design tuning driven by active machine learning. We demonstrate the language's ability to target FPGAs and CGRAs from common source code. We show that applications written in Spatial are, on average, 42% shorter and achieve a mean speedup of 2.9x over SDAccel HLS when targeting a Xilinx UltraScale+ VU9P FPGA on an Amazon EC2 F1 instance.},
booktitle = {Proceedings of the 39th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {296–311},
numpages = {16},
keywords = {FPGAs, domain-specific languages, CGRAs, high-level synthesis, compilers, hardware accelerators, reconfigurable architectures},
location = {Philadelphia, PA, USA},
series = {PLDI 2018}
}

@article{10.1145/3296979.3192379,
author = {Koeplinger, David and Feldman, Matthew and Prabhakar, Raghu and Zhang, Yaqi and Hadjis, Stefan and Fiszel, Ruben and Zhao, Tian and Nardi, Luigi and Pedram, Ardavan and Kozyrakis, Christos and Olukotun, Kunle},
title = {Spatial: A Language and Compiler for Application Accelerators},
year = {2018},
issue_date = {April 2018},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {53},
number = {4},
issn = {0362-1340},
url = {https://doi.org/10.1145/3296979.3192379},
doi = {10.1145/3296979.3192379},
abstract = {Industry is increasingly turning to reconfigurable architectures like FPGAs and CGRAs for improved performance and energy efficiency. Unfortunately, adoption of these architectures has been limited by their programming models. HDLs lack abstractions for productivity and are difficult to target from higher level languages. HLS tools are more productive, but offer an ad-hoc mix of software and hardware abstractions which make performance optimizations difficult. In this work, we describe a new domain-specific language and compiler called Spatial for higher level descriptions of application accelerators. We describe Spatial's hardware-centric abstractions for both programmer productivity and design performance, and summarize the compiler passes required to support these abstractions, including pipeline scheduling, automatic memory banking, and automated design tuning driven by active machine learning. We demonstrate the language's ability to target FPGAs and CGRAs from common source code. We show that applications written in Spatial are, on average, 42% shorter and achieve a mean speedup of 2.9x over SDAccel HLS when targeting a Xilinx UltraScale+ VU9P FPGA on an Amazon EC2 F1 instance.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {296–311},
numpages = {16},
keywords = {CGRAs, hardware accelerators, reconfigurable architectures, compilers, domain-specific languages, high-level synthesis, FPGAs}
}

@inproceedings{10.1145/3331543.3342587,
author = {Melkonian, Orestis and Ren, Iris Yuping and Swierstra, Wouter and Volk, Anja},
title = {What Constitutes a Musical Pattern?},
year = {2019},
isbn = {9781450368117},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3331543.3342587},
doi = {10.1145/3331543.3342587},
abstract = {There is a plethora of computational systems designed for alagorithmic discovery of musical patterns, ranging from geometrical methods to machine learning based approaches. These algorithms often disagree on what constitutes a pattern, mainly due to the lack of a broadly accepted definition of musical patterns. On the other side of the spectrum, human-annotated musical patterns also often do not reach a consensus, partly due to the subjectivity of each individual expert, but also due to the elusive definition of a musical pattern in general. In this work, we propose a framework of music-theoretic transformations, through which one can easily define predicates which dictate when two musical patterns belong to a particular equivalence class. We exploit simple notions from category theory to assemble transformations compositionally, allowing us to define complex transformations from simple and well-understood ones. Additionally, we provide a prototype implementation of our theoretical framework as an embedded domain-specific language in Haskell and conduct a meta-analysis on several algorithms submitted to a pattern extraction task of the the Music Information Retrieval Evaluation eXchange (MIREX) over the previous years.},
booktitle = {Proceedings of the 7th ACM SIGPLAN International Workshop on Functional Art, Music, Modeling, and Design},
pages = {95–105},
numpages = {11},
keywords = {transformation, edit distance, evaluation, clustering, musical patterns, contravariance},
location = {Berlin, Germany},
series = {FARM 2019}
}

@article{10.14778/3342263.3342633,
author = {Kunft, Andreas and Katsifodimos, Asterios and Schelter, Sebastian and Bre\ss{}, Sebastian and Rabl, Tilmann and Markl, Volker},
title = {An Intermediate Representation for Optimizing Machine Learning Pipelines},
year = {2019},
issue_date = {July 2019},
publisher = {VLDB Endowment},
volume = {12},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3342263.3342633},
doi = {10.14778/3342263.3342633},
abstract = {Machine learning (ML) pipelines for model training and validation typically include preprocessing, such as data cleaning and feature engineering, prior to training an ML model. Preprocessing combines relational algebra and user-defined functions (UDFs), while model training uses iterations and linear algebra. Current systems are tailored to either of the two. As a consequence, preprocessing and ML steps are optimized in isolation. To enable holistic optimization of ML training pipelines, we present Lara, a declarative domain-specific language for collections and matrices. Lara's inter-mediate representation (IR) reflects on the complete program, i.e., UDFs, control flow, and both data types. Two views on the IR enable diverse optimizations. Monads enable operator pushdown and fusion across type and loop boundaries. Combinators provide the semantics of domain-specific operators and optimize data access and cross-validation of ML algorithms. Our experiments on preprocessing pipelines and selected ML algorithms show the effects of our proposed optimizations on dense and sparse data, which achieve speedups of up to an order of magnitude.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {1553–1567},
numpages = {15}
}

@inproceedings{10.1145/3314221.3314597,
author = {Gopinath, Sridhar and Ghanathe, Nikhil and Seshadri, Vivek and Sharma, Rahul},
title = {Compiling KB-Sized Machine Learning Models to Tiny IoT Devices},
year = {2019},
isbn = {9781450367127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314221.3314597},
doi = {10.1145/3314221.3314597},
abstract = {Recent advances in machine learning (ML) have produced KiloByte-size models that can directly run on constrained IoT devices. This approach avoids expensive communication between IoT devices and the cloud, thereby enabling energy-efficient real-time analytics. However, ML models are expressed typically in floating-point, and IoT hardware typically does not support floating-point. Therefore, running these models on IoT devices requires simulating IEEE-754 floating-point using software, which is very inefficient. We present SeeDot, a domain-specific language to express ML inference algorithms and a compiler that compiles SeeDot programs to fixed-point code that can efficiently run on constrained IoT devices. We propose 1)&nbsp;a novel compilation strategy that reduces the search space for some key parameters used in the fixed-point code, and 2)&nbsp;new efficient implementations of expensive operations. SeeDot compiles state-of-the-art KB-sized models to various microcontrollers and low-end FPGAs. We show that SeeDot outperforms 1) software emulation of floating-point (Arduino), 2) high-bitwidth fixed-point (MATLAB), 3) post-training quantization (TensorFlow-Lite), and 4) floating- and fixed-point FPGA implementations generated using high-level synthesis tools.},
booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {79–95},
numpages = {17},
keywords = {IoT device, Programming Language, FPGA, Compiler, Machine Learning, Microcontroller, Fixed-point},
location = {Phoenix, AZ, USA},
series = {PLDI 2019}
}

@inproceedings{10.1145/3131851.3131853,
author = {Gulwani, Sumit},
title = {Programming by Examples: Applications, Algorithms, and Ambiguity Resolution},
year = {2017},
isbn = {9781450352918},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3131851.3131853},
doi = {10.1145/3131851.3131853},
abstract = {99% of computer users do not know programming and hence struggle with repetitive tasks. Programming by Examples (PBE) can revolutionize this landscape by enabling users to synthesize intended programs from example based specifications. A key technical challenge in PBE is to search for programs that are consistent with the examples provided by the user. Our efficient search methodology is based on two key ideas: (i) Restriction of the search space to an appropriate domain-specific language (ii) A divide-and-conquer based search paradigm that inductively reduces the problem of synthesizing a program with a certain top-level operator to simpler synthesis problems over its sub-programs by leveraging the operator's inverse semantics. Another challenge in PBE is to resolve the ambiguity in the example based specification. Our ambiguity resolution methodology leverages two complementary approaches: (a) machine learning based ranking techniques that can pick an intended program from among those that satisfy the specification, and (b) active-learning based user interaction models. I will illustrate these various concepts using Flash Fill, FlashExtract, and FlashRelate---PBE technologies for data manipulation domains. These technologies, which have been released inside various Microsoft products, are useful for data scientists who spend 80% of their time wrangling with data. The Microsoft PROSE SDK allows easy construction of such technologies.},
booktitle = {Proceedings of the 19th International Symposium on Principles and Practice of Declarative Programming},
pages = {2},
numpages = {1},
location = {Namur, Belgium},
series = {PPDP '17}
}

@inproceedings{10.1145/3123939.3123979,
author = {Park, Jongse and Sharma, Hardik and Mahajan, Divya and Kim, Joon Kyung and Olds, Preston and Esmaeilzadeh, Hadi},
title = {Scale-out Acceleration for Machine Learning},
year = {2017},
isbn = {9781450349529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123939.3123979},
doi = {10.1145/3123939.3123979},
abstract = {The growing scale and complexity of Machine Learning (ML) algorithms has resulted in prevalent use of distributed general-purpose systems. In a rather disjoint effort, the community is focusing mostly on high performance single-node accelerators for learning. This work bridges these two paradigms and offers CoSMIC, a full computing stack constituting language, compiler, system software, template architecture, and circuit generators, that enable programmable acceleration of learning at scale. CoSMIC enables programmers to exploit scale-out acceleration using FPGAs and Programmable ASICs (P-ASICs) from a high-level and mathematical Domain-Specific Language (DSL). Nonetheless, CoSMIC does not require programmers to delve into the onerous task of system software development or hardware design. CoSMIC achieves three conflicting objectives of efficiency, automation, and programmability, by integrating a novel multi-threaded template accelerator architecture and a cohesive stack that generates the hardware and software code from its high-level DSL. CoSMIC can accelerate a wide range of learning algorithms that are most commonly trained using parallel variants of gradient descent. The key is to distribute partial gradient calculations of the learning algorithms across the accelerator-augmented nodes of the scale-out system. Additionally, CoSMIC leverages the parallelizability of the algorithms to offer multi-threaded acceleration within each node. Multi-threading allows CoSMIC to efficiently exploit the numerous resources that are becoming available on modern FPGAs/P-ASICs by striking a balance between multi-threaded parallelism and single-threaded performance. CoSMIC takes advantage of algorithmic properties of ML to offer a specialized system software that optimizes task allocation, role-assignment, thread management, and internode communication. We evaluate the versatility and efficiency of CoSMIC for 10 different machine learning applications from various domains. On average, a 16-node CoSMIC with UltraScale+ FPGAs offers 18.8\texttimes{} speedup over a 16-node Spark system with Xeon processors while the programmer only writes 22--55 lines of code. CoSMIC offers higher scalability compared to the state-of-the-art Spark; scaling from 4 to 16 nodes with CoSMIC yields 2.7\texttimes{} improvements whereas Spark offers 1.8\texttimes{}. These results confirm that the full-stack approach of CoSMIC takes an effective and vital step towards enabling scale-out acceleration for machine learning.},
booktitle = {Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {367–381},
numpages = {15},
keywords = {distributed, cloud, scale-out, accelerator, machine learning},
location = {Cambridge, Massachusetts},
series = {MICRO-50 '17}
}

@inproceedings{10.1145/3314221.3314633,
author = {Fremont, Daniel J. and Dreossi, Tommaso and Ghosh, Shromona and Yue, Xiangyu and Sangiovanni-Vincentelli, Alberto L. and Seshia, Sanjit A.},
title = {Scenic: A Language for Scenario Specification and Scene Generation},
year = {2019},
isbn = {9781450367127},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3314221.3314633},
doi = {10.1145/3314221.3314633},
abstract = {We propose a new probabilistic programming language for the design and analysis of perception systems, especially those based on machine learning. Specifically, we consider the problems of training a perception system to handle rare events, testing its performance under different conditions, and debugging failures. We show how a probabilistic programming language can help address these problems by specifying distributions encoding interesting types of inputs and sampling these to generate specialized training and test sets. More generally, such languages can be used for cyber-physical systems and robotics to write environment models, an essential prerequisite to any formal analysis. In this paper, we focus on systems like autonomous cars and robots, whose environment is a scene, a configuration of physical objects and agents. We design a domain-specific language, Scenic, for describing scenarios that are distributions over scenes. As a probabilistic programming language, Scenic allows assigning distributions to features of the scene, as well as declaratively imposing hard and soft constraints over the scene. We develop specialized techniques for sampling from the resulting distribution, taking advantage of the structure provided by Scenic's domain-specific syntax. Finally, we apply Scenic in a case study on a convolutional neural network designed to detect cars in road images, improving its performance beyond that achieved by state-of-the-art synthetic data generation methods.},
booktitle = {Proceedings of the 40th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {63–78},
numpages = {16},
keywords = {deep learning, automatic test generation, probabilistic programming, fuzz testing, synthetic data, scenario description language},
location = {Phoenix, AZ, USA},
series = {PLDI 2019}
}

@inbook{10.1145/3447404.3447405,
title = {Preface},
year = {2021},
isbn = {9781450390293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
url = {https://doi.org/10.1145/3447404.3447405},
abstract = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice provides a comprehensive resource on what has become the dominant paradigm for novel interaction design methods involving gesture, speech, text, and touch embedded in novel and emerging interfaces. These interfaces support smartphones, wearables, in-vehicle devices, virtual reality, robotic, the Internet of Things (IoT), brain–computer interaction, and many other applications that are now highly competitive commercially.This edited collection is written by international experts and pioneers in the field of digital signal processing (DSP) and machine learning (ML) for interactive systems. It provides a textbook for students, and a reference and technology roadmap for developers and professionals working in interaction design on emerging platforms. This introductory textbook presents theory chapters on statistical grounding, signal processing, and ML foundations for guiding the development of novel interactive systems. Additional chapters discuss case studies on smart cities, brain–computer interfaces (BCI), probabilistic text entry, secure gestures, personal context from mobile phones, building adaptive touch interfaces, and automotive user interfaces (UIs). The chapters on case studies also highlight an in-depth look at domain-specific language (DSL) and ML methods used, for example, in touch, gesture, electroencephalography (EEG), electrocardiography (ECG), and galvanic skin response (GSR) signals, or embedded sensor inputs. A common theme throughout is the ubiquitous support for humans as they go about their daily professional or personal activities.This introductory book provides walk-through examples of different DSP and ML techniques and their use in interactive systems. Common terms are defined, and information on practical resources is provided (e.g., software tools, data resources) for hands-on project work to develop and evaluate multimodal–multisensor systems. After each chapter an expert on the legal and ethical issues explores the wider ethical issues on how DSP and ML should be adopted and used in socially appropriate ways, to most effectively advance human performance during interaction with novel platforms.Parisa Eslambolchilar, Andreas Komninos, and Mark D. Dunlop, March 2020AcknowledgmentsWe would like to thank our external reviewers for their valuable feedback throughout the writing process.},
booktitle = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice},
pages = {xv–xvi}
}

@article{10.14778/3236187.3236188,
author = {Mahajan, Divya and Kim, Joon Kyung and Sacks, Jacob and Ardalan, Adel and Kumar, Arun and Esmaeilzadeh, Hadi},
title = {In-RDBMS Hardware Acceleration of Advanced Analytics},
year = {2018},
issue_date = {July 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3236187.3236188},
doi = {10.14778/3236187.3236188},
abstract = {The data revolution is fueled by advances in machine learning, databases, and hardware design. Programmable accelerators are making their way into each of these areas independently. As such, there is a void of solutions that enables hardware acceleration at the intersection of these disjoint fields. This paper sets out to be the initial step towards a unifying solution for in-Database Acceleration of Advanced Analytics (DAnA). Deploying specialized hardware, such as FPGAs, for in-database analytics currently requires hand-designing the hardware and manually routing the data. Instead, DAnA automatically maps a high-level specification of advanced analytics queries to an FPGA accelerator. The accelerator implementation is generated for a User Defined Function (UDF), expressed as a part of an SQL query using a Python-embedded Domain-Specific Language (DSL). To realize an efficient in-database integration, DAnA accelerators contain a novel hardware structure, Striders, that directly interface with the buffer pool of the database. Striders extract, cleanse, and process the training data tuples that are consumed by a multi-threaded FPGA engine that executes the analytics algorithm. We integrate DAnA with PostgreSQL to generate hardware accelerators for a range of real-world and synthetic datasets running diverse ML algorithms. Results show that DAnA-enhanced PostgreSQL provides, on average, 8.3\texttimes{} end-to-end speedup for real datasets, with a maximum of 28.2\texttimes{}. Moreover, DAnA-enhanced PostgreSQL is, on average, 4.0\texttimes{} faster than the multi-threaded Apache MADLib running on Greenplum. DAnA provides these benefits while hiding the complexity of hardware design from data scientists and allowing them to express the algorithm in ≈30-60 lines of Python.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {1317–1331},
numpages = {15}
}

@inproceedings{10.1145/3550355.3552421,
author = {Saini, Rijul and Mussbacher, Gunter and Guo, Jin L. C. and Kienzle, J\"{o}rg},
title = {Machine Learning-Based Incremental Learning in Interactive Domain Modelling},
year = {2022},
isbn = {9781450394666},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550355.3552421},
doi = {10.1145/3550355.3552421},
abstract = {In domain modelling, practitioners manually transform informal requirements written in natural language (problem descriptions) to more concise and analyzable domain models expressed with class diagrams. With automated domain modelling support using existing approaches, manual modifications may still be required in extracted domain models and problem descriptions to make them more accurate and concise. For example, educators teaching software engineering courses at universities usually use an incremental approach to build modelling exercises to restrict students in using intended modelling patterns. These modifications result in the evolution of domain modelling exercises over time. To assist practitioners in this evolution, a synergy between interactive support and automated domain modelling is required. In this paper, we propose a bot-assisted approach to allow practitioners perform domain modelling quickly and interactively. Furthermore, we provide an incremental learning strategy empowered by machine learning to improve the accuracy of the bot's suggestions and extracted domain models by analyzing practitioners' decisions over time. We evaluate the performance of our bot using test problem descriptions which shows that practitioners can expect to get useful support from the bot when applied to exercises of similar size and complexity, with precision, recall, and F2 scores over 85%. Finally, we evaluate our incremental learning strategy where we observe a reduction in the required manual modifications by 70% and an improvement of F2 scores of extracted domain models by 4.2% when using our proposed approach and learning strategy together.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems},
pages = {176–186},
numpages = {11},
keywords = {bot, decisions, domain models, incremental learning, evolution, machine learning (ML), natural language processing (NLP)},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/3417990.3421385,
author = {Saini, Rijul and Mussbacher, Gunter and Guo, Jin L. C. and Kienzle, J\"{o}rg},
title = {DoMoBOT: A Bot for Automated and Interactive Domain Modelling},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3421385},
doi = {10.1145/3417990.3421385},
abstract = {Domain modelling transforms domain problem descriptions written in natural language (NL) into analyzable and concise domain models (class diagrams) during requirements analysis or the early stages of design in software development. Since the practice of domain modelling requires time in addition to modelling skills and experience, several approaches have been proposed to automate or semi-automate the construction of domain models from problem descriptions expressed in NL. Despite the existing work on domain model extraction, some significant challenges remain unaddressed: (i) the extracted domain models are not accurate enough to be used directly or with minor modifications in software development, (ii) existing approaches do not facilitate the tracing of the rationale behind the modelling decisions taken by the model extractor, and (iii) existing approaches do not provide interactive interfaces to update the extracted domain models. Therefore, in this paper, we introduce a domain modelling bot called DoMoBOT, explain its architecture, and implement it in the form of a web-based prototype tool. The bot automatically extracts a domain model from a problem description written in NL with an accuracy higher than existing approaches. Furthermore, the bot enables modellers to update a part of the extracted domain model and in response the bot re-configures the other parts of the domain model pro-actively. To improve the accuracy of extracted domain models, we combine the techniques of Natural Language Processing and Machine Learning. Finally, we evaluate the accuracy of the extracted domain models.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {45},
numpages = {10},
keywords = {machine learning (ML), natural language (NL), predictive model, bot, descriptive model, domain model, artificial intelligence (AI), neural networks, natural language processing (NLP)},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3417990.3419486,
author = {Saini, Rijul},
title = {Artificial Intelligence Empowered Domain Modelling Bot},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3419486},
doi = {10.1145/3417990.3419486},
abstract = {With the increasing adoption of Model-Based Software Engineering (MBSE) to handle the complexity of modern software systems in industry and inclusion of modelling topics in academic curricula, it is no longer a question of whether to use MBSE but how to use it. Acquiring modelling skills to properly build and use models with the help of modelling formalisms are non-trivial learning objectives, which novice modellers struggle to achieve for several reasons. For example, it is difficult for novice modellers to learn to use their abstraction abilities. Also, due to high student-teacher ratios in a typical classroom setting, novice modellers may not receive personalized and timely feedback on their modelling decisions. These issues hinder the novice modellers in improving their modelling skills. Furthermore, a lack of modelling skills among modellers inhibits the adoption and practice of modelling in industry. Therefore, an automated and intelligent solution is required to help modellers and other practitioners in improving their modelling skills. This doctoral research builds an automated and intelligent solution for one modelling formalism - domain models, in an avatar of a domain modelling bot. The bot automatically extracts domain models from problem descriptions written in natural language and generates intelligent recommendations, particularly for teaching modelling literacy to novice modellers. For this domain modelling bot, we leverage the capabilities of various Artificial Intelligence techniques such as Natural Language Processing and Machine Learning.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {26},
numpages = {6},
keywords = {natural language processing (NLP), domain model, natural language (NL), bot, machine learning (ML), artificial intelligence (AI)},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3417990.3418742,
author = {Boubekeur, Younes and Mussbacher, Gunter},
title = {Towards a Better Understanding of Interactions with a Domain Modeling Assistant},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3418742},
doi = {10.1145/3417990.3418742},
abstract = {The enrolment of software engineering students has increased rapidly in the past few years following industry demand. At the same time, model-driven engineering (MDE) continues to become relevant to more domains like embedded systems and machine learning. It is therefore important to teach students MDE skills in an effective manner to prepare them for future careers in academia and industry. The use of interactive online tools can help instructors deliver course material to more students in a more efficient manner, allowing them to offload repetitive or tedious tasks to these systems and focus on other teaching activities that cannot be easily automated. Interactive online tools can provide students with a more engaging learning experience than static resources like books or written exercises. Domain modeling with class diagrams is a fundamental modeling activity in MDE. While there exist multiple modeling tools that allow students to build a domain model, none of them offer an interactive learning experience. In this paper, we explore the interactions between a student modeler and an interactive domain modeling assistant with the aim of better understanding the required interaction. We illustrate desired interactions with three examples and then formalize them in a metamodel. Based on the metamodel, we explain how to form a corpus of learning material that supports the assistant interactions.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {21},
numpages = {10},
keywords = {feedback, domain model, chatbot, class diagram, learning corpus},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3039895.3039898,
author = {Dethlefs, Nina and Hawick, Ken},
title = {DEFIne: A Fluent Interface DSL for Deep Learning Applications},
year = {2017},
isbn = {9781450348454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3039895.3039898},
doi = {10.1145/3039895.3039898},
abstract = {Recent years have seen a surge of interest in deep learning models that outperform other machine learning algorithms on benchmarks across many disciplines. Most existing deep learning libraries facilitate the development of neural nets by providing a mathematical framework that helps users implement their models more efficiently. This still represents a substantial investment of time and effort, however, when the intention is to compare a range of competing models quickly for a specific task. We present DEFIne, a fluent interface DSL for the specification, optimisation and evaluation of deep learning models. The fluent interface is implemented through method chaining. DEFIne is embedded in Python and is build on top of its most popular deep learning libraries, Keras and Theano. It extends these with common operations for data pre-processing and representation as well as visualisation of datasets and results. We test our framework on three benchmark tasks from different domains: heart disease diagnosis, hand-written digit recognition and weather forecast generation. Results in terms of accuracy, runtime and lines of code show that our DSL achieves equivalent accuracy and runtime to state-of-the-art models, while requiring only about 10 lines of code per application.},
booktitle = {Proceedings of the 2nd International Workshop on Real World Domain Specific Languages},
articleno = {3},
numpages = {10},
keywords = {Domain-specific languages, deep learning},
location = {Austin, TX, USA},
series = {RWDSL17}
}

@inproceedings{10.1145/3417990.3420050,
author = {Barzdins, Paulis and Celms, Edgars and Barzdins, Janis and Kalnins, Audris and Sprogis, Arturs and Grasmanis, Mikus and Rikacovs, Sergejs},
title = {Metamodel Specialization Based DSL for DL Lifecycle Data Management},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420050},
doi = {10.1145/3417990.3420050},
abstract = {A new Domain Specific Language (DSL) based approach to Deep Learning (DL) lifecycle data management (LDM) is presented: a very simple but universal DL LDM tool, still usable in practice (called Core tool); and an advanced extension mechanism, that converts the Core tool into a DSL tool building framework for DL LDM tasks. The method used is based on the metamodel specialisation approach for DSL modeling tools introduced by authors.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {16},
numpages = {2},
keywords = {DSL, metamodel specialization, DL lifecycle data management},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.1145/3468044.3468052,
author = {Podobas, Artur and Svedin, Martin and Chien, Steven W. D. and Peng, Ivy B. and Ravichandran, Naresh Balaji and Herman, Pawel and Lansner, Anders and Markidis, Stefano},
title = {StreamBrain: An HPC Framework for Brain-like Neural Networks on CPUs, GPUs and FPGAs},
year = {2021},
isbn = {9781450385497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468044.3468052},
doi = {10.1145/3468044.3468052},
abstract = {The modern deep learning method based on backpropagation has surged in popularity and has been used in multiple domains and application areas. At the same time, there are other - less-known - machine learning algorithms with a mature and solid theoretical foundation whose performance remains unexplored. One such example is the brain-like Bayesian Confidence Propagation Neural Network (BCPNN). In this paper, we introduce StreamBrain--a framework that allows neural networks based on BCPNN to be practically deployed in High-Performance Computing systems. StreamBrain is a domain-specific language (DSL), similar in concept to existing machine learning (ML) frameworks, and supports backends for CPUs, GPUs, and even FPGAs. We empirically demonstrate that StreamBrain can train the well-known ML benchmark dataset MNIST within seconds, and we are the first to demonstrate BCPNN on STL-10 size networks. We also show how StreamBrain can be used to train with custom floating-point formats and illustrate the impact of using different bfloat variations on BCPNN using FPGAs.},
booktitle = {Proceedings of the 11th International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
articleno = {8},
numpages = {6},
keywords = {GPU, Representation learning, AI, HPC, Unsupervised learning, FPGA, BCPNN, Neural networks, Emerging Machine Learning},
location = {Online, Germany},
series = {HEART '21}
}

@inproceedings{10.1145/3378678.3391880,
author = {Sioutas, Savvas and Stuijk, Sander and Basten, Twan and Somers, Lou and Corporaal, Henk},
title = {Programming Tensor Cores from an Image Processing DSL},
year = {2020},
isbn = {9781450371315},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3378678.3391880},
doi = {10.1145/3378678.3391880},
abstract = {Tensor Cores (TCUs) are specialized units first introduced by NVIDIA in the Volta microarchitecture in order to accelerate matrix multiplications for deep learning and linear algebra workloads. While these units have proved to be capable of providing significant speedups for specific applications, their programmability remains difficult for the average user. In this paper, we extend the Halide DSL and compiler with the ability to utilize these units when generating code for a CUDA based NVIDIA GPGPU. To this end, we introduce a new scheduling directive along with custom lowering passes that automatically transform a Halide AST in order to be able to generate code for the TCUs. We evaluate the generated code and show that it can achieve over 5X speedup compared to Halide manual schedules without TCU support, while it remains within 20% of the NVIDIA cuBLAS implementations for mixed precision GEMM and within 10% of manual CUDA implementations with WMMA intrinsics.},
booktitle = {Proceedings of the 23th International Workshop on Software and Compilers for Embedded Systems},
pages = {36–41},
numpages = {6},
keywords = {GPGPUs, Halide, tensor cores, matrix multiplication},
location = {St. Goar, Germany},
series = {SCOPES '20}
}

@inproceedings{10.1145/3097983.3098171,
author = {Cheng, Heng-Tze and Haque, Zakaria and Hong, Lichan and Ispir, Mustafa and Mewald, Clemens and Polosukhin, Illia and Roumpos, Georgios and Sculley, D. and Smith, Jamie and Soergel, David and Tang, Yuan and Tucker, Philipp and Wicke, Martin and Xia, Cassandra and Xie, Jianwei},
title = {TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level Machine Learning Frameworks},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098171},
doi = {10.1145/3097983.3098171},
abstract = {We present a framework for specifying, training, evaluating, and deploying machine learning models. Our focus is on simplifying cutting edge machine learning for practitioners in order to bring such technologies into production. Recognizing the fast evolution of the field of deep learning, we make no attempt to capture the design space of all possible model architectures in a domain-specific language (DSL) or similar configuration language. We allow users to write code to define their models, but provide abstractions that guide developers to write models in ways conducive to productionization. We also provide a unifying Estimator interface, making it possible to write downstream infrastructure (e.g. distributed training, hyperparameter tuning) independent of the model implementation.We balance the competing demands for flexibility and simplicity by offering APIs at different levels of abstraction, making common model architectures available out of the box, while providing a library of utilities designed to speed up experimentation with model architectures. To make out of the box models flexible and usable across a wide range of problems, these canned Estimators are parameterized not only over traditional hyperparameters, but also using feature columns, a declarative specification describing how to interpret input dataWe discuss our experience in using this framework in research and production environments, and show the impact on code health, maintainability, and development speed.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1763–1771},
numpages = {9},
keywords = {high level api, machine learning framework, deep learning},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/3337821.3337883,
author = {Gao, Wei and Fang, Jiarui and Zhao, Wenlai and Yang, Jinzhe and Wang, Long and Gan, Lin and Fu, Haohuan and Yang, Guangwen},
title = {SwATOP: Automatically Optimizing Deep Learning Operators on SW26010 Many-Core Processor},
year = {2019},
isbn = {9781450362955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3337821.3337883},
doi = {10.1145/3337821.3337883},
abstract = {Achieving an optimized mapping of Deep Learning (DL) operators to new hardware architectures is the key to building a scalable DL system. However, handcrafted optimization involves huge engineering efforts, due to the variety of DL operator implementations and complex programming skills. Targeting the innovative many-core processor SW26010 adopted by the 3rd fastest supercomputer Sunway TaihuLight, an end-to-end automated framework called swATOP is presented as a more practical solution for DL operator optimization. Arithmetic intensive DL operators are expressed into an auto-tuning-friendly form, which is based on tensorized primitives. By describing the algorithm of a DL operator using our domain specific language (DSL), swATOP is able to derive and produce an optimal implementation by separating hardware-dependent optimization and hardware-agnostic optimization. Hardware-dependent optimization is encapsulated in a set of tensorized primitives with sufficient utilization of the underlying hardware features. The hardware-agnostic optimization contains a scheduler, an intermediate representation (IR) optimizer, an auto-tuner, and a code generator. These modules cooperate to perform an automatic design space exploration, to apply a set of programming techniques, to discover a near-optimal solution, and to generate the executable code. Our experiments show that swATOP is able to bring significant performance improvement on DL operators in over 88% of cases, compared with the best-handcrafted optimization. Compared to a black-box autotuner, the tuning and code generation time can be reduced to minutes from days using swATOP.},
booktitle = {Proceedings of the 48th International Conference on Parallel Processing},
articleno = {89},
numpages = {10},
keywords = {Deep Learning Operators, SW26010, Autotuning},
location = {Kyoto, Japan},
series = {ICPP 2019}
}

@inproceedings{10.1145/3417990.3420050,
author = {Barzdins, Paulis and Celms, Edgars and Barzdins, Janis and Kalnins, Audris and Sprogis, Arturs and Grasmanis, Mikus and Rikacovs, Sergejs},
title = {Metamodel Specialization Based DSL for DL Lifecycle Data Management},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420050},
doi = {10.1145/3417990.3420050},
abstract = {A new Domain Specific Language (DSL) based approach to Deep Learning (DL) lifecycle data management (LDM) is presented: a very simple but universal DL LDM tool, still usable in practice (called Core tool); and an advanced extension mechanism, that converts the Core tool into a DSL tool building framework for DL LDM tasks. The method used is based on the metamodel specialisation approach for DSL modeling tools introduced by authors.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {16},
numpages = {2},
keywords = {DSL, metamodel specialization, DL lifecycle data management},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@article{10.1145/3355606,
author = {Vasilache, Nicolas and Zinenko, Oleksandr and Theodoridis, Theodoros and Goyal, Priya and Devito, Zachary and Moses, William S. and Verdoolaege, Sven and Adams, Andrew and Cohen, Albert},
title = {The Next 700 Accelerated Layers: From Mathematical Expressions of Network Computation Graphs to Accelerated GPU Kernels, Automatically},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3355606},
doi = {10.1145/3355606},
abstract = {Deep learning frameworks automate the deployment, distribution, synchronization, memory allocation, and hardware acceleration of models represented as graphs of computational operators. These operators wrap high-performance libraries such as cuDNN or NNPACK. When the computation does not match any predefined library call, custom operators must be implemented, often at high engineering cost and performance penalty, limiting the pace of innovation. To address this productivity gap, we propose and evaluate: (1) a domain-specific language with a tensor notation close to the mathematics of deep learning; (2) a Just-In-Time optimizing compiler based on the polyhedral framework; (3) carefully coordinated linear optimization and evolutionary algorithms to synthesize high-performance CUDA kernels; (4) the transparent integration of our flow into PyTorch and Caffe2, providing the fully automatic synthesis of high-performance GPU kernels from simple tensor algebra. The performance is comparable to, and often exceeds the performance of, highly tuned libraries.},
journal = {ACM Trans. Archit. Code Optim.},
month = {oct},
articleno = {38},
numpages = {26},
keywords = {Deep learning layers, GPU acceleration, polyhedral compilation}
}

@inproceedings{10.1145/3468044.3468052,
author = {Podobas, Artur and Svedin, Martin and Chien, Steven W. D. and Peng, Ivy B. and Ravichandran, Naresh Balaji and Herman, Pawel and Lansner, Anders and Markidis, Stefano},
title = {StreamBrain: An HPC Framework for Brain-like Neural Networks on CPUs, GPUs and FPGAs},
year = {2021},
isbn = {9781450385497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468044.3468052},
doi = {10.1145/3468044.3468052},
abstract = {The modern deep learning method based on backpropagation has surged in popularity and has been used in multiple domains and application areas. At the same time, there are other - less-known - machine learning algorithms with a mature and solid theoretical foundation whose performance remains unexplored. One such example is the brain-like Bayesian Confidence Propagation Neural Network (BCPNN). In this paper, we introduce StreamBrain--a framework that allows neural networks based on BCPNN to be practically deployed in High-Performance Computing systems. StreamBrain is a domain-specific language (DSL), similar in concept to existing machine learning (ML) frameworks, and supports backends for CPUs, GPUs, and even FPGAs. We empirically demonstrate that StreamBrain can train the well-known ML benchmark dataset MNIST within seconds, and we are the first to demonstrate BCPNN on STL-10 size networks. We also show how StreamBrain can be used to train with custom floating-point formats and illustrate the impact of using different bfloat variations on BCPNN using FPGAs.},
booktitle = {Proceedings of the 11th International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
articleno = {8},
numpages = {6},
keywords = {Unsupervised learning, Emerging Machine Learning, FPGA, AI, Neural networks, BCPNN, Representation learning, GPU, HPC},
location = {Online, Germany},
series = {HEART '21}
}

@inproceedings{10.1145/3097983.3098171,
author = {Cheng, Heng-Tze and Haque, Zakaria and Hong, Lichan and Ispir, Mustafa and Mewald, Clemens and Polosukhin, Illia and Roumpos, Georgios and Sculley, D. and Smith, Jamie and Soergel, David and Tang, Yuan and Tucker, Philipp and Wicke, Martin and Xia, Cassandra and Xie, Jianwei},
title = {TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level Machine Learning Frameworks},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098171},
doi = {10.1145/3097983.3098171},
abstract = {We present a framework for specifying, training, evaluating, and deploying machine learning models. Our focus is on simplifying cutting edge machine learning for practitioners in order to bring such technologies into production. Recognizing the fast evolution of the field of deep learning, we make no attempt to capture the design space of all possible model architectures in a domain-specific language (DSL) or similar configuration language. We allow users to write code to define their models, but provide abstractions that guide developers to write models in ways conducive to productionization. We also provide a unifying Estimator interface, making it possible to write downstream infrastructure (e.g. distributed training, hyperparameter tuning) independent of the model implementation.We balance the competing demands for flexibility and simplicity by offering APIs at different levels of abstraction, making common model architectures available out of the box, while providing a library of utilities designed to speed up experimentation with model architectures. To make out of the box models flexible and usable across a wide range of problems, these canned Estimators are parameterized not only over traditional hyperparameters, but also using feature columns, a declarative specification describing how to interpret input dataWe discuss our experience in using this framework in research and production environments, and show the impact on code health, maintainability, and development speed.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1763–1771},
numpages = {9},
keywords = {high level api, machine learning framework, deep learning},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@article{10.14778/3554821.3554836,
author = {Mishchenko, Andrey and Danco, Dominique and Jindal, Abhilash and Blue, Adrian},
title = {Blueprint: A Constraint-Solving Approach for Document Extraction},
year = {2022},
issue_date = {August 2022},
publisher = {VLDB Endowment},
volume = {15},
number = {12},
issn = {2150-8097},
url = {https://doi.org/10.14778/3554821.3554836},
doi = {10.14778/3554821.3554836},
abstract = {Blueprint is a declarative domain-specific language for document extraction. Users describe document layout using spatial, textual, semantic, and numerical fuzzy constraints, and the language runtime extracts the field-value mappings that best satisfy the constraints in a given document.We used Blueprint to develop several document extraction solutions in a commercial setting. This approach to the extraction problem proved powerful. Concise Blueprint programs were able to generate good accuracy on a broad set of use cases. However, a major goal of our work was to build a system that non-experts, and in particular non-engineers, could use effectively, and we found that writing declarative fuzzy constraint-based extraction programs was not intuitive for many users: a large up-front learning investment was required to be effective, and debugging was often challenging.To address these issues, we developed a no-code IDE for Blueprint, called Studio, as well as program synthesis functionality for automatically generating Blueprint programs from training data, which could be created by labeling document samples in our IDE. Overall, the IDE significantly improved the Blueprint development experience and the results users were able to achieve.In this paper, we discuss the design, implementation, and deployment of Blueprint and Studio. We compare our system with a state-of-the-art deep-learning based extraction tool and show that our system can achieve comparable accuracy results, with comparable development time, for appropriately-chosen use cases, while providing better interpretability and debuggability.},
journal = {Proc. VLDB Endow.},
month = {sep},
pages = {3459–3471},
numpages = {13}
}

@inproceedings{10.1145/3337821.3337883,
author = {Gao, Wei and Fang, Jiarui and Zhao, Wenlai and Yang, Jinzhe and Wang, Long and Gan, Lin and Fu, Haohuan and Yang, Guangwen},
title = {SwATOP: Automatically Optimizing Deep Learning Operators on SW26010 Many-Core Processor},
year = {2019},
isbn = {9781450362955},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3337821.3337883},
doi = {10.1145/3337821.3337883},
abstract = {Achieving an optimized mapping of Deep Learning (DL) operators to new hardware architectures is the key to building a scalable DL system. However, handcrafted optimization involves huge engineering efforts, due to the variety of DL operator implementations and complex programming skills. Targeting the innovative many-core processor SW26010 adopted by the 3rd fastest supercomputer Sunway TaihuLight, an end-to-end automated framework called swATOP is presented as a more practical solution for DL operator optimization. Arithmetic intensive DL operators are expressed into an auto-tuning-friendly form, which is based on tensorized primitives. By describing the algorithm of a DL operator using our domain specific language (DSL), swATOP is able to derive and produce an optimal implementation by separating hardware-dependent optimization and hardware-agnostic optimization. Hardware-dependent optimization is encapsulated in a set of tensorized primitives with sufficient utilization of the underlying hardware features. The hardware-agnostic optimization contains a scheduler, an intermediate representation (IR) optimizer, an auto-tuner, and a code generator. These modules cooperate to perform an automatic design space exploration, to apply a set of programming techniques, to discover a near-optimal solution, and to generate the executable code. Our experiments show that swATOP is able to bring significant performance improvement on DL operators in over 88% of cases, compared with the best-handcrafted optimization. Compared to a black-box autotuner, the tuning and code generation time can be reduced to minutes from days using swATOP.},
booktitle = {Proceedings of the 48th International Conference on Parallel Processing},
articleno = {89},
numpages = {10},
keywords = {Deep Learning Operators, SW26010, Autotuning},
location = {Kyoto, Japan},
series = {ICPP 2019}
}

@inproceedings{10.5555/2662593.2662595,
author = {Hastjarjanto, Tom and Jeuring, Johan and Leather, Sean},
title = {A DSL for Describing the Artificial Intelligence in Real-Time Video Games},
year = {2013},
isbn = {9781467362634},
publisher = {IEEE Press},
abstract = {Many games have computer-controlled agents that play against a player. The behavior of these computer-controlled agents is described by means of the artificial intelligence (AI) in the game. The AI is an important component of the game, and needs to be developed carefully, and adapted regularly. This paper introduces a novel language for describing the decision making process of the AI in real-time video games. We develop a declarative, domain-specific language (DSL) embedded in the functional programming language Haskell for real-time video games. We use the DSL to describe the AI of a prototype real-time video game.},
booktitle = {Proceedings of the 3rd International Workshop on Games and Software Engineering: Engineering Computer Games to Enable Positive, Progressive Change},
pages = {8–14},
numpages = {7},
location = {San Francisco, California},
series = {GAS '13}
}

@inproceedings{10.5555/2008503.2008556,
author = {Lortal, Ga\"{e}lle and Dhouib, Saadia and G\'{e}rard, S\'{e}bastien},
title = {Integrating Ontological Domain Knowledge into a Robotic DSL},
year = {2010},
isbn = {9783642212093},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Coming from the Artificial Intelligence (AI) and Semantic Web (SW) circles, ontologies are used mainly to represent domains. The Model Driven Engineering (MDE) field gave birth to Domain Specific Languages to represent a particular technical domain. Abstracting from their uses, we consider as many others researchers that ontologies and models are closer than their original fields could get to think. Furthermore, their building or development are facing the same problems. They are costly and need experts' interviews in order to grasp specific knowledge and structure it. Likewise, ontologies and DSL can benefit from each other domains in reusing construction methodologies and even reusing knowledge modelled in another format. In this paper we first present the ontologies and DSL definition we use and some methodologies of development enabling the reuse of knowledge (as alignment, fusion). We then present how we propose to reuse the knowledge of a robotic ontology to develop robotic DSLs within the PROTEUS project in order to inject readymade domain information to the DSL.},
booktitle = {Proceedings of the 2010 International Conference on Models in Software Engineering},
pages = {401–414},
numpages = {14},
location = {Oslo, Norway},
series = {MODELS'10}
}

@inproceedings{10.1145/3339252.3339278,
author = {Stelly, Christopher and Roussev, Vassil},
title = {Language-Based Integration of Digital Forensics &amp; Incident Response},
year = {2019},
isbn = {9781450371643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339252.3339278},
doi = {10.1145/3339252.3339278},
abstract = {In the cybersecurity domain, the level of standardization and interoperability among cybersecurity products from different vendors, including open-source ones, is fairly low. Although understandable from a business perspective, this deficiency makes it difficult and expensive for analysts to put together custom solutions and to have visibility across their entire IT infrastructure. It also hampers the adoption of custom data analytics and AI solutions, and slows down the exchange of threat detection and mitigation solutions.Recently, the Nugget domain specific language (DSL) has been proposed as a solution to the integration of digital forensics computations. The essential idea is to use a data flow language, somewhat similar to SQL, and an extensible run-time environment to decouple the specification of forensic computations from their implementation.In this paper, we study the integration of Nugget with security monitoring tools; specifically, we integrate Google's GRR incident response framework, and the de facto standard for log aggregation: Splunk. We demonstrate the utility of this type standardization to both tool developers and end-user analysts/IT administrators. We discuss potential implications of having such a DSL becoming widely adopted across the entire domain of cybersecurity.},
booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
articleno = {27},
numpages = {6},
keywords = {digital forensics, nugget, domain specific language, incident response, grr},
location = {Canterbury, CA, United Kingdom},
series = {ARES '19}
}

@inproceedings{10.1145/1133981.1134003,
author = {Johnson, Troy A. and Eigenmann, Rudolf},
title = {Context-Sensitive Domain-Independent Algorithm Composition and Selection},
year = {2006},
isbn = {1595933204},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1133981.1134003},
doi = {10.1145/1133981.1134003},
abstract = {Progressing beyond the productivity of present-day languages appears to require using domain-specific knowledge. Domain-specific languages and libraries (DSLs) proliferate, but most optimizations and language features have limited portability because each language's semantics are related closely to its domain. We explain how any DSL compiler can use a domain-independent AI planner to implement algorithm composition as a language feature. Our notion of composition addresses a common DSL problem: good library designers tend to minimize redundancy by including only fundamental procedures that users must chain together into call sequences. Novice users are confounded by not knowing an appropriate sequence to achieve their goal. Composition allows the programmer to define and call an abstract algorithm (AA) like a procedure. The compiler replaces an AA call with a sequence of library calls, while considering the calling context. Because AI planners compute a sequence of operations to reach a goal state, the compiler can implement composition by analyzing the calling context to provide the planner's initial state. Nevertheless, mapping composition onto planning is not straightforward because applying planning to software requires extensions to classical planning, and procedure specifications may be incomplete when expressed in a planning language. Compositions may not be provably correct, so our approach mitigates semantic incompleteness with unobtrusive programmer-compiler interaction. This tradeoff is key to making composition a practical and natural feature of otherwise imperative languages, whose users eschew complex logical specifications. Compositions satisfying an AA may not be equal in performance, memory usage, or precision and require selection of a preferred solution. We examine language design and implementation issues, and we perform a case study on the BioPerl bioinformatics library.},
booktitle = {Proceedings of the 27th ACM SIGPLAN Conference on Programming Language Design and Implementation},
pages = {181–192},
numpages = {12},
keywords = {algorithm composition, algorithm selection, automated planning, bioinformatics, domain-specific languages},
location = {Ottawa, Ontario, Canada},
series = {PLDI '06}
}

@article{10.1145/1133255.1134003,
author = {Johnson, Troy A. and Eigenmann, Rudolf},
title = {Context-Sensitive Domain-Independent Algorithm Composition and Selection},
year = {2006},
issue_date = {June 2006},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {41},
number = {6},
issn = {0362-1340},
url = {https://doi.org/10.1145/1133255.1134003},
doi = {10.1145/1133255.1134003},
abstract = {Progressing beyond the productivity of present-day languages appears to require using domain-specific knowledge. Domain-specific languages and libraries (DSLs) proliferate, but most optimizations and language features have limited portability because each language's semantics are related closely to its domain. We explain how any DSL compiler can use a domain-independent AI planner to implement algorithm composition as a language feature. Our notion of composition addresses a common DSL problem: good library designers tend to minimize redundancy by including only fundamental procedures that users must chain together into call sequences. Novice users are confounded by not knowing an appropriate sequence to achieve their goal. Composition allows the programmer to define and call an abstract algorithm (AA) like a procedure. The compiler replaces an AA call with a sequence of library calls, while considering the calling context. Because AI planners compute a sequence of operations to reach a goal state, the compiler can implement composition by analyzing the calling context to provide the planner's initial state. Nevertheless, mapping composition onto planning is not straightforward because applying planning to software requires extensions to classical planning, and procedure specifications may be incomplete when expressed in a planning language. Compositions may not be provably correct, so our approach mitigates semantic incompleteness with unobtrusive programmer-compiler interaction. This tradeoff is key to making composition a practical and natural feature of otherwise imperative languages, whose users eschew complex logical specifications. Compositions satisfying an AA may not be equal in performance, memory usage, or precision and require selection of a preferred solution. We examine language design and implementation issues, and we perform a case study on the BioPerl bioinformatics library.},
journal = {SIGPLAN Not.},
month = {jun},
pages = {181–192},
numpages = {12},
keywords = {algorithm selection, domain-specific languages, automated planning, algorithm composition, bioinformatics}
}

@inproceedings{10.1109/MODELS-C.2019.00028,
author = {Burgue\~{n}o, Loli and Burdusel, Alexandru and G\'{e}rard, S\'{e}bastien and Wimmer, Manuel},
title = {MDE Intelligence 2019: 1st Workshop on Artificial Intelligence and Model-Driven Engineering},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00028},
doi = {10.1109/MODELS-C.2019.00028},
abstract = {Model-driven engineering (MDE) and Artificial Intelligence (AI) are two separate fields in computer science, which can clearly benefit from cross-fertilization and collaboration. There are at least two ways in which such integrations---which we call MDE Intelligence---can manifest: (1) MDE can benefit from integrating AI concepts and ideas to increasing the power and flexibility of model-driven techniques by means of the application of AI algorithms. (2) Conversely, AI can benefit from integrating concepts and ideas from MDE---for example, using domain-specific languages and model transformations allows domain experts to directly express and manipulate their problems while providing an auditable computation pipeline.To discuss and further stimulate such integrations, the 1st edition of the Workshop on Artificial Intelligence and Model-driven Engineering (MDE Intelligence) was held on September 16, 2019 in Munich, Germany, as part of the satellite events of the IEEE/ACM 22th International Conference on Model-Driven Engineering Languages and Systems (MODELS 2019).},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {168–169},
numpages = {2},
keywords = {artificial intelligence, MDE intelligence, MDE},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1145/3550356.3561609,
author = {Bergelin, Johan and Strandberg, Per Erik},
title = {Industrial Requirements for Supporting AI-Enhanced Model-Driven Engineering},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561609},
doi = {10.1145/3550356.3561609},
abstract = {There is an increasing interest in research on the combination of AI techniques and methods with MDE. However, there is a gap between AI and MDE practices, as well as between researchers and practitioners. This paper tackles this gap by reporting on industrial requirements in this field. In the AIDOaRt research project, practitioners and researchers collaborate on AI-augmented automation supporting modeling, coding, testing, monitoring, and continuous development in cyber-physical systems. The project specifically lies at the intersection of industry and academia collaboration with several industrial use cases. Through a process of elicitation and refinement, 78 high-level requirements were defined, and generalized into 30 generic requirements by the AIDOaRt partners. The main contribution of this paper is the set of generic requirements from the project for enhancing the development of cyber-physical systems with artificial intelligence, DevOps, and model-driven engineering, identifying the hot spots of industry needs in the interactions of MDE and AI. Future work will refine, implement and evaluate solutions toward these requirements in industry contexts.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {375–379},
numpages = {5},
keywords = {artificial intelligence, model-driven engineering, cyber-physical systems, requirements},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/2829875.2829880,
author = {Garcia-Sanjuan, Fernando and Jaen, Javier and Catala, Alejandro},
title = {Multi-Display Environments to Foster Emotional Intelligence in Hospitalized Children},
year = {2015},
isbn = {9781450334631},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2829875.2829880},
doi = {10.1145/2829875.2829880},
abstract = {Long-term and frequent hospitalized children are under high loads of emotional stress, which affects their well-being in addition to the illness they are suffering. This thesis proposes and will focus on an approach to use Multi-Display Environments (MDE) in pediatric hospitalization contexts to improve patients' emotional intelligence so they can deal with the negative emotions produced by their situation.},
booktitle = {Proceedings of the XVI International Conference on Human Computer Interaction},
articleno = {13},
numpages = {2},
keywords = {Emotional Intelligence, Hospitalization, Multi-Display Environments (MDE), Socialization, Child-Computer Interaction},
location = {Vilanova i la Geltru, Spain},
series = {Interacci\'{o}n '15}
}

@inproceedings{10.5555/1762828.1762852,
author = {Nechypurenko, Andrey and Wuchner, Egon and White, Jules and Schmidt, Douglas C.},
title = {Applying Model Intelligence Frameworks for Deployment Problem in Real-Time and Embedded Systems},
year = {2006},
isbn = {9783540694885},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {There are many application domains, such as distributed real-time and embedded (DRE) systems, where the domain constraints are so restrictive and the solution spaces so large that it is infeasible for modelers to produce correct solution manually using a conventional graphical model-based approach. In DRE systems the available resources, such as memory, CPU, and bandwidth, must be managed carefully to ensure a certain level of quality of service. This paper provides three contributions to simplify modeling of complex application domains: (1) we present our approach of combining model intelligence and domain-specific solvers with model-driven engineering (MDE) environments, (2) we show techniques for automatically guiding modelers to correct solutions and how to support the specification of large and complex systems using intelligent mechanisms to complete partially specified models, and (3) we present the results of applying an MDE tool that maps software components to Electronic Control Units (ECUs) using the typical automotive modeling and middleware infrastructure.},
booktitle = {Proceedings of the 2006 International Conference on Models in Software Engineering},
pages = {143–151},
numpages = {9},
keywords = {constraint solver, modeling, prolog, automotive, model completion, model checking},
location = {Genoa, Italy},
series = {MoDELS'06}
}

@inproceedings{10.5555/2008503.2008556,
author = {Lortal, Ga\"{e}lle and Dhouib, Saadia and G\'{e}rard, S\'{e}bastien},
title = {Integrating Ontological Domain Knowledge into a Robotic DSL},
year = {2010},
isbn = {9783642212093},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Coming from the Artificial Intelligence (AI) and Semantic Web (SW) circles, ontologies are used mainly to represent domains. The Model Driven Engineering (MDE) field gave birth to Domain Specific Languages to represent a particular technical domain. Abstracting from their uses, we consider as many others researchers that ontologies and models are closer than their original fields could get to think. Furthermore, their building or development are facing the same problems. They are costly and need experts' interviews in order to grasp specific knowledge and structure it. Likewise, ontologies and DSL can benefit from each other domains in reusing construction methodologies and even reusing knowledge modelled in another format. In this paper we first present the ontologies and DSL definition we use and some methodologies of development enabling the reuse of knowledge (as alignment, fusion). We then present how we propose to reuse the knowledge of a robotic ontology to develop robotic DSLs within the PROTEUS project in order to inject readymade domain information to the DSL.},
booktitle = {Proceedings of the 2010 International Conference on Models in Software Engineering},
pages = {401–414},
numpages = {14},
location = {Oslo, Norway},
series = {MODELS'10}
}

@inproceedings{10.1109/MODELS-C.2019.00028,
author = {Burgue\~{n}o, Loli and Burdusel, Alexandru and G\'{e}rard, S\'{e}bastien and Wimmer, Manuel},
title = {MDE Intelligence 2019: 1st Workshop on Artificial Intelligence and Model-Driven Engineering},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00028},
doi = {10.1109/MODELS-C.2019.00028},
abstract = {Model-driven engineering (MDE) and Artificial Intelligence (AI) are two separate fields in computer science, which can clearly benefit from cross-fertilization and collaboration. There are at least two ways in which such integrations---which we call MDE Intelligence---can manifest: (1) MDE can benefit from integrating AI concepts and ideas to increasing the power and flexibility of model-driven techniques by means of the application of AI algorithms. (2) Conversely, AI can benefit from integrating concepts and ideas from MDE---for example, using domain-specific languages and model transformations allows domain experts to directly express and manipulate their problems while providing an auditable computation pipeline.To discuss and further stimulate such integrations, the 1st edition of the Workshop on Artificial Intelligence and Model-driven Engineering (MDE Intelligence) was held on September 16, 2019 in Munich, Germany, as part of the satellite events of the IEEE/ACM 22th International Conference on Model-Driven Engineering Languages and Systems (MODELS 2019).},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {168–169},
numpages = {2},
keywords = {artificial intelligence, MDE intelligence, MDE},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1145/2422518.2422519,
author = {Bencomo, Nelly and Blair, Gordon and G\"{o}tz, Sebastian and Morin, Brice and Rumpe, Bernhard},
title = {Summary of the 7th International Workshop on Models@run.Time},
year = {2012},
isbn = {9781450318020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2422518.2422519},
doi = {10.1145/2422518.2422519},
abstract = {The Models@run.time (MRT) workshop series offers a discussion forum for the rising need to leverage modeling techniques for the software of the future. The main goals are to explore the benefits of models@run.time and to foster collaboration and cross-fertilization between different research communities like for example like model-driven engineering (e.g. MODELS), self-adaptive/autonomous systems communities (e.g., SEAMS and ICAC), the control theory community and the artificial intelligence community.},
booktitle = {Proceedings of the 7th Workshop on Models@run.Time},
pages = {1–2},
numpages = {2},
keywords = {abstraction, runtime models, MDE, runtime adaptation, runtime abstractions, reflection},
location = {Innsbruck, Austria},
series = {MRT '12}
}

@inproceedings{10.5555/3400397.3400521,
author = {Benaben, Frederick and Lauras, Matthieu and Fertier, Audrey and Salatg\'{e}, Nicolas},
title = {Integrating Model-Driven Engineering as the next Challenge for Artificial Intelligence: Application to Risk and Crisis Management},
year = {2020},
isbn = {9781728132839},
publisher = {IEEE Press},
abstract = {Artificial Intelligence (AI) is currently on top of the hype regarding simultaneously research publications and industrial development. However, the current status of AI makes it quite far and different from the current understanding of Human intelligence. One suggestion that is made in this article is that Model-Driven approaches could be considered as an interesting avenue to complement classical visions of AI and to provide some missing features. Specifically, the use of Model-Driven Engineering tools (such as metamodel and model transformation) could benefit to the domain of AI by introducing a way to extend the apprehension of unknown situations. To support that proposal, an illustrative example is provided regarding the domain of risk and crisis management.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {1549–1563},
numpages = {15},
location = {National Harbor, Maryland},
series = {WSC '19}
}

@inproceedings{10.5555/1762828.1762852,
author = {Nechypurenko, Andrey and Wuchner, Egon and White, Jules and Schmidt, Douglas C.},
title = {Applying Model Intelligence Frameworks for Deployment Problem in Real-Time and Embedded Systems},
year = {2006},
isbn = {9783540694885},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {There are many application domains, such as distributed real-time and embedded (DRE) systems, where the domain constraints are so restrictive and the solution spaces so large that it is infeasible for modelers to produce correct solution manually using a conventional graphical model-based approach. In DRE systems the available resources, such as memory, CPU, and bandwidth, must be managed carefully to ensure a certain level of quality of service. This paper provides three contributions to simplify modeling of complex application domains: (1) we present our approach of combining model intelligence and domain-specific solvers with model-driven engineering (MDE) environments, (2) we show techniques for automatically guiding modelers to correct solutions and how to support the specification of large and complex systems using intelligent mechanisms to complete partially specified models, and (3) we present the results of applying an MDE tool that maps software components to Electronic Control Units (ECUs) using the typical automotive modeling and middleware infrastructure.},
booktitle = {Proceedings of the 2006 International Conference on Models in Software Engineering},
pages = {143–151},
numpages = {9},
keywords = {constraint solver, modeling, prolog, automotive, model completion, model checking},
location = {Genoa, Italy},
series = {MoDELS'06}
}

@inproceedings{10.5555/2008503.2008556,
author = {Lortal, Ga\"{e}lle and Dhouib, Saadia and G\'{e}rard, S\'{e}bastien},
title = {Integrating Ontological Domain Knowledge into a Robotic DSL},
year = {2010},
isbn = {9783642212093},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Coming from the Artificial Intelligence (AI) and Semantic Web (SW) circles, ontologies are used mainly to represent domains. The Model Driven Engineering (MDE) field gave birth to Domain Specific Languages to represent a particular technical domain. Abstracting from their uses, we consider as many others researchers that ontologies and models are closer than their original fields could get to think. Furthermore, their building or development are facing the same problems. They are costly and need experts' interviews in order to grasp specific knowledge and structure it. Likewise, ontologies and DSL can benefit from each other domains in reusing construction methodologies and even reusing knowledge modelled in another format. In this paper we first present the ontologies and DSL definition we use and some methodologies of development enabling the reuse of knowledge (as alignment, fusion). We then present how we propose to reuse the knowledge of a robotic ontology to develop robotic DSLs within the PROTEUS project in order to inject readymade domain information to the DSL.},
booktitle = {Proceedings of the 2010 International Conference on Models in Software Engineering},
pages = {401–414},
numpages = {14},
location = {Oslo, Norway},
series = {MODELS'10}
}

@inproceedings{10.1145/3436829.3436851,
author = {Zahoor, Tayyba and Azam, Farooque and Anwar, Muahmmad Waseem and Tariq, Ayesha and Javaid, Haider Ali},
title = {An Investigation of Smart Parking Tools, Technologies, &amp; Challenges},
year = {2021},
isbn = {9781450377218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3436829.3436851},
doi = {10.1145/3436829.3436851},
abstract = {Urbanization, exceptional increase in population and advancement in technology caused the automotive industry to grow rapidly &amp; automobiles become essential part of daily life. Consequently, finding a parking space particularly in populous zones, is a challenging task. Researchers have proposed different solutions to assist the developments in smart parking systems. In this paper, we have investigated the key tools, techniques &amp; challenges proposed in the recent research studies. Primarily, a Systematic Literature Review is carried out, total 35 studies are explored during time interval of (2015-2019). Subsequently, five major areas are recognized where smart parking is often functional i.e. Internet of Things (IoT) (13 studies), Cloud Computing (2 studies), Model-Driven Engineering (4 studies), Fog Computing (6 studies) and Artificial Intelligence (11 studies). Furthermore, (15) primary tools and (25) algorithms are presented. This article also portray the challenges cited by different studies. The findings of this study will definitely assist the practitioners while deciding the appropriate selections.},
booktitle = {Proceedings of the 2020 9th International Conference on Software and Information Engineering (ICSIE)},
pages = {198–203},
numpages = {6},
keywords = {Smart Parking Tools, Smart Parking, Smart Parking Technologies, Systematic Literature Review, Smart Parking Challenges},
location = {Cairo, Egypt},
series = {ICSIE 2020}
}

@inproceedings{10.1145/3550356.3561609,
author = {Bergelin, Johan and Strandberg, Per Erik},
title = {Industrial Requirements for Supporting AI-Enhanced Model-Driven Engineering},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561609},
doi = {10.1145/3550356.3561609},
abstract = {There is an increasing interest in research on the combination of AI techniques and methods with MDE. However, there is a gap between AI and MDE practices, as well as between researchers and practitioners. This paper tackles this gap by reporting on industrial requirements in this field. In the AIDOaRt research project, practitioners and researchers collaborate on AI-augmented automation supporting modeling, coding, testing, monitoring, and continuous development in cyber-physical systems. The project specifically lies at the intersection of industry and academia collaboration with several industrial use cases. Through a process of elicitation and refinement, 78 high-level requirements were defined, and generalized into 30 generic requirements by the AIDOaRt partners. The main contribution of this paper is the set of generic requirements from the project for enhancing the development of cyber-physical systems with artificial intelligence, DevOps, and model-driven engineering, identifying the hot spots of industry needs in the interactions of MDE and AI. Future work will refine, implement and evaluate solutions toward these requirements in industry contexts.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {375–379},
numpages = {5},
keywords = {artificial intelligence, model-driven engineering, cyber-physical systems, requirements},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.5555/3237383.3237878,
author = {Papapanagiotou, Petros and Davoust, Alan and Murray-Rust, Dave and Manataki, Areti and Van Kleek, Max and Shadbolt, Nigel and Robertson, Dave},
title = {Social Machines for All},
year = {2018},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {In today's interconnected world, people interact to a unprecedented degree through the use of digital platforms and services, forming complex 'social machines'. These are now homes to autonomous agents as well as people, providing an open space where human and computational intelligence can mingle---a new frontier for distributed agent systems. However, participants typically have limited autonomy to define and shape the machines they are part of. In this paper, we envision a future where individuals are able to develop their own Social Machines, enabling them to interact in a trustworthy, decentralized way. To make this possible, development methods and tools must see their barriers-to-entry dramatically lowered. People should be able to specify the agent roles and interaction patterns in an intuitive, visual way, analyse and test their designs and deploy them as easy to use systems. We argue that this is a challenging but realistic goal, which should be tackled by navigating the trade-off between the accessibility of the design methods --primarily the modelling formalisms-- and their expressive power. We support our arguments by drawing ideas from different research areas including electronic institutions, agent-based simulation, process modelling, formal verification, and model-driven engineering.},
booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1208–1212},
numpages = {5},
keywords = {design, social machines, model-driven development, modelling, analysis},
location = {Stockholm, Sweden},
series = {AAMAS '18}
}

@inproceedings{10.1145/1967486.1967492,
author = {Dignum, Frank and Padget, Julian and Vasconcelos, Wamberto},
title = {Organizing Services for a Changing Environment},
year = {2010},
isbn = {9781450304214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1967486.1967492},
doi = {10.1145/1967486.1967492},
abstract = {Service-oriented computing is the "new wave" emerging from the growing up of web services and its adoption of elements of semantic web technology. More sophistication, in response to business requirements, does of course not make it easier to use or to control. In particular business processes demand resilience and (real-time) adaptation in the face of changing business requirements, incorporation of alternative services and finding suitable substitutes when those needed are not available. The EU-funded ALIVE project is prototyping ideas, driven by commercial and industrial uses cases, that utilize research in organizational modelling, software agents, model-driven engineering, artificial intelligence, semantic web and web services to construct tools and demonstrators to address these needs. This tutorial will focus on a use case from the ALIVE project (in one of the domains of crisis management, communications, or information services), discuss the requirements that arise from it and then explore it from the three perspectives that characterize the ALIVE approach: organizations, coordination and services, all illustrated by the innovative tools that have been developed during the project.More information about the ALIVE project can be downloaded from http://www.ist-alive.eu and a public release of the ALIVE tools, integrated into the Eclipse IDE will be available from mid October via the above website.},
booktitle = {Proceedings of the 12th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {16},
numpages = {1},
keywords = {organizations, agents, services},
location = {Paris, France},
series = {iiWAS '10}
}

@inproceedings{10.1145/3387940.3392195,
author = {Rivera, Luis F. and M\"{u}ller, Hausi A. and Villegas, Norha M. and Tamura, Gabriel and Jim\'{e}nez, Miguel},
title = {On the Engineering of IoT-Intensive Digital Twin Software Systems},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3392195},
doi = {10.1145/3387940.3392195},
abstract = {Digital Twins (DT) are software systems representing different aspects of a physical or conceptual counterpart---the real twin, which is instrumented with several sensors or computing devices that generate, consume and transfer data to its DT with different purposes. In other words, DT systems are, to a large extent, IoT-intensive systems. Indeed, by exploiting and managing IoT data, artificial intelligence, and big data and simulation capabilities, DTs have emerged as a promising approach to manage the virtual manifestation of real-world entities throughout their entire lifecycle. Their proliferation will contribute to realizing the long-craved convergence of virtual and physical spaces to augment things and human capabilities. In this context, despite the proposal of noteworthy contributions, we argue that DTs have not been sufficiently investigated from a software engineering perspective. To address this, in this paper we propose GEMINIS, an architectural reference model that adopts self-adaptation, control, and model-driven engineering techniques to specify the structural and behavioural aspects of DTs and enable the evolution of their internal models. Moreover, we introduce an approach for engineering IoT-intensive Digital Twin Software Systems (DTSS) using GEMINIS' capabilities to deal with uncertain conditions that are inherent to the nature of mirrored physical environments and that might compromise the fidelity of a DT. With GEMINIS and the proposed approach, we aim to advance the engineering of DTSS as well as IoT and cyber-physical systems by providing practitioners with guidelines to model and specify inherent structural and behavioural characteristics of DTs, addressing common design concerns.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {631–638},
numpages = {8},
keywords = {DTSS, IoT, GEMINIS, Digital twin, MIAC, dynamic context management, megamodel, MRAC, adaptive control, models at runtime, self-adaptive, reference model},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/1570433.1570478,
author = {Calvary, Ga\"{e}lle and Demeure, Alexandre},
title = {Context-Aware and Mobile Interactive Systems: The Future of User Interfaces Plasticity},
year = {2009},
isbn = {9781605586007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1570433.1570478},
doi = {10.1145/1570433.1570478},
abstract = {Mobility and integration of systems into the physical environment are key challenges for computer science. In particular, User Interfaces (UI) must accommodate variations in the context of use while preserving human-centered properties. We call this capacity UI plasticity. This tutorial begins by reviewing ideas from the last decade concerning the plasticity of user interfaces. From this starting point, it develops key ideas and perspectives for the near future. These are illustrated with a demo of a tool for prototyping plastic widgets and UIs.In the near future, there will be a need for elaborating a theory of adaptation to predict and explain the difficulties that users encounter when adaptation occurs. Secondly, in order to go beyond simplistic UI adaptation, there will be a need to bring together advances in several research areas including HCI (to support multimodality), Software Engineering (in particular, Model-Driven Engineering, Aspect Oriented Programming, as well as components and services, to cover both design time and run time adaptation), as well as Artificial Intelligence (to support situated information and planning). Indeed, in most current research, the user's task model is assumed as given and is used as the starting point for generating UIs on the fly. In addition, the functional core is considered to be stable rather than compliant with opportunistic discovery of services. In the coming years, we will need to confront challenges that go beyond HCI: (1) incompleteness and uncertainty of the system perception of both the context of use and of the appropriateness of the adapted UI; (2) combinatory explosion when composing a UI for sustaining emergent users goals. Finally, we will need to develop environments (or studios) for UI Plasticity to integrate partial advances, to make the theory operational and to alleviate designers and developers task.},
booktitle = {Proceedings of the 1st ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {243–244},
numpages = {2},
keywords = {user interface adaptation, context-aware user interface, plastic user interface},
location = {Pittsburgh, PA, USA},
series = {EICS '09}
}

@inproceedings{10.5555/2662593.2662595,
author = {Hastjarjanto, Tom and Jeuring, Johan and Leather, Sean},
title = {A DSL for Describing the Artificial Intelligence in Real-Time Video Games},
year = {2013},
isbn = {9781467362634},
publisher = {IEEE Press},
abstract = {Many games have computer-controlled agents that play against a player. The behavior of these computer-controlled agents is described by means of the artificial intelligence (AI) in the game. The AI is an important component of the game, and needs to be developed carefully, and adapted regularly. This paper introduces a novel language for describing the decision making process of the AI in real-time video games. We develop a declarative, domain-specific language (DSL) embedded in the functional programming language Haskell for real-time video games. We use the DSL to describe the AI of a prototype real-time video game.},
booktitle = {Proceedings of the 3rd International Workshop on Games and Software Engineering: Engineering Computer Games to Enable Positive, Progressive Change},
pages = {8–14},
numpages = {7},
location = {San Francisco, California},
series = {GAS '13}
}

@inproceedings{10.5555/2008503.2008556,
author = {Lortal, Ga\"{e}lle and Dhouib, Saadia and G\'{e}rard, S\'{e}bastien},
title = {Integrating Ontological Domain Knowledge into a Robotic DSL},
year = {2010},
isbn = {9783642212093},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Coming from the Artificial Intelligence (AI) and Semantic Web (SW) circles, ontologies are used mainly to represent domains. The Model Driven Engineering (MDE) field gave birth to Domain Specific Languages to represent a particular technical domain. Abstracting from their uses, we consider as many others researchers that ontologies and models are closer than their original fields could get to think. Furthermore, their building or development are facing the same problems. They are costly and need experts' interviews in order to grasp specific knowledge and structure it. Likewise, ontologies and DSL can benefit from each other domains in reusing construction methodologies and even reusing knowledge modelled in another format. In this paper we first present the ontologies and DSL definition we use and some methodologies of development enabling the reuse of knowledge (as alignment, fusion). We then present how we propose to reuse the knowledge of a robotic ontology to develop robotic DSLs within the PROTEUS project in order to inject readymade domain information to the DSL.},
booktitle = {Proceedings of the 2010 International Conference on Models in Software Engineering},
pages = {401–414},
numpages = {14},
location = {Oslo, Norway},
series = {MODELS'10}
}

@inproceedings{10.1145/1519130.1519133,
author = {Clemente, Pedro J. and Conejero, Jos\'{e} M. and Hern\'{a}ndez, Juan and S\'{a}nchez, Lara},
title = {HAAIS-DSL: DSL to Develop Home Automation and Ambient Intelligence Systems},
year = {2009},
isbn = {9781605584645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1519130.1519133},
doi = {10.1145/1519130.1519133},
abstract = {Domain Specific Language (DSL) is an emergent software engineering discipline that allows software architects to model systems based on the elements of a specific domain. Home Automation (HA) and Ambient Intelligence (AmI) are examples of specific domains and they are considered the key elements in the future of home development. However, software for these domains is usually hand coded based on embedded devices and specific implementation technologies and frameworks. In this paper we present a Model Driven Development (MDD) approach to develop software systems for HA and AmI. A Domain Specific Language has been designed to model the architecture of these kinds of systems. Then, taking as input the architecture models, a set of model transformations allows code and configuration generation for a specific device platform like KNX/EIB (European Installation Bus).},
booktitle = {Proceedings of the Second Workshop on Isolation and Integration in Embedded Systems},
pages = {13–18},
numpages = {6},
keywords = {embedded devices, home automation, ambient intelligence, code generation, DSL, model driven development},
location = {Nuremburg, Germany},
series = {IIES '09}
}

@inproceedings{10.1145/1519130.1519133,
author = {Clemente, Pedro J. and Conejero, Jos\'{e} M. and Hern\'{a}ndez, Juan and S\'{a}nchez, Lara},
title = {HAAIS-DSL: DSL to Develop Home Automation and Ambient Intelligence Systems},
year = {2009},
isbn = {9781605584645},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1519130.1519133},
doi = {10.1145/1519130.1519133},
abstract = {Domain Specific Language (DSL) is an emergent software engineering discipline that allows software architects to model systems based on the elements of a specific domain. Home Automation (HA) and Ambient Intelligence (AmI) are examples of specific domains and they are considered the key elements in the future of home development. However, software for these domains is usually hand coded based on embedded devices and specific implementation technologies and frameworks. In this paper we present a Model Driven Development (MDD) approach to develop software systems for HA and AmI. A Domain Specific Language has been designed to model the architecture of these kinds of systems. Then, taking as input the architecture models, a set of model transformations allows code and configuration generation for a specific device platform like KNX/EIB (European Installation Bus).},
booktitle = {Proceedings of the Second Workshop on Isolation and Integration in Embedded Systems},
pages = {13–18},
numpages = {6},
keywords = {embedded devices, home automation, ambient intelligence, code generation, DSL, model driven development},
location = {Nuremburg, Germany},
series = {IIES '09}
}

@inproceedings{10.5555/2662593.2662595,
author = {Hastjarjanto, Tom and Jeuring, Johan and Leather, Sean},
title = {A DSL for Describing the Artificial Intelligence in Real-Time Video Games},
year = {2013},
isbn = {9781467362634},
publisher = {IEEE Press},
abstract = {Many games have computer-controlled agents that play against a player. The behavior of these computer-controlled agents is described by means of the artificial intelligence (AI) in the game. The AI is an important component of the game, and needs to be developed carefully, and adapted regularly. This paper introduces a novel language for describing the decision making process of the AI in real-time video games. We develop a declarative, domain-specific language (DSL) embedded in the functional programming language Haskell for real-time video games. We use the DSL to describe the AI of a prototype real-time video game.},
booktitle = {Proceedings of the 3rd International Workshop on Games and Software Engineering: Engineering Computer Games to Enable Positive, Progressive Change},
pages = {8–14},
numpages = {7},
location = {San Francisco, California},
series = {GAS '13}
}

@inproceedings{10.1145/1774088.1774614,
author = {Hurnaus, Dominik and Pr\"{a}hofer, Herbert},
title = {Programming Assistance Based on Contracts and Modular Verification in the Automation Domain},
year = {2010},
isbn = {9781605586397},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1774088.1774614},
doi = {10.1145/1774088.1774614},
abstract = {In industrial automation, control software often has to get changed and adapted by domain experts and end users who have no or only limited software development expertise. This results in high demands on programming environments with respect to supporting, guiding, and supervising the programming tasks. In this paper we present an approach based on model checking and artificial intelligence techniques to guide domain experts in building control software which is guaranteed to obey specified contracts and constraints. The work is based on Monaco which is a domain-specific language for programming automation solutions. As Monaco employs a hierarchical component approach, the verification is done hierarchically where an upper component is verified against the contracts of its subcomponents. The verification approach is leveraged in different programming support systems which give immediate feedback about valid and invalid programs in an integrated development environment.},
booktitle = {Proceedings of the 2010 ACM Symposium on Applied Computing},
pages = {2544–2551},
numpages = {8},
keywords = {automation software, domain-specific language, component-based systems, end-user programming},
location = {Sierre, Switzerland},
series = {SAC '10}
}

@inproceedings{10.1145/3053600.3053619,
author = {Mangels, Tatiana and Murarasu, Alin and Oden, Forest and Fishkin, Alexey and Becker, Daniel},
title = {Efficient Analysis at Edge},
year = {2017},
isbn = {9781450348997},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3053600.3053619},
doi = {10.1145/3053600.3053619},
abstract = {Digitalization changes traditional business models by using digital technologies to improve existing offerings and to create new offerings. Current technological trends such as artificial intelligence, autonomous systems, and predictive maintenance are ideal candidate technologies to enable digitalization use cases. Often, these technologies rely on the availability of large amounts of data and the capability to process these data efficiently. In contrast to consumer markets, industrial products must fulfill higher non-functional requirements such as fast response times, 24/7 availability and stability, real-time processing, safety, or security requirements. As a consequence, processing capabilities -- ranging from multicore and manycores to even high end parallel clusters -- have to be exploited to achieve necessary performance and stability needs. In this paper, we introduce a Distributed Multicore Monitoring Framework (MoMo) which is a reference monitoring solution developed at Siemens Corporate Technology. It can be used to easily build efficient and stable diagnostic solutions which can help to understand the correctness, availability, reliability, and performance of large-scale distributed systems based on live data. Due to its small footprint MoMo can be used to analyze data directly at the data source which, for instance, can significantly reduce the network load. While MoMo's efficiency comes from the usage of multicore processors (CPUs) for running analysis in parallel, its usability is guaranteed by its capability to easily integrate with other monitoring frameworks and its usage of SPL - a domain-specific language which allows user to easily define diagnostic algorithms.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering Companion},
pages = {85–90},
numpages = {6},
keywords = {monitoring, data analysis, parallel computing},
location = {L'Aquila, Italy},
series = {ICPE '17 Companion}
}

@inproceedings{10.1145/224401.224834,
author = {Frantz, Frederick K.},
title = {A Taxonomy of Model Abstraction Techniques},
year = {1995},
isbn = {0780330188},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1145/224401.224834},
doi = {10.1145/224401.224834},
abstract = {Model abstraction is a method for reducing the complexity of a simulation model while maintaining the validity of the simulation results with respect to the question that the simulation is being used to address. Model developers have traditionally used a number of abstraction techniques, and simulation researchers have conducted formal research to build a theoretical foundation for model manipulation. More recently, researchers in the artificial intelligence (AI) subfield of qualitative simulation have also been developing techniques for simplifying models, determining whether models results are valid, and developing tools for automatic model selection and manipulation. Metamodeling can also be considered as an abstraction technique. The purpose of the paper is to provide a taxonomy of abstraction techniques drawn from these fields. This taxonomy provides a framework for comparing and contrasting various abstraction techniques.},
booktitle = {Proceedings of the 27th Conference on Winter Simulation},
pages = {1413–1420},
numpages = {8},
location = {Arlington, Virginia, USA},
series = {WSC '95}
}@inproceedings{10.1145/3417990.3419486,
author = {Saini, Rijul},
title = {Artificial Intelligence Empowered Domain Modelling Bot},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3419486},
doi = {10.1145/3417990.3419486},
abstract = {With the increasing adoption of Model-Based Software Engineering (MBSE) to handle the complexity of modern software systems in industry and inclusion of modelling topics in academic curricula, it is no longer a question of whether to use MBSE but how to use it. Acquiring modelling skills to properly build and use models with the help of modelling formalisms are non-trivial learning objectives, which novice modellers struggle to achieve for several reasons. For example, it is difficult for novice modellers to learn to use their abstraction abilities. Also, due to high student-teacher ratios in a typical classroom setting, novice modellers may not receive personalized and timely feedback on their modelling decisions. These issues hinder the novice modellers in improving their modelling skills. Furthermore, a lack of modelling skills among modellers inhibits the adoption and practice of modelling in industry. Therefore, an automated and intelligent solution is required to help modellers and other practitioners in improving their modelling skills. This doctoral research builds an automated and intelligent solution for one modelling formalism - domain models, in an avatar of a domain modelling bot. The bot automatically extracts domain models from problem descriptions written in natural language and generates intelligent recommendations, particularly for teaching modelling literacy to novice modellers. For this domain modelling bot, we leverage the capabilities of various Artificial Intelligence techniques such as Natural Language Processing and Machine Learning.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {26},
numpages = {6},
keywords = {natural language processing (NLP), bot, machine learning (ML), natural language (NL), artificial intelligence (AI), domain model},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@inproceedings{10.5555/1123196.1123314,
author = {Malyankar, R. M. and Baddam, A.},
title = {XML Schemas from Computational Ontologies},
year = {2003},
publisher = {Digital Government Society of North America},
abstract = {Academic researchers in artificial intelligence tend to use computational ontologies for knowledge modeling whereas commercial developers tend to use XML schemas, even though there is considerable overlap between the two representations considered as models of knowledge domains. Each representation has its own advantages and disadvantages compared to the other. There are active initiatives on the representation of knowledge for Web technologies, e.g., RDF (Resource Description Framework), and OWL (Web Ontology Language). These efforts often include ontology and schema editors that try to make schemas adhere to well-defined domain modeling principles, usually drawn from AI research in knowledge representation. This work is generally part of semantic web research. However, application developer communities have long accepted XML markup technology for data structuring, even though XML lacks (or rather, does not require) well-defined, rigorous domain models; the fact that such rigor is not required means that XML vocabularies are proliferating, and variant and ill-constructed models of domains and XML markup vocabularies are becoming set in stone by the effort that has gone into developing XML-based applications around them. One way to avoid this, and pave the way for future semantic web applications, is to devise a way to create and maintain a well-defined and unambiguous link between XML schemas and XML vocabularies and computational ontologies.Our XML schema generator is intended for ontologies represented in Protege. The schema generator maps ontology classes to named complex types in the format of the XML Schema specification; slots in the ontology are (at the user's option) either attributes for the complex types corresponding to the classes, or sub-elements in those same complex types. Range restrictions on the values of slots in the ontology are preserved and enumerated ranges are transformed into schema enumerations. Class inheritance relationships are converted into XML schema extension relationships. Metadata for classes and attributes is placed into schema annotation elements. Schema metadata can also be entered by the user. The schema generator optionally compels adherence to the naming standards in the Department of the Navy draft guidelines for XML schema development. The validity of the XML type libraries generated by this tool has been verified using schema validation tools available on XML Schema-related web sites.The difference between the expressive power of XML schemas and ontologies means certain features cannot be transformed. However, we find that for limited purposes, namely, turning ontologies into XML schema type libraries, the tool is useful even in its current form - it certainly speeds up the process of XML schema creation, because the taxonomical content of XML schemas, i.e., defining inheritance relationships, attributes, slot value ranges, etc., is easier with an ontology editor; so far, adding the unrepresented information to the sype libraries after the fact has not been too laborious a task - though it is certainly error-prone and repetitive, and we are investigating means of automating it or representing all the details necessary for XML schemas in ontologies.The XML schema generator described here is being used in WIN (Waterway Information Network), a proposed distributed content management architecture for marine transportation information, described in a companion paper in this conference (Malyankar et al 2003). The rationale underlying the use of such a schema generator is outlined above and in the companion paper: facilitating linkage between AI concepts of ontologies and programming structures for XML, thereby providing a formal and logically sound basis for XML application development. We hope this is one route from current Web technology to the Semantic Web; i.e., it is transitional technology that should ease progression to the semantic web.},
booktitle = {Proceedings of the 2003 Annual National Conference on Digital Government Research},
pages = {1},
numpages = {1},
location = {Boston, MA, USA},
series = {dg.o '03}
}

@inproceedings{10.5555/2662593.2662595,
author = {Hastjarjanto, Tom and Jeuring, Johan and Leather, Sean},
title = {A DSL for Describing the Artificial Intelligence in Real-Time Video Games},
year = {2013},
isbn = {9781467362634},
publisher = {IEEE Press},
abstract = {Many games have computer-controlled agents that play against a player. The behavior of these computer-controlled agents is described by means of the artificial intelligence (AI) in the game. The AI is an important component of the game, and needs to be developed carefully, and adapted regularly. This paper introduces a novel language for describing the decision making process of the AI in real-time video games. We develop a declarative, domain-specific language (DSL) embedded in the functional programming language Haskell for real-time video games. We use the DSL to describe the AI of a prototype real-time video game.},
booktitle = {Proceedings of the 3rd International Workshop on Games and Software Engineering: Engineering Computer Games to Enable Positive, Progressive Change},
pages = {8–14},
numpages = {7},
location = {San Francisco, California},
series = {GAS '13}
}

@inproceedings{10.1145/3322640.3326718,
author = {van Doesburg, Robert and van Engers, Tom},
title = {The False, the Former, and the Parish Priest},
year = {2019},
isbn = {9781450367547},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3322640.3326718},
doi = {10.1145/3322640.3326718},
abstract = {In the field of AI and Law, there is a debate whether normative relations can be expressed using only deontic concepts versus the opinion that a potestative perspective on norms cannot be reduced to deontic expressions. Makinson, Jones and Sergot are proponents of the latter view. In this paper, we will expand on their examples of priests marrying couples of mixed religions, and couples married by former priests, in order to better understand the notion of power.In this quest, we believe it is important to investigate the sources of norms, in this case the Code of Canon Law on Catholic marriage. We will do so using our method Calculemus and illustrate this method for making interpretation models of normative systems using a domain specific language (FLINT) for expressing frames for institutional acts, duties and facts. In this paper, we will give an overview of our analysis. An extended version of this paper will be published on Research Gate.},
booktitle = {Proceedings of the Seventeenth International Conference on Artificial Intelligence and Law},
pages = {194–198},
numpages = {5},
keywords = {Norm interpretation, Knowledge acquisition, Normative relations, Legal engineering},
location = {Montreal, QC, Canada},
series = {ICAIL '19}
}

@inproceedings{10.1145/3339252.3339278,
author = {Stelly, Christopher and Roussev, Vassil},
title = {Language-Based Integration of Digital Forensics &amp; Incident Response},
year = {2019},
isbn = {9781450371643},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3339252.3339278},
doi = {10.1145/3339252.3339278},
abstract = {In the cybersecurity domain, the level of standardization and interoperability among cybersecurity products from different vendors, including open-source ones, is fairly low. Although understandable from a business perspective, this deficiency makes it difficult and expensive for analysts to put together custom solutions and to have visibility across their entire IT infrastructure. It also hampers the adoption of custom data analytics and AI solutions, and slows down the exchange of threat detection and mitigation solutions.Recently, the Nugget domain specific language (DSL) has been proposed as a solution to the integration of digital forensics computations. The essential idea is to use a data flow language, somewhat similar to SQL, and an extensible run-time environment to decouple the specification of forensic computations from their implementation.In this paper, we study the integration of Nugget with security monitoring tools; specifically, we integrate Google's GRR incident response framework, and the de facto standard for log aggregation: Splunk. We demonstrate the utility of this type standardization to both tool developers and end-user analysts/IT administrators. We discuss potential implications of having such a DSL becoming widely adopted across the entire domain of cybersecurity.},
booktitle = {Proceedings of the 14th International Conference on Availability, Reliability and Security},
articleno = {27},
numpages = {6},
keywords = {digital forensics, nugget, incident response, domain specific language, grr},
location = {Canterbury, CA, United Kingdom},
series = {ARES '19}
}

@inproceedings{10.1145/224401.224834,
author = {Frantz, Frederick K.},
title = {A Taxonomy of Model Abstraction Techniques},
year = {1995},
isbn = {0780330188},
publisher = {IEEE Computer Society},
address = {USA},
url = {https://doi.org/10.1145/224401.224834},
doi = {10.1145/224401.224834},
abstract = {Model abstraction is a method for reducing the complexity of a simulation model while maintaining the validity of the simulation results with respect to the question that the simulation is being used to address. Model developers have traditionally used a number of abstraction techniques, and simulation researchers have conducted formal research to build a theoretical foundation for model manipulation. More recently, researchers in the artificial intelligence (AI) subfield of qualitative simulation have also been developing techniques for simplifying models, determining whether models results are valid, and developing tools for automatic model selection and manipulation. Metamodeling can also be considered as an abstraction technique. The purpose of the paper is to provide a taxonomy of abstraction techniques drawn from these fields. This taxonomy provides a framework for comparing and contrasting various abstraction techniques.},
booktitle = {Proceedings of the 27th Conference on Winter Simulation},
pages = {1413–1420},
numpages = {8},
location = {Arlington, Virginia, USA},
series = {WSC '95}
}@inbook{10.5555/3042094.3042482,
author = {Pelosi, Michael J. and Brown, Michael Scott},
title = {Software Engineering a Multi-Layer and Scalable Autonomous Forces "A.I." for Professional Military Training},
year = {2016},
isbn = {9781509044849},
publisher = {IEEE Press},
abstract = {Described herein is a general-purpose software engineering architecture for autonomous, computer controlled opponent implementation in modern maneuver warfare simulation and training. The implementation has been developed, refined, and tested in the user crucible for several years. The approach represents a hybrid application of various well-known AI techniques, including domain modeling, agent modeling, and object-oriented programming. Inspired by computer chess approaches, the methodology combines this theoretical foundation with a hybrid and scalable portfolio of additional techniques. The result remains simple enough to be maintainable and comprehensible for the code writers as well as the end-users, and robust enough to handle a wide spectrum of possible mission scenarios and circumstances without modification.},
booktitle = {Proceedings of the 2016 Winter Simulation Conference},
pages = {3122–3133},
numpages = {12}
}

@inproceedings{10.5555/3237383.3237990,
author = {Lallement, Rapha\"{e}l and de Silva, Lavindra and Alami, Rachid},
title = {HATP: Hierarchical Agent-Based Task Planner},
year = {2018},
publisher = {International Foundation for Autonomous Agents and Multiagent Systems},
address = {Richland, SC},
abstract = {Hierarchical Task Network (HTN) planning is a proven approach to solving complex, real world planning problems more efficiently than planning from first principles when 'standard operating procedures' (or `recipes') can be supplied by the user. By planning for tasks in the same order that they are later executed, total-order HTN planners always know the complete state of the world at each planning step. This enables writing more expressive planning domains than what is possible in partial-order HTN planning, such as preconditions with calls to external procedures. Such features have facilitated the use of total-order HTN planners in agent systems and seen them excel in AI games. This paper describes the Hierarchical Agent-based Task Planner (HATP), a total-order HTN planner. Since its first implementation, HATP has had various extensions and integrations over the years, such as support for splitting a solution into multiple streams and assigning them to the agents in the domain; modelling their beliefs as distinct world states; allowing 'social rules' to be included by the user to define what kind of agent behaviour is appropriate; allowing tasks to be planned by taking the human's safety and comfort into account; and to interleave HTN and geometric planning. Since many of these implementations have remained prototypes, we have significantly enhanced them as well as HATP itself, and integrated them into a stand-alone distribution, which is now available as open source software (under a BSD 2-Clause License). This paper presents some of our recent improvements to HATP, and gives an overview of its user-friendly language, which treats agents as distinct entities; its mechanisms for effective control over decomposition; and its integration into our larger robotics framework.},
booktitle = {Proceedings of the 17th International Conference on Autonomous Agents and MultiAgent Systems},
pages = {1823–1825},
numpages = {3},
keywords = {geometric planning, htn planning, multi-robot planning},
location = {Stockholm, Sweden},
series = {AAMAS '18}
}

@inproceedings{10.5555/1123196.1123314,
author = {Malyankar, R. M. and Baddam, A.},
title = {XML Schemas from Computational Ontologies},
year = {2003},
publisher = {Digital Government Society of North America},
abstract = {Academic researchers in artificial intelligence tend to use computational ontologies for knowledge modeling whereas commercial developers tend to use XML schemas, even though there is considerable overlap between the two representations considered as models of knowledge domains. Each representation has its own advantages and disadvantages compared to the other. There are active initiatives on the representation of knowledge for Web technologies, e.g., RDF (Resource Description Framework), and OWL (Web Ontology Language). These efforts often include ontology and schema editors that try to make schemas adhere to well-defined domain modeling principles, usually drawn from AI research in knowledge representation. This work is generally part of semantic web research. However, application developer communities have long accepted XML markup technology for data structuring, even though XML lacks (or rather, does not require) well-defined, rigorous domain models; the fact that such rigor is not required means that XML vocabularies are proliferating, and variant and ill-constructed models of domains and XML markup vocabularies are becoming set in stone by the effort that has gone into developing XML-based applications around them. One way to avoid this, and pave the way for future semantic web applications, is to devise a way to create and maintain a well-defined and unambiguous link between XML schemas and XML vocabularies and computational ontologies.Our XML schema generator is intended for ontologies represented in Protege. The schema generator maps ontology classes to named complex types in the format of the XML Schema specification; slots in the ontology are (at the user's option) either attributes for the complex types corresponding to the classes, or sub-elements in those same complex types. Range restrictions on the values of slots in the ontology are preserved and enumerated ranges are transformed into schema enumerations. Class inheritance relationships are converted into XML schema extension relationships. Metadata for classes and attributes is placed into schema annotation elements. Schema metadata can also be entered by the user. The schema generator optionally compels adherence to the naming standards in the Department of the Navy draft guidelines for XML schema development. The validity of the XML type libraries generated by this tool has been verified using schema validation tools available on XML Schema-related web sites.The difference between the expressive power of XML schemas and ontologies means certain features cannot be transformed. However, we find that for limited purposes, namely, turning ontologies into XML schema type libraries, the tool is useful even in its current form - it certainly speeds up the process of XML schema creation, because the taxonomical content of XML schemas, i.e., defining inheritance relationships, attributes, slot value ranges, etc., is easier with an ontology editor; so far, adding the unrepresented information to the sype libraries after the fact has not been too laborious a task - though it is certainly error-prone and repetitive, and we are investigating means of automating it or representing all the details necessary for XML schemas in ontologies.The XML schema generator described here is being used in WIN (Waterway Information Network), a proposed distributed content management architecture for marine transportation information, described in a companion paper in this conference (Malyankar et al 2003). The rationale underlying the use of such a schema generator is outlined above and in the companion paper: facilitating linkage between AI concepts of ontologies and programming structures for XML, thereby providing a formal and logically sound basis for XML application development. We hope this is one route from current Web technology to the Semantic Web; i.e., it is transitional technology that should ease progression to the semantic web.},
booktitle = {Proceedings of the 2003 Annual National Conference on Digital Government Research},
pages = {1},
numpages = {1},
location = {Boston, MA, USA},
series = {dg.o '03}
}

@inproceedings{10.1109/MODELS-C.2019.00028,
author = {Burgue\~{n}o, Loli and Burdusel, Alexandru and G\'{e}rard, S\'{e}bastien and Wimmer, Manuel},
title = {MDE Intelligence 2019: 1st Workshop on Artificial Intelligence and Model-Driven Engineering},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00028},
doi = {10.1109/MODELS-C.2019.00028},
abstract = {Model-driven engineering (MDE) and Artificial Intelligence (AI) are two separate fields in computer science, which can clearly benefit from cross-fertilization and collaboration. There are at least two ways in which such integrations---which we call MDE Intelligence---can manifest: (1) MDE can benefit from integrating AI concepts and ideas to increasing the power and flexibility of model-driven techniques by means of the application of AI algorithms. (2) Conversely, AI can benefit from integrating concepts and ideas from MDE---for example, using domain-specific languages and model transformations allows domain experts to directly express and manipulate their problems while providing an auditable computation pipeline.To discuss and further stimulate such integrations, the 1st edition of the Workshop on Artificial Intelligence and Model-driven Engineering (MDE Intelligence) was held on September 16, 2019 in Munich, Germany, as part of the satellite events of the IEEE/ACM 22th International Conference on Model-Driven Engineering Languages and Systems (MODELS 2019).},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {168–169},
numpages = {2},
keywords = {MDE, MDE intelligence, artificial intelligence},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1145/3550356.3561609,
author = {Bergelin, Johan and Strandberg, Per Erik},
title = {Industrial Requirements for Supporting AI-Enhanced Model-Driven Engineering},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561609},
doi = {10.1145/3550356.3561609},
abstract = {There is an increasing interest in research on the combination of AI techniques and methods with MDE. However, there is a gap between AI and MDE practices, as well as between researchers and practitioners. This paper tackles this gap by reporting on industrial requirements in this field. In the AIDOaRt research project, practitioners and researchers collaborate on AI-augmented automation supporting modeling, coding, testing, monitoring, and continuous development in cyber-physical systems. The project specifically lies at the intersection of industry and academia collaboration with several industrial use cases. Through a process of elicitation and refinement, 78 high-level requirements were defined, and generalized into 30 generic requirements by the AIDOaRt partners. The main contribution of this paper is the set of generic requirements from the project for enhancing the development of cyber-physical systems with artificial intelligence, DevOps, and model-driven engineering, identifying the hot spots of industry needs in the interactions of MDE and AI. Future work will refine, implement and evaluate solutions toward these requirements in industry contexts.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {375–379},
numpages = {5},
keywords = {artificial intelligence, requirements, cyber-physical systems, model-driven engineering},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.5555/2008503.2008556,
author = {Lortal, Ga\"{e}lle and Dhouib, Saadia and G\'{e}rard, S\'{e}bastien},
title = {Integrating Ontological Domain Knowledge into a Robotic DSL},
year = {2010},
isbn = {9783642212093},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Coming from the Artificial Intelligence (AI) and Semantic Web (SW) circles, ontologies are used mainly to represent domains. The Model Driven Engineering (MDE) field gave birth to Domain Specific Languages to represent a particular technical domain. Abstracting from their uses, we consider as many others researchers that ontologies and models are closer than their original fields could get to think. Furthermore, their building or development are facing the same problems. They are costly and need experts' interviews in order to grasp specific knowledge and structure it. Likewise, ontologies and DSL can benefit from each other domains in reusing construction methodologies and even reusing knowledge modelled in another format. In this paper we first present the ontologies and DSL definition we use and some methodologies of development enabling the reuse of knowledge (as alignment, fusion). We then present how we propose to reuse the knowledge of a robotic ontology to develop robotic DSLs within the PROTEUS project in order to inject readymade domain information to the DSL.},
booktitle = {Proceedings of the 2010 International Conference on Models in Software Engineering},
pages = {401–414},
numpages = {14},
location = {Oslo, Norway},
series = {MODELS'10}
}

@inproceedings{10.1109/MODELS-C.2019.00028,
author = {Burgue\~{n}o, Loli and Burdusel, Alexandru and G\'{e}rard, S\'{e}bastien and Wimmer, Manuel},
title = {MDE Intelligence 2019: 1st Workshop on Artificial Intelligence and Model-Driven Engineering},
year = {2021},
isbn = {9781728151250},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/MODELS-C.2019.00028},
doi = {10.1109/MODELS-C.2019.00028},
abstract = {Model-driven engineering (MDE) and Artificial Intelligence (AI) are two separate fields in computer science, which can clearly benefit from cross-fertilization and collaboration. There are at least two ways in which such integrations---which we call MDE Intelligence---can manifest: (1) MDE can benefit from integrating AI concepts and ideas to increasing the power and flexibility of model-driven techniques by means of the application of AI algorithms. (2) Conversely, AI can benefit from integrating concepts and ideas from MDE---for example, using domain-specific languages and model transformations allows domain experts to directly express and manipulate their problems while providing an auditable computation pipeline.To discuss and further stimulate such integrations, the 1st edition of the Workshop on Artificial Intelligence and Model-driven Engineering (MDE Intelligence) was held on September 16, 2019 in Munich, Germany, as part of the satellite events of the IEEE/ACM 22th International Conference on Model-Driven Engineering Languages and Systems (MODELS 2019).},
booktitle = {Proceedings of the 22nd International Conference on Model Driven Engineering Languages and Systems},
pages = {168–169},
numpages = {2},
keywords = {MDE intelligence, MDE, artificial intelligence},
location = {Munich, Germany},
series = {MODELS '19}
}

@inproceedings{10.1145/2422518.2422519,
author = {Bencomo, Nelly and Blair, Gordon and G\"{o}tz, Sebastian and Morin, Brice and Rumpe, Bernhard},
title = {Summary of the 7th International Workshop on Models@run.Time},
year = {2012},
isbn = {9781450318020},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2422518.2422519},
doi = {10.1145/2422518.2422519},
abstract = {The Models@run.time (MRT) workshop series offers a discussion forum for the rising need to leverage modeling techniques for the software of the future. The main goals are to explore the benefits of models@run.time and to foster collaboration and cross-fertilization between different research communities like for example like model-driven engineering (e.g. MODELS), self-adaptive/autonomous systems communities (e.g., SEAMS and ICAC), the control theory community and the artificial intelligence community.},
booktitle = {Proceedings of the 7th Workshop on Models@run.Time},
pages = {1–2},
numpages = {2},
keywords = {reflection, runtime abstractions, abstraction, runtime models, MDE, runtime adaptation},
location = {Innsbruck, Austria},
series = {MRT '12}
}

@inproceedings{10.5555/3400397.3400521,
author = {Benaben, Frederick and Lauras, Matthieu and Fertier, Audrey and Salatg\'{e}, Nicolas},
title = {Integrating Model-Driven Engineering as the next Challenge for Artificial Intelligence: Application to Risk and Crisis Management},
year = {2020},
isbn = {9781728132839},
publisher = {IEEE Press},
abstract = {Artificial Intelligence (AI) is currently on top of the hype regarding simultaneously research publications and industrial development. However, the current status of AI makes it quite far and different from the current understanding of Human intelligence. One suggestion that is made in this article is that Model-Driven approaches could be considered as an interesting avenue to complement classical visions of AI and to provide some missing features. Specifically, the use of Model-Driven Engineering tools (such as metamodel and model transformation) could benefit to the domain of AI by introducing a way to extend the apprehension of unknown situations. To support that proposal, an illustrative example is provided regarding the domain of risk and crisis management.},
booktitle = {Proceedings of the Winter Simulation Conference},
pages = {1549–1563},
numpages = {15},
location = {National Harbor, Maryland},
series = {WSC '19}
}

@inproceedings{10.1145/3436829.3436851,
author = {Zahoor, Tayyba and Azam, Farooque and Anwar, Muahmmad Waseem and Tariq, Ayesha and Javaid, Haider Ali},
title = {An Investigation of Smart Parking Tools, Technologies, &amp; Challenges},
year = {2021},
isbn = {9781450377218},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3436829.3436851},
doi = {10.1145/3436829.3436851},
abstract = {Urbanization, exceptional increase in population and advancement in technology caused the automotive industry to grow rapidly &amp; automobiles become essential part of daily life. Consequently, finding a parking space particularly in populous zones, is a challenging task. Researchers have proposed different solutions to assist the developments in smart parking systems. In this paper, we have investigated the key tools, techniques &amp; challenges proposed in the recent research studies. Primarily, a Systematic Literature Review is carried out, total 35 studies are explored during time interval of (2015-2019). Subsequently, five major areas are recognized where smart parking is often functional i.e. Internet of Things (IoT) (13 studies), Cloud Computing (2 studies), Model-Driven Engineering (4 studies), Fog Computing (6 studies) and Artificial Intelligence (11 studies). Furthermore, (15) primary tools and (25) algorithms are presented. This article also portray the challenges cited by different studies. The findings of this study will definitely assist the practitioners while deciding the appropriate selections.},
booktitle = {Proceedings of the 2020 9th International Conference on Software and Information Engineering (ICSIE)},
pages = {198–203},
numpages = {6},
keywords = {Smart Parking Tools, Smart Parking, Smart Parking Technologies, Systematic Literature Review, Smart Parking Challenges},
location = {Cairo, Egypt},
series = {ICSIE 2020}
}

@inproceedings{10.5555/2008503.2008556,
author = {Lortal, Ga\"{e}lle and Dhouib, Saadia and G\'{e}rard, S\'{e}bastien},
title = {Integrating Ontological Domain Knowledge into a Robotic DSL},
year = {2010},
isbn = {9783642212093},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Coming from the Artificial Intelligence (AI) and Semantic Web (SW) circles, ontologies are used mainly to represent domains. The Model Driven Engineering (MDE) field gave birth to Domain Specific Languages to represent a particular technical domain. Abstracting from their uses, we consider as many others researchers that ontologies and models are closer than their original fields could get to think. Furthermore, their building or development are facing the same problems. They are costly and need experts' interviews in order to grasp specific knowledge and structure it. Likewise, ontologies and DSL can benefit from each other domains in reusing construction methodologies and even reusing knowledge modelled in another format. In this paper we first present the ontologies and DSL definition we use and some methodologies of development enabling the reuse of knowledge (as alignment, fusion). We then present how we propose to reuse the knowledge of a robotic ontology to develop robotic DSLs within the PROTEUS project in order to inject readymade domain information to the DSL.},
booktitle = {Proceedings of the 2010 International Conference on Models in Software Engineering},
pages = {401–414},
numpages = {14},
location = {Oslo, Norway},
series = {MODELS'10}
}

@inproceedings{10.1145/3550356.3561609,
author = {Bergelin, Johan and Strandberg, Per Erik},
title = {Industrial Requirements for Supporting AI-Enhanced Model-Driven Engineering},
year = {2022},
isbn = {9781450394673},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3550356.3561609},
doi = {10.1145/3550356.3561609},
abstract = {There is an increasing interest in research on the combination of AI techniques and methods with MDE. However, there is a gap between AI and MDE practices, as well as between researchers and practitioners. This paper tackles this gap by reporting on industrial requirements in this field. In the AIDOaRt research project, practitioners and researchers collaborate on AI-augmented automation supporting modeling, coding, testing, monitoring, and continuous development in cyber-physical systems. The project specifically lies at the intersection of industry and academia collaboration with several industrial use cases. Through a process of elicitation and refinement, 78 high-level requirements were defined, and generalized into 30 generic requirements by the AIDOaRt partners. The main contribution of this paper is the set of generic requirements from the project for enhancing the development of cyber-physical systems with artificial intelligence, DevOps, and model-driven engineering, identifying the hot spots of industry needs in the interactions of MDE and AI. Future work will refine, implement and evaluate solutions toward these requirements in industry contexts.},
booktitle = {Proceedings of the 25th International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
pages = {375–379},
numpages = {5},
keywords = {artificial intelligence, requirements, cyber-physical systems, model-driven engineering},
location = {Montreal, Quebec, Canada},
series = {MODELS '22}
}

@inproceedings{10.1145/1967486.1967492,
author = {Dignum, Frank and Padget, Julian and Vasconcelos, Wamberto},
title = {Organizing Services for a Changing Environment},
year = {2010},
isbn = {9781450304214},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1967486.1967492},
doi = {10.1145/1967486.1967492},
abstract = {Service-oriented computing is the "new wave" emerging from the growing up of web services and its adoption of elements of semantic web technology. More sophistication, in response to business requirements, does of course not make it easier to use or to control. In particular business processes demand resilience and (real-time) adaptation in the face of changing business requirements, incorporation of alternative services and finding suitable substitutes when those needed are not available. The EU-funded ALIVE project is prototyping ideas, driven by commercial and industrial uses cases, that utilize research in organizational modelling, software agents, model-driven engineering, artificial intelligence, semantic web and web services to construct tools and demonstrators to address these needs. This tutorial will focus on a use case from the ALIVE project (in one of the domains of crisis management, communications, or information services), discuss the requirements that arise from it and then explore it from the three perspectives that characterize the ALIVE approach: organizations, coordination and services, all illustrated by the innovative tools that have been developed during the project.More information about the ALIVE project can be downloaded from http://www.ist-alive.eu and a public release of the ALIVE tools, integrated into the Eclipse IDE will be available from mid October via the above website.},
booktitle = {Proceedings of the 12th International Conference on Information Integration and Web-Based Applications &amp; Services},
pages = {16},
numpages = {1},
keywords = {services, organizations, agents},
location = {Paris, France},
series = {iiWAS '10}
}

@inproceedings{10.1145/3387940.3392195,
author = {Rivera, Luis F. and M\"{u}ller, Hausi A. and Villegas, Norha M. and Tamura, Gabriel and Jim\'{e}nez, Miguel},
title = {On the Engineering of IoT-Intensive Digital Twin Software Systems},
year = {2020},
isbn = {9781450379632},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3387940.3392195},
doi = {10.1145/3387940.3392195},
abstract = {Digital Twins (DT) are software systems representing different aspects of a physical or conceptual counterpart---the real twin, which is instrumented with several sensors or computing devices that generate, consume and transfer data to its DT with different purposes. In other words, DT systems are, to a large extent, IoT-intensive systems. Indeed, by exploiting and managing IoT data, artificial intelligence, and big data and simulation capabilities, DTs have emerged as a promising approach to manage the virtual manifestation of real-world entities throughout their entire lifecycle. Their proliferation will contribute to realizing the long-craved convergence of virtual and physical spaces to augment things and human capabilities. In this context, despite the proposal of noteworthy contributions, we argue that DTs have not been sufficiently investigated from a software engineering perspective. To address this, in this paper we propose GEMINIS, an architectural reference model that adopts self-adaptation, control, and model-driven engineering techniques to specify the structural and behavioural aspects of DTs and enable the evolution of their internal models. Moreover, we introduce an approach for engineering IoT-intensive Digital Twin Software Systems (DTSS) using GEMINIS' capabilities to deal with uncertain conditions that are inherent to the nature of mirrored physical environments and that might compromise the fidelity of a DT. With GEMINIS and the proposed approach, we aim to advance the engineering of DTSS as well as IoT and cyber-physical systems by providing practitioners with guidelines to model and specify inherent structural and behavioural characteristics of DTs, addressing common design concerns.},
booktitle = {Proceedings of the IEEE/ACM 42nd International Conference on Software Engineering Workshops},
pages = {631–638},
numpages = {8},
keywords = {GEMINIS, adaptive control, dynamic context management, IoT, MRAC, megamodel, MIAC, reference model, models at runtime, self-adaptive, Digital twin, DTSS},
location = {Seoul, Republic of Korea},
series = {ICSEW'20}
}

@inproceedings{10.1145/1570433.1570478,
author = {Calvary, Ga\"{e}lle and Demeure, Alexandre},
title = {Context-Aware and Mobile Interactive Systems: The Future of User Interfaces Plasticity},
year = {2009},
isbn = {9781605586007},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1570433.1570478},
doi = {10.1145/1570433.1570478},
abstract = {Mobility and integration of systems into the physical environment are key challenges for computer science. In particular, User Interfaces (UI) must accommodate variations in the context of use while preserving human-centered properties. We call this capacity UI plasticity. This tutorial begins by reviewing ideas from the last decade concerning the plasticity of user interfaces. From this starting point, it develops key ideas and perspectives for the near future. These are illustrated with a demo of a tool for prototyping plastic widgets and UIs.In the near future, there will be a need for elaborating a theory of adaptation to predict and explain the difficulties that users encounter when adaptation occurs. Secondly, in order to go beyond simplistic UI adaptation, there will be a need to bring together advances in several research areas including HCI (to support multimodality), Software Engineering (in particular, Model-Driven Engineering, Aspect Oriented Programming, as well as components and services, to cover both design time and run time adaptation), as well as Artificial Intelligence (to support situated information and planning). Indeed, in most current research, the user's task model is assumed as given and is used as the starting point for generating UIs on the fly. In addition, the functional core is considered to be stable rather than compliant with opportunistic discovery of services. In the coming years, we will need to confront challenges that go beyond HCI: (1) incompleteness and uncertainty of the system perception of both the context of use and of the appropriateness of the adapted UI; (2) combinatory explosion when composing a UI for sustaining emergent users goals. Finally, we will need to develop environments (or studios) for UI Plasticity to integrate partial advances, to make the theory operational and to alleviate designers and developers task.},
booktitle = {Proceedings of the 1st ACM SIGCHI Symposium on Engineering Interactive Computing Systems},
pages = {243–244},
numpages = {2},
keywords = {user interface adaptation, plastic user interface, context-aware user interface},
location = {Pittsburgh, PA, USA},
series = {EICS '09}
}

@inproceedings{10.5555/2662593.2662595,
author = {Hastjarjanto, Tom and Jeuring, Johan and Leather, Sean},
title = {A DSL for Describing the Artificial Intelligence in Real-Time Video Games},
year = {2013},
isbn = {9781467362634},
publisher = {IEEE Press},
abstract = {Many games have computer-controlled agents that play against a player. The behavior of these computer-controlled agents is described by means of the artificial intelligence (AI) in the game. The AI is an important component of the game, and needs to be developed carefully, and adapted regularly. This paper introduces a novel language for describing the decision making process of the AI in real-time video games. We develop a declarative, domain-specific language (DSL) embedded in the functional programming language Haskell for real-time video games. We use the DSL to describe the AI of a prototype real-time video game.},
booktitle = {Proceedings of the 3rd International Workshop on Games and Software Engineering: Engineering Computer Games to Enable Positive, Progressive Change},
pages = {8–14},
numpages = {7},
location = {San Francisco, California},
series = {GAS '13}
}

@inproceedings{10.5555/2008503.2008556,
author = {Lortal, Ga\"{e}lle and Dhouib, Saadia and G\'{e}rard, S\'{e}bastien},
title = {Integrating Ontological Domain Knowledge into a Robotic DSL},
year = {2010},
isbn = {9783642212093},
publisher = {Springer-Verlag},
address = {Berlin, Heidelberg},
abstract = {Coming from the Artificial Intelligence (AI) and Semantic Web (SW) circles, ontologies are used mainly to represent domains. The Model Driven Engineering (MDE) field gave birth to Domain Specific Languages to represent a particular technical domain. Abstracting from their uses, we consider as many others researchers that ontologies and models are closer than their original fields could get to think. Furthermore, their building or development are facing the same problems. They are costly and need experts' interviews in order to grasp specific knowledge and structure it. Likewise, ontologies and DSL can benefit from each other domains in reusing construction methodologies and even reusing knowledge modelled in another format. In this paper we first present the ontologies and DSL definition we use and some methodologies of development enabling the reuse of knowledge (as alignment, fusion). We then present how we propose to reuse the knowledge of a robotic ontology to develop robotic DSLs within the PROTEUS project in order to inject readymade domain information to the DSL.},
booktitle = {Proceedings of the 2010 International Conference on Models in Software Engineering},
pages = {401–414},
numpages = {14},
location = {Oslo, Norway},
series = {MODELS'10}
}

