@inproceedings{10.1145/2371401.2371417,
author = {Bauer, Tim and Erwig, Martin and Fern, Alan and Pinto, Jervis},
title = {Faster Program Adaptation through Reward Attribution Inference},
year = {2012},
isbn = {9781450311298},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2371401.2371417},
doi = {10.1145/2371401.2371417},
abstract = {In the adaptation-based programming (ABP) paradigm, programs may contain variable parts (function calls, parameter values, etc.) that can be take a number of different values. Programs also contain reward statements with which a programmer can provide feedback about how well a program is performing with respect to achieving its goals (for example, achieving a high score on some scale). By repeatedly running the program, a machine learning component will, guided by the rewards, gradually adjust the automatic choices made in the variable program parts so that they converge toward an optimal strategy.ABP is a method for semi-automatic program generation in which the choices and rewards offered by programmers allow standard machine-learning techniques to explore a design space defined by the programmer to find an optimal instance of a program template. ABP effectively provides a DSL that allows non-machine-learning experts to exploit machine learning to generate self-optimizing programs.Unfortunately, in many cases the placement and structuring of choices and rewards can have a detrimental effect on how an optimal solution to a program-generation problem can be found. To address this problem, we have developed a dataflow analysis that computes influence tracks of choices and rewards. This information can be exploited by an augmented machine-learning technique to ignore misleading rewards and to generally attribute rewards better to the choices that have actually influenced them. Moreover, this technique allows us to detect errors in the adaptive program that might arise out of program maintenance. Our evaluation shows that the dataflow analysis can lead to improvements in performance.},
booktitle = {Proceedings of the 11th International Conference on Generative Programming and Component Engineering},
pages = {103–111},
numpages = {9},
keywords = {reinforcement learning, partial programming, program adaptation},
location = {Dresden, Germany},
series = {GPCE '12}
}

@article{10.1145/2480361.2371417,
author = {Bauer, Tim and Erwig, Martin and Fern, Alan and Pinto, Jervis},
title = {Faster Program Adaptation through Reward Attribution Inference},
year = {2012},
issue_date = {March 2013},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {48},
number = {3},
issn = {0362-1340},
url = {https://doi.org/10.1145/2480361.2371417},
doi = {10.1145/2480361.2371417},
abstract = {In the adaptation-based programming (ABP) paradigm, programs may contain variable parts (function calls, parameter values, etc.) that can be take a number of different values. Programs also contain reward statements with which a programmer can provide feedback about how well a program is performing with respect to achieving its goals (for example, achieving a high score on some scale). By repeatedly running the program, a machine learning component will, guided by the rewards, gradually adjust the automatic choices made in the variable program parts so that they converge toward an optimal strategy.ABP is a method for semi-automatic program generation in which the choices and rewards offered by programmers allow standard machine-learning techniques to explore a design space defined by the programmer to find an optimal instance of a program template. ABP effectively provides a DSL that allows non-machine-learning experts to exploit machine learning to generate self-optimizing programs.Unfortunately, in many cases the placement and structuring of choices and rewards can have a detrimental effect on how an optimal solution to a program-generation problem can be found. To address this problem, we have developed a dataflow analysis that computes influence tracks of choices and rewards. This information can be exploited by an augmented machine-learning technique to ignore misleading rewards and to generally attribute rewards better to the choices that have actually influenced them. Moreover, this technique allows us to detect errors in the adaptive program that might arise out of program maintenance. Our evaluation shows that the dataflow analysis can lead to improvements in performance.},
journal = {SIGPLAN Not.},
month = {sep},
pages = {103–111},
numpages = {9},
keywords = {partial programming, reinforcement learning, program adaptation}
}

@inproceedings{10.1145/3417990.3420057,
author = {Moin, Armin and R\"{o}ssler, Stephan and Sayih, Marouane and G\"{u}nnemann, Stephan},
title = {From Things' Modeling Language (ThingML) to Things' Machine Learning (ThingML2)},
year = {2020},
isbn = {9781450381352},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3417990.3420057},
doi = {10.1145/3417990.3420057},
abstract = {In this paper, we illustrate how to enhance an existing state-of-the-art modeling language and tool for the Internet of Things (IoT), called ThingML, to support machine learning on the modeling level. To this aim, we extend the Domain-Specific Language (DSL) of ThingML, as well as its code generation framework. Our DSL allows one to define things, which are in charge of carrying out data analytics. Further, our code generators can automatically produce the complete implementation in Java and Python. The generated Python code is responsible for data analytics and employs APIs of machine learning libraries, such as Keras, Tensorflow and Scikit Learn. Our prototype is available as open source software on Github.},
booktitle = {Proceedings of the 23rd ACM/IEEE International Conference on Model Driven Engineering Languages and Systems: Companion Proceedings},
articleno = {19},
numpages = {2},
keywords = {internet of things, machine learning, domain-specific modeling},
location = {Virtual Event, Canada},
series = {MODELS '20}
}

@article{10.14778/3297753.3297763,
author = {Xin, Doris and Macke, Stephen and Ma, Litian and Liu, Jialin and Song, Shuchen and Parameswaran, Aditya},
title = {HELIX: Holistic Optimization for Accelerating Iterative Machine Learning},
year = {2018},
issue_date = {December 2018},
publisher = {VLDB Endowment},
volume = {12},
number = {4},
issn = {2150-8097},
url = {https://doi.org/10.14778/3297753.3297763},
doi = {10.14778/3297753.3297763},
abstract = {Machine learning workflow development is a process of trial-and-error: developers iterate on workflows by testing out small modifications until the desired accuracy is achieved. Unfortunately, existing machine learning systems focus narrowly on model training---a small fraction of the overall development time---and neglect to address iterative development. We propose Helix, a machine learning system that optimizes the execution across iterations---intelligently caching and reusing, or recomputing intermediates as appropriate. Helix captures a wide variety of application needs within its Scala DSL, with succinct syntax defining unified processes for data preprocessing, model specification, and learning. We demonstrate that the reuse problem can be cast as a Max-Flow problem, while the caching problem is NP-Hard. We develop effective lightweight heuristics for the latter. Empirical evaluation shows that Helix is not only able to handle a wide variety of use cases in one unified workflow but also much faster, providing run time reductions of up to 19x over state-of-the-art systems, such as DeepDive or KeystoneML, on four real-world applications in natural language processing, computer vision, social and natural sciences.},
journal = {Proc. VLDB Endow.},
month = {dec},
pages = {446–460},
numpages = {15}
}

@inproceedings{10.1145/3468044.3468052,
author = {Podobas, Artur and Svedin, Martin and Chien, Steven W. D. and Peng, Ivy B. and Ravichandran, Naresh Balaji and Herman, Pawel and Lansner, Anders and Markidis, Stefano},
title = {StreamBrain: An HPC Framework for Brain-like Neural Networks on CPUs, GPUs and FPGAs},
year = {2021},
isbn = {9781450385497},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3468044.3468052},
doi = {10.1145/3468044.3468052},
abstract = {The modern deep learning method based on backpropagation has surged in popularity and has been used in multiple domains and application areas. At the same time, there are other - less-known - machine learning algorithms with a mature and solid theoretical foundation whose performance remains unexplored. One such example is the brain-like Bayesian Confidence Propagation Neural Network (BCPNN). In this paper, we introduce StreamBrain--a framework that allows neural networks based on BCPNN to be practically deployed in High-Performance Computing systems. StreamBrain is a domain-specific language (DSL), similar in concept to existing machine learning (ML) frameworks, and supports backends for CPUs, GPUs, and even FPGAs. We empirically demonstrate that StreamBrain can train the well-known ML benchmark dataset MNIST within seconds, and we are the first to demonstrate BCPNN on STL-10 size networks. We also show how StreamBrain can be used to train with custom floating-point formats and illustrate the impact of using different bfloat variations on BCPNN using FPGAs.},
booktitle = {Proceedings of the 11th International Symposium on Highly Efficient Accelerators and Reconfigurable Technologies},
articleno = {8},
numpages = {6},
keywords = {Neural networks, GPU, Emerging Machine Learning, Unsupervised learning, HPC, AI, FPGA, BCPNN, Representation learning},
location = {Online, Germany},
series = {HEART '21}
}

@inproceedings{10.1145/3123939.3123979,
author = {Park, Jongse and Sharma, Hardik and Mahajan, Divya and Kim, Joon Kyung and Olds, Preston and Esmaeilzadeh, Hadi},
title = {Scale-out Acceleration for Machine Learning},
year = {2017},
isbn = {9781450349529},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3123939.3123979},
doi = {10.1145/3123939.3123979},
abstract = {The growing scale and complexity of Machine Learning (ML) algorithms has resulted in prevalent use of distributed general-purpose systems. In a rather disjoint effort, the community is focusing mostly on high performance single-node accelerators for learning. This work bridges these two paradigms and offers CoSMIC, a full computing stack constituting language, compiler, system software, template architecture, and circuit generators, that enable programmable acceleration of learning at scale. CoSMIC enables programmers to exploit scale-out acceleration using FPGAs and Programmable ASICs (P-ASICs) from a high-level and mathematical Domain-Specific Language (DSL). Nonetheless, CoSMIC does not require programmers to delve into the onerous task of system software development or hardware design. CoSMIC achieves three conflicting objectives of efficiency, automation, and programmability, by integrating a novel multi-threaded template accelerator architecture and a cohesive stack that generates the hardware and software code from its high-level DSL. CoSMIC can accelerate a wide range of learning algorithms that are most commonly trained using parallel variants of gradient descent. The key is to distribute partial gradient calculations of the learning algorithms across the accelerator-augmented nodes of the scale-out system. Additionally, CoSMIC leverages the parallelizability of the algorithms to offer multi-threaded acceleration within each node. Multi-threading allows CoSMIC to efficiently exploit the numerous resources that are becoming available on modern FPGAs/P-ASICs by striking a balance between multi-threaded parallelism and single-threaded performance. CoSMIC takes advantage of algorithmic properties of ML to offer a specialized system software that optimizes task allocation, role-assignment, thread management, and internode communication. We evaluate the versatility and efficiency of CoSMIC for 10 different machine learning applications from various domains. On average, a 16-node CoSMIC with UltraScale+ FPGAs offers 18.8\texttimes{} speedup over a 16-node Spark system with Xeon processors while the programmer only writes 22--55 lines of code. CoSMIC offers higher scalability compared to the state-of-the-art Spark; scaling from 4 to 16 nodes with CoSMIC yields 2.7\texttimes{} improvements whereas Spark offers 1.8\texttimes{}. These results confirm that the full-stack approach of CoSMIC takes an effective and vital step towards enabling scale-out acceleration for machine learning.},
booktitle = {Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture},
pages = {367–381},
numpages = {15},
keywords = {distributed, cloud, scale-out, accelerator, machine learning},
location = {Cambridge, Massachusetts},
series = {MICRO-50 '17}
}

@article{10.1145/3364999,
author = {Daruwalla, Kyle and Zhuo, Heng and Shukla, Rohit and Lipasti, Mikko},
title = {BitSAD v2: Compiler Optimization and Analysis for Bitstream Computing},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3364999},
doi = {10.1145/3364999},
abstract = {Computer vision and machine learning algorithms operating under a strict power budget require an alternate computing paradigm. While bitstream computing (BC) satisfies these constraints, creating BC systems is difficult. To address the design challenges, we propose compiler extensions to BitSAD, a DSL for BC. Our work enables bit-level software emulation and automated generation of hierarchical hardware, discusses potential optimizations, and proposes compiler phases to implement those optimizations in a hardware-aware manner. Finally, we introduce population coding, a parallelization scheme for stochastic computing that decreases latency without sacrificing accuracy, and provide theoretical and experimental guarantees on its effectiveness.},
journal = {ACM Trans. Archit. Code Optim.},
month = {nov},
articleno = {43},
numpages = {25},
keywords = {compiler, pulse density modulation, stochastic computing, Bitstream computing}
}

@inproceedings{10.1145/3097983.3098171,
author = {Cheng, Heng-Tze and Haque, Zakaria and Hong, Lichan and Ispir, Mustafa and Mewald, Clemens and Polosukhin, Illia and Roumpos, Georgios and Sculley, D. and Smith, Jamie and Soergel, David and Tang, Yuan and Tucker, Philipp and Wicke, Martin and Xia, Cassandra and Xie, Jianwei},
title = {TensorFlow Estimators: Managing Simplicity vs. Flexibility in High-Level Machine Learning Frameworks},
year = {2017},
isbn = {9781450348874},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3097983.3098171},
doi = {10.1145/3097983.3098171},
abstract = {We present a framework for specifying, training, evaluating, and deploying machine learning models. Our focus is on simplifying cutting edge machine learning for practitioners in order to bring such technologies into production. Recognizing the fast evolution of the field of deep learning, we make no attempt to capture the design space of all possible model architectures in a domain-specific language (DSL) or similar configuration language. We allow users to write code to define their models, but provide abstractions that guide developers to write models in ways conducive to productionization. We also provide a unifying Estimator interface, making it possible to write downstream infrastructure (e.g. distributed training, hyperparameter tuning) independent of the model implementation.We balance the competing demands for flexibility and simplicity by offering APIs at different levels of abstraction, making common model architectures available out of the box, while providing a library of utilities designed to speed up experimentation with model architectures. To make out of the box models flexible and usable across a wide range of problems, these canned Estimators are parameterized not only over traditional hyperparameters, but also using feature columns, a declarative specification describing how to interpret input dataWe discuss our experience in using this framework in research and production environments, and show the impact on code health, maintainability, and development speed.},
booktitle = {Proceedings of the 23rd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages = {1763–1771},
numpages = {9},
keywords = {deep learning, high level api, machine learning framework},
location = {Halifax, NS, Canada},
series = {KDD '17}
}

@inproceedings{10.1145/3276604.3276981,
author = {Merino, Mauricio Verano and Vinju, Jurgen and van der Storm, Tijs},
title = {Bacat\'{a}: A Language Parametric Notebook Generator (Tool Demo)},
year = {2018},
isbn = {9781450360296},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3276604.3276981},
doi = {10.1145/3276604.3276981},
abstract = {Interactive notebooks allow people to communicate and collaborate through a single rich document that might include live code, multimedia, computed results, and documentation, which is persisted as a whole for reproducibility. Notebooks are currently being used extensively in domains such as data science, data journalism, and machine learning. However, constructing a notebook interface for a new language requires a lot of effort. In this tool paper, we present Bacat\'{a}, a language parametric notebook generator for domain-specific languages (DSL) based on the Jupyter framework. Bacat\'{a} is designed so that language engineers may reuse existing language components (such as parsers, code generators, interpreters, etc.) as much as possible. Moreover, we explain the design of Bacat\'{a} and how DSL notebooks can be generated with minimum effort in the context of the Rascal meta programming system and language workbench.},
booktitle = {Proceedings of the 11th ACM SIGPLAN International Conference on Software Language Engineering},
pages = {210–214},
numpages = {5},
keywords = {domain-specific languages, language workbenches, literate programming, Interactive computing},
location = {Boston, MA, USA},
series = {SLE 2018}
}

@inproceedings{10.1145/1941553.1941561,
author = {Chafi, Hassan and Sujeeth, Arvind K. and Brown, Kevin J. and Lee, HyoukJoong and Atreya, Anand R. and Olukotun, Kunle},
title = {A Domain-Specific Approach to Heterogeneous Parallelism},
year = {2011},
isbn = {9781450301190},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1941553.1941561},
doi = {10.1145/1941553.1941561},
abstract = {Exploiting heterogeneous parallel hardware currently requires mapping application code to multiple disparate programming models. Unfortunately, general-purpose programming models available today can yield high performance but are too low-level to be accessible to the average programmer. We propose leveraging domain-specific languages (DSLs) to map high-level application code to heterogeneous devices. To demonstrate the potential of this approach we present OptiML, a DSL for machine learning. OptiML programs are implicitly parallel and can achieve high performance on heterogeneous hardware with no modification required to the source code. For such a DSL-based approach to be tractable at large scales, better tools are required for DSL authors to simplify language creation and parallelization. To address this concern, we introduce Delite, a system designed specifically for DSLs that is both a framework for creating an implicitly parallel DSL as well as a dynamic runtime providing automated targeting to heterogeneous parallel hardware. We show that OptiML running on Delite achieves single-threaded, parallel, and GPU performance superior to explicitly parallelized MATLAB code in nearly all cases.},
booktitle = {Proceedings of the 16th ACM Symposium on Principles and Practice of Parallel Programming},
pages = {35–46},
numpages = {12},
keywords = {dynamic optimizations, runtimes, parallel programming, domain-specific languages},
location = {San Antonio, TX, USA},
series = {PPoPP '11}
}

@article{10.1145/2038037.1941561,
author = {Chafi, Hassan and Sujeeth, Arvind K. and Brown, Kevin J. and Lee, HyoukJoong and Atreya, Anand R. and Olukotun, Kunle},
title = {A Domain-Specific Approach to Heterogeneous Parallelism},
year = {2011},
issue_date = {August 2011},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {46},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/2038037.1941561},
doi = {10.1145/2038037.1941561},
abstract = {Exploiting heterogeneous parallel hardware currently requires mapping application code to multiple disparate programming models. Unfortunately, general-purpose programming models available today can yield high performance but are too low-level to be accessible to the average programmer. We propose leveraging domain-specific languages (DSLs) to map high-level application code to heterogeneous devices. To demonstrate the potential of this approach we present OptiML, a DSL for machine learning. OptiML programs are implicitly parallel and can achieve high performance on heterogeneous hardware with no modification required to the source code. For such a DSL-based approach to be tractable at large scales, better tools are required for DSL authors to simplify language creation and parallelization. To address this concern, we introduce Delite, a system designed specifically for DSLs that is both a framework for creating an implicitly parallel DSL as well as a dynamic runtime providing automated targeting to heterogeneous parallel hardware. We show that OptiML running on Delite achieves single-threaded, parallel, and GPU performance superior to explicitly parallelized MATLAB code in nearly all cases.},
journal = {SIGPLAN Not.},
month = {feb},
pages = {35–46},
numpages = {12},
keywords = {runtimes, dynamic optimizations, parallel programming, domain-specific languages}
}

@inproceedings{10.1145/2555243.2557966,
author = {Olukotun, Kunle},
title = {Beyond Parallel Programming with Domain Specific Languages},
year = {2014},
isbn = {9781450326568},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2555243.2557966},
doi = {10.1145/2555243.2557966},
abstract = {Today, almost all computer architectures are parallel and heterogeneous; a combination of multiple CPUs, GPUs and specialized processors. This creates a challenging problem for application developers who want to develop high performance programs without the effort required to use low-level, architecture specific parallel programming models (e.g. OpenMP for CMPs, CUDA for GPUs, MPI for clusters). Domain-specific languages (DSLs) are a promising solution to this problem because they can provide an avenue for high-level application-specific abstractions with implicit parallelism to be mapped directly to low level architecture-specific programming models; providing both high programmer productivity and high execution performance.In this talk I will describe an approach to building high performance DSLs, which is based on DSL embedding in a general purpose programming language, metaprogramming and a DSL infrastructure called Delite. I will describe how we transform DSL programs into efficient first-order low-level code using domain specific optimization, parallelism and locality optimization with parallel patterns, and architecture-specific code generation. All optimizations and transformations are implemented in Delite: an extensible DSL compiler infrastucture that significantly reduces the effort required to develop new DSLs. Delite DSLs for machine learning, data querying, graph analysis, and scientific computing all achieve performance competitive with manually parallelized C++ code.},
booktitle = {Proceedings of the 19th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming},
pages = {179–180},
numpages = {2},
keywords = {domain specific languages},
location = {Orlando, Florida, USA},
series = {PPoPP '14}
}

@article{10.1145/2692916.2557966,
author = {Olukotun, Kunle},
title = {Beyond Parallel Programming with Domain Specific Languages},
year = {2014},
issue_date = {August 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {49},
number = {8},
issn = {0362-1340},
url = {https://doi.org/10.1145/2692916.2557966},
doi = {10.1145/2692916.2557966},
abstract = {Today, almost all computer architectures are parallel and heterogeneous; a combination of multiple CPUs, GPUs and specialized processors. This creates a challenging problem for application developers who want to develop high performance programs without the effort required to use low-level, architecture specific parallel programming models (e.g. OpenMP for CMPs, CUDA for GPUs, MPI for clusters). Domain-specific languages (DSLs) are a promising solution to this problem because they can provide an avenue for high-level application-specific abstractions with implicit parallelism to be mapped directly to low level architecture-specific programming models; providing both high programmer productivity and high execution performance.In this talk I will describe an approach to building high performance DSLs, which is based on DSL embedding in a general purpose programming language, metaprogramming and a DSL infrastructure called Delite. I will describe how we transform DSL programs into efficient first-order low-level code using domain specific optimization, parallelism and locality optimization with parallel patterns, and architecture-specific code generation. All optimizations and transformations are implemented in Delite: an extensible DSL compiler infrastucture that significantly reduces the effort required to develop new DSLs. Delite DSLs for machine learning, data querying, graph analysis, and scientific computing all achieve performance competitive with manually parallelized C++ code.},
journal = {SIGPLAN Not.},
month = {feb},
pages = {179–180},
numpages = {2},
keywords = {domain specific languages}
}

@inproceedings{10.1145/3039895.3039898,
author = {Dethlefs, Nina and Hawick, Ken},
title = {DEFIne: A Fluent Interface DSL for Deep Learning Applications},
year = {2017},
isbn = {9781450348454},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3039895.3039898},
doi = {10.1145/3039895.3039898},
abstract = {Recent years have seen a surge of interest in deep learning models that outperform other machine learning algorithms on benchmarks across many disciplines. Most existing deep learning libraries facilitate the development of neural nets by providing a mathematical framework that helps users implement their models more efficiently. This still represents a substantial investment of time and effort, however, when the intention is to compare a range of competing models quickly for a specific task. We present DEFIne, a fluent interface DSL for the specification, optimisation and evaluation of deep learning models. The fluent interface is implemented through method chaining. DEFIne is embedded in Python and is build on top of its most popular deep learning libraries, Keras and Theano. It extends these with common operations for data pre-processing and representation as well as visualisation of datasets and results. We test our framework on three benchmark tasks from different domains: heart disease diagnosis, hand-written digit recognition and weather forecast generation. Results in terms of accuracy, runtime and lines of code show that our DSL achieves equivalent accuracy and runtime to state-of-the-art models, while requiring only about 10 lines of code per application.},
booktitle = {Proceedings of the 2nd International Workshop on Real World Domain Specific Languages},
articleno = {3},
numpages = {10},
keywords = {deep learning, Domain-specific languages},
location = {Austin, TX, USA},
series = {RWDSL17}
}

@inproceedings{10.1145/1921168.1921178,
author = {Jin, Yu and Duffield, Nick and Gerber, Alexandre and Haffner, Patrick and Sen, Subhabrata and Zhang, Zhi-Li},
title = {NEVERMIND, the Problem is Already Fixed: Proactively Detecting and Troubleshooting Customer DSL Problems},
year = {2010},
isbn = {9781450304481},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/1921168.1921178},
doi = {10.1145/1921168.1921178},
abstract = {Traditional DSL troubleshooting solutions are reactive, relying mainly on customers to report problems, and tend to be labor-intensive, time consuming, prone to incorrect resolutions and overall can contribute to increased customer dissatisfaction. In this paper, we propose a proactive approach to facilitate troubleshooting customer edge problems and reducing customer tickets. Our system consists of: i) a ticket predictor which predicts future customer tickets; and ii) a trouble locator which helps technicians accelerate the troubleshooting process during field dispatches. Both components infer future tickets and trouble locations based on existing sparse line measurements, and the inference models are constructed automatically using supervised machine learning techniques. We propose several novel techniques to address the operational constraints in DSL networks and to enhance the accuracy of NEVERMIND. Extensive evaluations using an entire year worth of customer tickets and measurement data from a large network show that our method can predict thousands of future customer tickets per week with high accuracy and signifcantly reduce the time and effort for diagnosing these tickets. This is benefcial as it has the effect of both reducing the number of customer care calls and improving customer satisfaction.},
booktitle = {Proceedings of the 6th International COnference},
articleno = {7},
numpages = {12},
location = {Philadelphia, Pennsylvania},
series = {Co-NEXT '10}
}

@inbook{10.1145/3447404.3447405,
title = {Preface},
year = {2021},
isbn = {9781450390293},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
edition = {1},
url = {https://doi.org/10.1145/3447404.3447405},
abstract = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice provides a comprehensive resource on what has become the dominant paradigm for novel interaction design methods involving gesture, speech, text, and touch embedded in novel and emerging interfaces. These interfaces support smartphones, wearables, in-vehicle devices, virtual reality, robotic, the Internet of Things (IoT), brain–computer interaction, and many other applications that are now highly competitive commercially.This edited collection is written by international experts and pioneers in the field of digital signal processing (DSP) and machine learning (ML) for interactive systems. It provides a textbook for students, and a reference and technology roadmap for developers and professionals working in interaction design on emerging platforms. This introductory textbook presents theory chapters on statistical grounding, signal processing, and ML foundations for guiding the development of novel interactive systems. Additional chapters discuss case studies on smart cities, brain–computer interfaces (BCI), probabilistic text entry, secure gestures, personal context from mobile phones, building adaptive touch interfaces, and automotive user interfaces (UIs). The chapters on case studies also highlight an in-depth look at domain-specific language (DSL) and ML methods used, for example, in touch, gesture, electroencephalography (EEG), electrocardiography (ECG), and galvanic skin response (GSR) signals, or embedded sensor inputs. A common theme throughout is the ubiquitous support for humans as they go about their daily professional or personal activities.This introductory book provides walk-through examples of different DSP and ML techniques and their use in interactive systems. Common terms are defined, and information on practical resources is provided (e.g., software tools, data resources) for hands-on project work to develop and evaluate multimodal–multisensor systems. After each chapter an expert on the legal and ethical issues explores the wider ethical issues on how DSP and ML should be adopted and used in socially appropriate ways, to most effectively advance human performance during interaction with novel platforms.Parisa Eslambolchilar, Andreas Komninos, and Mark D. Dunlop, March 2020AcknowledgmentsWe would like to thank our external reviewers for their valuable feedback throughout the writing process.},
booktitle = {Intelligent Computing for Interactive System Design: Statistics, Digital Signal Processing, and Machine Learning in Practice},
pages = {xv–xvi}
}

@article{10.1145/3368858,
author = {Stoltzfus, Larisa and Hagedorn, Bastian and Steuwer, Michel and Gorlatch, Sergei and Dubach, Christophe},
title = {Tiling Optimizations for Stencil Computations Using Rewrite Rules in Lift},
year = {2019},
issue_date = {December 2019},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {16},
number = {4},
issn = {1544-3566},
url = {https://doi.org/10.1145/3368858},
doi = {10.1145/3368858},
abstract = {Stencil computations are a widely used type of algorithm, found in applications from physical simulations to machine learning. Stencils are embarrassingly parallel, therefore fit on modern hardware such as Graphic Processing Units perfectly. Although stencil computations have been extensively studied, optimizing them for increasingly diverse hardware remains challenging. Domain-specific Languages (DSLs) have raised the programming abstraction and offer good performance; however, this method places the burden on DSL implementers to write almost full-fledged parallelizing compilers and optimizers.Lift has recently emerged as a promising approach to achieve performance portability by using a small set of reusable parallel primitives that DSL or library writers utilize. Lift’s key novelty is in its encoding of optimizations as a system of extensible rewrite rules which are used to explore the optimization space.This article demonstrates how complex multi-dimensional stencil code and optimizations are expressed using compositions of simple 1D Lift primitives and rewrite rules. We introduce two optimizations that provide high performance for stencils in particular: classical overlapped tiling for multi-dimensional stencils and 2.5D tiling specifically for 3D stencils. We provide an in-depth analysis on how the tiling optimizations affects stencils of different shapes and sizes across different applications. Our experimental results show that our approach outperforms existing compiler approaches and hand-tuned codes.},
journal = {ACM Trans. Archit. Code Optim.},
month = {dec},
articleno = {52},
numpages = {25},
keywords = {GPU computing, lift, performance portability, stencil, Code generation}
}

@inproceedings{10.1145/3168824,
author = {Hagedorn, Bastian and Stoltzfus, Larisa and Steuwer, Michel and Gorlatch, Sergei and Dubach, Christophe},
title = {High Performance Stencil Code Generation with Lift},
year = {2018},
isbn = {9781450356176},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3168824},
doi = {10.1145/3168824},
abstract = {Stencil computations are widely used from physical simulations to machine-learning. They are embarrassingly parallel and perfectly fit modern hardware such as Graphic Processing Units. Although stencil computations have been extensively studied, optimizing them for increasingly diverse hardware remains challenging. Domain Specific Languages (DSLs) have raised the programming abstraction and offer good performance. However, this places the burden on DSL implementers who have to write almost full-fledged parallelizing compilers and optimizers. Lift has recently emerged as a promising approach to achieve performance portability and is based on a small set of reusable parallel primitives that DSL or library writers can build upon. Lift’s key novelty is in its encoding of optimizations as a system of extensible rewrite rules which are used to explore the optimization space. However, Lift has mostly focused on linear algebra operations and it remains to be seen whether this approach is applicable for other domains. This paper demonstrates how complex multidimensional stencil code and optimizations such as tiling are expressible using compositions of simple 1D Lift primitives. By leveraging existing Lift primitives and optimizations, we only require the addition of two primitives and one rewrite rule to do so. Our results show that this approach outperforms existing compiler approaches and hand-tuned codes.},
booktitle = {Proceedings of the 2018 International Symposium on Code Generation and Optimization},
pages = {100–112},
numpages = {13},
keywords = {GPU Computing, Stencil, Performance Portability, Code Generation, Lift},
location = {Vienna, Austria},
series = {CGO 2018}
}

@article{10.1145/2584665,
author = {Sujeeth, Arvind K. and Brown, Kevin J. and Lee, Hyoukjoong and Rompf, Tiark and Chafi, Hassan and Odersky, Martin and Olukotun, Kunle},
title = {Delite: A Compiler Architecture for Performance-Oriented Embedded Domain-Specific Languages},
year = {2014},
issue_date = {July 2014},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
volume = {13},
number = {4s},
issn = {1539-9087},
url = {https://doi.org/10.1145/2584665},
doi = {10.1145/2584665},
abstract = {Developing high-performance software is a difficult task that requires the use of low-level, architecture-specific programming models (e.g., OpenMP for CMPs, CUDA for GPUs, MPI for clusters). It is typically not possible to write a single application that can run efficiently in different environments, leading to multiple versions and increased complexity. Domain-Specific Languages (DSLs) are a promising avenue to enable programmers to use high-level abstractions and still achieve good performance on a variety of hardware. This is possible because DSLs have higher-level semantics and restrictions than general-purpose languages, so DSL compilers can perform higher-level optimization and translation. However, the cost of developing performance-oriented DSLs is a substantial roadblock to their development and adoption. In this article, we present an overview of the Delite compiler framework and the DSLs that have been developed with it. Delite simplifies the process of DSL development by providing common components, like parallel patterns, optimizations, and code generators, that can be reused in DSL implementations. Delite DSLs are embedded in Scala, a general-purpose programming language, but use metaprogramming to construct an Intermediate Representation (IR) of user programs and compile to multiple languages (including C++, CUDA, and OpenCL). DSL programs are automatically parallelized and different parts of the application can run simultaneously on CPUs and GPUs. We present Delite DSLs for machine learning, data querying, graph analysis, and scientific computing and show that they all achieve performance competitive to or exceeding C++ code.},
journal = {ACM Trans. Embed. Comput. Syst.},
month = {apr},
articleno = {134},
numpages = {25},
keywords = {Domain-specific languages, language virtualization, code generation, multistage programming}
}

@article{10.14778/3236187.3236188,
author = {Mahajan, Divya and Kim, Joon Kyung and Sacks, Jacob and Ardalan, Adel and Kumar, Arun and Esmaeilzadeh, Hadi},
title = {In-RDBMS Hardware Acceleration of Advanced Analytics},
year = {2018},
issue_date = {July 2018},
publisher = {VLDB Endowment},
volume = {11},
number = {11},
issn = {2150-8097},
url = {https://doi.org/10.14778/3236187.3236188},
doi = {10.14778/3236187.3236188},
abstract = {The data revolution is fueled by advances in machine learning, databases, and hardware design. Programmable accelerators are making their way into each of these areas independently. As such, there is a void of solutions that enables hardware acceleration at the intersection of these disjoint fields. This paper sets out to be the initial step towards a unifying solution for in-Database Acceleration of Advanced Analytics (DAnA). Deploying specialized hardware, such as FPGAs, for in-database analytics currently requires hand-designing the hardware and manually routing the data. Instead, DAnA automatically maps a high-level specification of advanced analytics queries to an FPGA accelerator. The accelerator implementation is generated for a User Defined Function (UDF), expressed as a part of an SQL query using a Python-embedded Domain-Specific Language (DSL). To realize an efficient in-database integration, DAnA accelerators contain a novel hardware structure, Striders, that directly interface with the buffer pool of the database. Striders extract, cleanse, and process the training data tuples that are consumed by a multi-threaded FPGA engine that executes the analytics algorithm. We integrate DAnA with PostgreSQL to generate hardware accelerators for a range of real-world and synthetic datasets running diverse ML algorithms. Results show that DAnA-enhanced PostgreSQL provides, on average, 8.3\texttimes{} end-to-end speedup for real datasets, with a maximum of 28.2\texttimes{}. Moreover, DAnA-enhanced PostgreSQL is, on average, 4.0\texttimes{} faster than the multi-threaded Apache MADLib running on Greenplum. DAnA provides these benefits while hiding the complexity of hardware design from data scientists and allowing them to express the algorithm in ≈30-60 lines of Python.},
journal = {Proc. VLDB Endow.},
month = {jul},
pages = {1317–1331},
numpages = {15}
}

@article{10.1145/3571284,
author = {Perez, Victor and Sommer, Lukas and Lom\"{u}ller, Victor and Narasimhan, Kumudha and Goli, Mehdi},
title = {User-Driven Online Kernel Fusion for SYCL},
year = {2022},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
issn = {1544-3566},
url = {https://doi.org/10.1145/3571284},
doi = {10.1145/3571284},
abstract = {Heterogeneous programming models are becoming increasingly popular to support the ever-evolving hardware architectures, especially for new and emerging specialized accelerators optimizing specific tasks. While such programs provide performance portability of the existing applications across various heterogeneous architectures to some extent, short-running device kernels can affect an application performance due to overheads of data transfer, synchronization and kernel launch. While in applications with one or two short-running kernels the overhead can be negligible, it can be noticeable when these short-running kernels dominate the overall number of kernels in an application, as it is the case in graph-based neural network models, where there are several small memory-bound nodes alongside few large compute-bound nodes. To reduce the overhead, combining several kernels into a single, more optimized kernel is an active area of research. However, this task can be time-consuming and error-prone given the huge set of potential combinations. This can push programmers to seek a trade-off between (a) task-specific kernels with low overhead but hard to maintain and (b) smaller modular kernels with higher overhead but easier to maintain. While there are DSL-based approaches, such as those provided for machine learning frameworks, which offer the possibility of such a fusion, they are limited to a particular domain and exploit specific knowledge of that domain and, as a consequence, are hard to port elsewhere. This study explores the feasibility of a user-driven kernel fusion through an extension to the SYCL API to address the automation of kernel fusion. The proposed solution requires programmers to define the subgraph regions that are potentially suitable for fusion without any modification to the kernel code or the function signature. We evaluate the performance benefit of our approach on common neural networks and study the performance improvement in detail.},
note = {Just Accepted},
journal = {ACM Trans. Archit. Code Optim.},
month = {nov},
keywords = {runtime environments, neural networks, just-in-time compilers}
}

